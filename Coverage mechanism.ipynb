{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f012667",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a66edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- System & Utilities ---\n",
    "import os                    # File and directory operations\n",
    "import re                    # Regular expressions for string cleaning\n",
    "import string                # String operations\n",
    "import ast                   # Safe evaluation of Python expressions\n",
    "import random                # Random operations (shuffling, sampling)\n",
    "import time                  # Time tracking for performance\n",
    "from collections import Counter  # Count frequencies of tokens\n",
    "\n",
    "# --- Data Handling ---\n",
    "import pandas as pd          # DataFrames for structured data\n",
    "import numpy as np           # Numerical operations and arrays\n",
    "\n",
    "# --- Natural Language Processing (NLP) ---\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize           # Tokenize sentences/words\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.corpus import stopwords, wordnet        # Common stopwords and WordNet\n",
    "from nltk.stem import WordNetLemmatizer           # Lemmatization for word normalization\n",
    "from bert_score import score as bert_score        # Semantic similarity metric\n",
    "\n",
    "# --- Deep Learning with PyTorch ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# --- Visualization & Progress Tracking ---\n",
    "import matplotlib.pyplot as plt                   # Plotting graphs\n",
    "from tqdm import tqdm                              # Progress bar for loops\n",
    "\n",
    "# --- Word Embeddings ---\n",
    "from gensim.models import KeyedVectors            # Load pretrained word vectors\n",
    "\n",
    "# --- Memory Management ---\n",
    "import gc                                          # Garbage collection to manage RAM\n",
    "\n",
    "# --- Optimization ---\n",
    "import torch.optim as optim                       # Optimizers (e.g., Adam, SGD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168da80c",
   "metadata": {},
   "source": [
    "#### Set up the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df3b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# --- Device Configuration ---\n",
    "# Automatically select the best available device: MPS (Apple), CUDA (GPU), or CPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(\"✅ Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429480b",
   "metadata": {},
   "source": [
    "#### Special Tokens and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d0582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Special Tokens & Model Hyperparameters ---\n",
    "# Define tokens for padding, start/end of sequence, and unknown words\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "SOS_TOKEN = \"<sos>\"\n",
    "EOS_TOKEN = \"<eos>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "SPECIAL_TOKENS = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN]\n",
    "\n",
    "# Set model hyperparameters and data preprocessing constants\n",
    "MAX_INGREDIENT_LEN = 20     # Max number of input tokens\n",
    "MAX_RECIPE_LEN = 60         # Max number of output tokens\n",
    "BATCH_SIZE = 64             # Training batch size\n",
    "EMB_DIM = 64                # Word embedding dimension\n",
    "HIDDEN_DIM = 256            # RNN hidden state dimension\n",
    "TEACHER_FORCING_RATIO = 0.8 # Probability of using teacher forcing during training\n",
    "num_iters = 10000           # Total training iterations\n",
    "print_every = 50            # Frequency of logging training loss\n",
    "plot_every = 50             # Frequency of computing validation loss and plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4868afa1",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ce9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSVs\n",
    "train_df = pd.read_csv('/Users/myatpwintphyu/Desktop/Monash/2025 S1/NLP/Assignment_2/Cooking_Dataset/train.csv')\n",
    "dev_df = pd.read_csv('/Users/myatpwintphyu/Desktop/Monash/2025 S1/NLP/Assignment_2/Cooking_Dataset/dev.csv')\n",
    "test_df = pd.read_csv('/Users/myatpwintphyu/Desktop/Monash/2025 S1/NLP/Assignment_2/Cooking_Dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f45cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NLP Preprocessing Utilities ---\n",
    "lemmatizer = WordNetLemmatizer()                        # Word lemmatizer for reducing words to base form\n",
    "stop_words = set(stopwords.words('english'))            # English stopwords to remove from text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Text Cleaning and Formatting Functions ---\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and tokenizes a text string by lowercasing, removing non-alphabetic characters,\n",
    "    removing stopwords, and applying lemmatization.\n",
    "    \"\"\"\n",
    "    words = re.findall(r'\\b[a-zA-Z]+\\b', str(text).lower())\n",
    "    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
    "    return words if words else [\"unknown\"]\n",
    "\n",
    "def preprocess_ingredients_column(df):\n",
    "    \"\"\"Adds 'input_tokens' column by preprocessing the 'Ingredients' field.\"\"\"\n",
    "    df['input_tokens'] = df['Ingredients'].apply(preprocess_text)\n",
    "    return df\n",
    "\n",
    "def preprocess_recipes_column(df):\n",
    "    \"\"\"Adds 'output_tokens' column by preprocessing the 'Recipe' field.\"\"\"\n",
    "    df['output_tokens'] = df['Recipe'].apply(preprocess_text)\n",
    "    return df\n",
    "\n",
    "def format_input_prompt(tokens):\n",
    "    \"\"\"Formats ingredient tokens as a prompt string for generation.\"\"\"\n",
    "    return f\"Generate recipe for: {', '.join(tokens)}\"\n",
    "\n",
    "def format_target_text(row):\n",
    "    \"\"\"Formats a row into a readable multi-line recipe string.\"\"\"\n",
    "    title = row['Title'] if 'Title' in row else 'Generated Recipe'\n",
    "    ingredients = ', '.join(row['input_tokens'])\n",
    "    instructions = ', '.join(row['output_tokens'])\n",
    "    return f\"Title: {title}\\n\\nIngredients:\\n{ingredients}\\nInstructions:\\n{instructions}\"\n",
    "\n",
    "def build_vocab(token_lists):\n",
    "    \"\"\"\n",
    "    Builds vocabulary from token lists and assigns unique index to each token.\n",
    "    Includes special tokens.\n",
    "    \"\"\"\n",
    "    vocab = {PAD_TOKEN: 0, SOS_TOKEN: 1, EOS_TOKEN: 2, UNK_TOKEN: 3}\n",
    "    counter = Counter(token for tokens in token_lists for token in tokens)\n",
    "    for token in counter:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff993b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Apply Preprocessing to Dataset Splits ---\n",
    "# Tokenize and clean text fields for each split (train/dev/test)\n",
    "train_df = preprocess_ingredients_column(train_df)\n",
    "train_df = preprocess_recipes_column(train_df)\n",
    "\n",
    "dev_df = preprocess_ingredients_column(dev_df)\n",
    "dev_df = preprocess_recipes_column(dev_df)\n",
    "\n",
    "test_df = preprocess_ingredients_column(test_df)\n",
    "test_df = preprocess_recipes_column(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6748177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate Input Prompts for Model ---\n",
    "# Converts token lists into natural language prompts\n",
    "train_df['input_prompt'] = train_df['input_tokens'].apply(format_input_prompt)\n",
    "dev_df['input_prompt'] = dev_df['input_tokens'].apply(format_input_prompt)\n",
    "test_df['input_prompt'] = test_df['input_tokens'].apply(format_input_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate Readable Target Texts ---\n",
    "# Combine title, ingredients, and instructions into formatted strings\n",
    "train_df['target_text'] = train_df.apply(format_target_text, axis=1)\n",
    "dev_df['target_text'] = dev_df.apply(format_target_text, axis=1)\n",
    "test_df['target_text'] = test_df.apply(format_target_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1074372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build Vocabularies ---\n",
    "# Construct token-to-index mappings from training data\n",
    "input_vocab = build_vocab(train_df['input_tokens'])\n",
    "output_vocab = build_vocab(train_df['output_tokens'])\n",
    "\n",
    "# Create reverse index-to-token dictionaries for decoding\n",
    "input_idx2word = {i: w for w, i in input_vocab.items()}\n",
    "output_idx2word = {i: w for w, i in output_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c314658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(tokens, vocab, max_len, is_target=False):\n",
    "    \"\"\"\n",
    "    Encodes a list of tokens into a fixed-length list of token IDs using a vocabulary.\n",
    "\n",
    "    Args:\n",
    "        tokens: List of tokens (strings) to encode.\n",
    "        vocab: Dictionary mapping tokens to indices.\n",
    "        max_len: Maximum allowed length of the output sequence.\n",
    "        is_target: If True, adds <sos> at the start and <eos> at the end.\n",
    "\n",
    "    Returns:\n",
    "        A list of token IDs (integers), padded or truncated to max_len.\n",
    "    \"\"\"\n",
    "    encoded = []  # Initialize the list of token IDs\n",
    "\n",
    "    if is_target:\n",
    "        # Add <sos> token at the beginning if it's a target sequence\n",
    "        encoded.append(vocab[SOS_TOKEN])\n",
    "    \n",
    "    for tok in tokens:\n",
    "        # Convert each token to its corresponding index in the vocab\n",
    "        # Use <unk> token index if token is not found\n",
    "        encoded.append(vocab.get(tok, vocab[UNK_TOKEN]))\n",
    "\n",
    "    if is_target:\n",
    "        # Add <eos> token at the end if it's a target sequence\n",
    "        encoded.append(vocab[EOS_TOKEN])\n",
    "\n",
    "    # Ensure the sequence is exactly max_len in length\n",
    "    if len(encoded) > max_len:\n",
    "        # Truncate if too long\n",
    "        encoded = encoded[:max_len]\n",
    "    else:\n",
    "        # Pad with <pad> tokens if too short\n",
    "        encoded += [vocab[PAD_TOKEN]] * (max_len - len(encoded))\n",
    "\n",
    "    return encoded  # Return the fixed-length list of token indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8907583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CookingDataset(Dataset):\n",
    "    def __init__(self, df, input_vocab, output_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (DataFrame): The dataset containing tokenized ingredients and recipes.\n",
    "            input_vocab (dict): Vocabulary mapping for input tokens (ingredients).\n",
    "            output_vocab (dict): Vocabulary mapping for output tokens (recipes).\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples (rows) in the DataFrame\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get token lists from the DataFrame at the given index\n",
    "        src_tokens = self.df.iloc[idx]['input_tokens']   # Ingredients\n",
    "        trg_tokens = self.df.iloc[idx]['output_tokens']  # Recipe steps\n",
    "\n",
    "        # Encode the tokens using the vocabularies\n",
    "        src_encoded = encode_text(src_tokens, self.input_vocab, MAX_INGREDIENT_LEN)\n",
    "        trg_encoded = encode_text(trg_tokens, self.output_vocab, MAX_RECIPE_LEN, is_target=True)\n",
    "\n",
    "        # Return as PyTorch tensors\n",
    "        return torch.tensor(src_encoded), torch.tensor(trg_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d27d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for DataLoader to pad sequences in a batch.\n",
    "\n",
    "    Args:\n",
    "        batch: A list of (input_tensor, target_tensor) tuples from the dataset.\n",
    "\n",
    "    Returns:\n",
    "        src_padded: Padded input tensor of shape (batch_size, max_input_len).\n",
    "        trg_padded: Padded target tensor of shape (batch_size, max_target_len).\n",
    "    \"\"\"\n",
    "    # Unpack the batch into two lists: inputs and targets\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "\n",
    "    # Pad input sequences to the length of the longest in the batch\n",
    "    # batch_first=True -> shape will be (batch_size, seq_len)\n",
    "    src_padded = pad_sequence(\n",
    "        src_batch, batch_first=True, padding_value=input_vocab[PAD_TOKEN]\n",
    "    )\n",
    "\n",
    "    # Pad target sequences similarly\n",
    "    trg_padded = pad_sequence(\n",
    "        trg_batch, batch_first=True, padding_value=output_vocab[PAD_TOKEN]\n",
    "    )\n",
    "\n",
    "    # Return padded input and target batches\n",
    "    return src_padded, trg_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb03747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CookingDataset(train_df, input_vocab, output_vocab)\n",
    "dev_dataset = CookingDataset(dev_df, input_vocab, output_vocab)\n",
    "test_dataset = CookingDataset(test_df, input_vocab, output_vocab)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d307b721",
   "metadata": {},
   "source": [
    "#### Epoch Time Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a4418ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to format time nicely\n",
    "def epoch_time(start_time, end_time):\n",
    "    \"\"\"\n",
    "    Calculates elapsed time between two time points and formats it into minutes and seconds.\n",
    "\n",
    "    Args:\n",
    "        start_time: Float timestamp at the start (e.g., from time.time()).\n",
    "        end_time: Float timestamp at the end.\n",
    "\n",
    "    Returns:\n",
    "        A tuple (minutes, seconds) representing the duration.\n",
    "    \"\"\"\n",
    "    elapsed_time = end_time - start_time\n",
    "    minutes = int(elapsed_time / 60)\n",
    "    seconds = int(elapsed_time - (minutes * 60))\n",
    "    return minutes, seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854b7aa4",
   "metadata": {},
   "source": [
    "#### Evaluating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fdb8f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line creates a smoothing function for the BLEU score calculation using NLTK’s SmoothingFunction.\n",
    "smoothie = SmoothingFunction().method4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a443d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, input_vocab, output_vocab, device, model_name=\"Seq2Seq-RNN\"):\n",
    "    \"\"\"\n",
    "    Evaluates a trained Seq2Seq model using BLEU, METEOR, and BERTScore.\n",
    "\n",
    "    Args:\n",
    "        model: The trained sequence-to-sequence model.\n",
    "        data_loader: A DataLoader for the validation or test set.\n",
    "        input_vocab: Vocabulary mapping for input tokens (not used in this function).\n",
    "        output_vocab: Vocabulary mapping for output tokens (used for decoding).\n",
    "        device: PyTorch device (e.g., 'cuda' or 'cpu').\n",
    "        model_name: A string label for the model (used in the results dictionary).\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing average BLEU, METEOR, and BERTScore values for the dataset.\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode (disables dropout, etc.)\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize lists to store evaluation metrics and text outputs\n",
    "    bleu_scores = []\n",
    "    meteor_scores = []\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    # Create a reverse mapping from index to word for decoding output tokens\n",
    "    output_idx2word = {i: w for w, i in output_vocab.items()}\n",
    "\n",
    "    # Disable gradient calculation during evaluation\n",
    "    with torch.no_grad():\n",
    "        # Loop through batches from the validation/test DataLoader\n",
    "        for src_batch, trg_batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            # Move batches to the correct device (CPU or GPU)\n",
    "            src_batch = src_batch.to(device)\n",
    "            trg_batch = trg_batch.to(device)\n",
    "\n",
    "            # Get model predictions without teacher forcing\n",
    "            output = model(src_batch, trg_batch, teacher_forcing_ratio=0.0)\n",
    "            \n",
    "            # Get the most likely token index at each time step\n",
    "            # Shape: (batch_size, seq_len)\n",
    "            output_ids = output.argmax(2)\n",
    "\n",
    "            # Loop through each prediction-reference pair in the batch\n",
    "            for pred_seq, true_seq in zip(output_ids, trg_batch):\n",
    "                # Convert predicted token IDs to words, removing special tokens\n",
    "                pred_tokens = [\n",
    "                    output_idx2word.get(idx.item(), UNK_TOKEN)\n",
    "                    for idx in pred_seq\n",
    "                    if idx.item() not in [output_vocab[PAD_TOKEN], output_vocab[SOS_TOKEN], output_vocab[EOS_TOKEN]]\n",
    "                ]\n",
    "\n",
    "                true_tokens = [\n",
    "                    output_idx2word.get(idx.item(), UNK_TOKEN)\n",
    "                    for idx in true_seq\n",
    "                    if idx.item() not in [output_vocab[PAD_TOKEN], output_vocab[SOS_TOKEN], output_vocab[EOS_TOKEN]]\n",
    "                ]\n",
    "\n",
    "                # Store string versions for corpus-level evaluation later\n",
    "                predictions.append(\" \".join(pred_tokens))\n",
    "                references.append(\" \".join(true_tokens))\n",
    "\n",
    "                # Compute individual BLEU and METEOR scores for this sample\n",
    "                bleu = sentence_bleu([true_tokens], pred_tokens, smoothing_function=smoothie)\n",
    "                meteor = meteor_score([true_tokens], pred_tokens)\n",
    "\n",
    "                bleu_scores.append(bleu)\n",
    "                meteor_scores.append(meteor)\n",
    "\n",
    "    # Compute BERTScore once for the entire corpus\n",
    "    try:\n",
    "        P, R, F1 = bert_score(predictions, references, lang=\"en\", verbose=False)\n",
    "        bert_f1 = F1.mean().item()\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ BERTScore skipped due to error: {e}\")\n",
    "        bert_f1 = None\n",
    "\n",
    "    # Compute average scores across all samples\n",
    "    results = {\n",
    "        \"Model\": model_name,\n",
    "        \"BLEU\": sum(bleu_scores) / len(bleu_scores),\n",
    "        \"METEOR\": sum(meteor_scores) / len(meteor_scores),\n",
    "        \"BERTScore\": bert_f1 if bert_f1 is not None else \"Unavailable\"\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c8f820",
   "metadata": {},
   "source": [
    "#### Evaluation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef0bb8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(model, val_loader, criterion, output_vocab, device):\n",
    "    \"\"\"\n",
    "    Computes the average loss of a trained model on a validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model: Trained Seq2Seq model.\n",
    "        val_loader: DataLoader for the validation set.\n",
    "        criterion: Loss function (e.g., nn.CrossEntropyLoss).\n",
    "        output_vocab: Target vocabulary dictionary (not used directly here).\n",
    "        device: PyTorch device (e.g., 'cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        Average validation loss across all batches.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src_batch, trg_batch in val_loader:\n",
    "            src_batch = src_batch.to(device)\n",
    "            trg_batch = trg_batch.to(device)\n",
    "\n",
    "            output = model(src_batch, trg_batch, teacher_forcing_ratio=0.0)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            target = trg_batch[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef344f7",
   "metadata": {},
   "source": [
    "#### Training Loop for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, output_vocab, device,\n",
    "                num_iters, print_every, plot_every, teacher_forcing_ratio=0.5, \n",
    "                log_filename=\"training_log.csv\", plot_title=\"Training and Validation Loss\"):\n",
    "    \"\"\"\n",
    "    Trains a Seq2Seq model using random batches from the training data.\n",
    "    Also tracks validation loss and logs progress over time.\n",
    "    \"\"\"\n",
    "    \n",
    "    import time\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    print_loss_total = 0  # Running total for printing\n",
    "    plot_loss_total = 0   # Running total for plotting\n",
    "    first_val_loss = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Cache all training batches to randomly sample from them\n",
    "    train_batches = list(train_loader)\n",
    "\n",
    "    for iteration in range(1, num_iters + 1):\n",
    "        # === Randomly sample a batch from training set ===\n",
    "        input_batch, target_batch = random.choice(train_batches)\n",
    "        input_batch = input_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        # === Forward pass ===\n",
    "        output = model(input_batch, target_batch, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "\n",
    "        # === Reshape output and target for loss computation ===\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)      # Skip <sos>\n",
    "        target = target_batch[:, 1:].reshape(-1)\n",
    "\n",
    "        # === Compute loss and backpropagation ===\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_value = loss.item()\n",
    "        print_loss_total += loss_value\n",
    "        plot_loss_total += loss_value\n",
    "\n",
    "        # === Print training progress every 'print_every' iterations ===\n",
    "        if iteration % print_every == 0:\n",
    "            avg_loss = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"[Iter {iteration:05d}] ⏱ Time: {elapsed:.1f}s | Avg Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # === Validate and track performance every 'plot_every' iterations ===\n",
    "        if iteration % plot_every == 0:\n",
    "            val_loss_total = 0\n",
    "            model.eval()  # Set model to evaluation mode (e.g., disable dropout)\n",
    "            with torch.no_grad():  # Disable gradient tracking for validation\n",
    "                for val_input, val_target in val_loader:\n",
    "                    val_input = val_input.to(device)\n",
    "                    val_target = val_target.to(device)\n",
    "\n",
    "                    # In validation, use greedy decoding (no teacher forcing)\n",
    "                    val_output = model(val_input, val_target, teacher_forcing_ratio=0.0)\n",
    "                    val_output = val_output[:, 1:].reshape(-1, output_dim)\n",
    "                    val_target = val_target[:, 1:].reshape(-1)\n",
    "                    val_loss = criterion(val_output, val_target)\n",
    "                    val_loss_total += val_loss.item()\n",
    "\n",
    "            # Compute and store average validation loss\n",
    "            avg_val_loss = val_loss_total / len(val_loader)\n",
    "            train_losses.append(plot_loss_total / plot_every)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            print(f\"📉 Iter {iteration}: Val Loss = {avg_val_loss:.4f}\")\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    # === Save training and validation loss log to CSV ===\n",
    "    log_data = {\n",
    "        \"Iteration\": list(range(plot_every, plot_every * len(train_losses) + 1, plot_every)),\n",
    "        \"Training Loss\": train_losses,\n",
    "        \"Validation Loss\": val_losses\n",
    "    }\n",
    "    log_df = pd.DataFrame(log_data)\n",
    "    log_df.to_csv(log_filename, index=False)\n",
    "    print(f\"📁 Training log saved to {log_filename}\")\n",
    "\n",
    "    # === Plot training vs. validation loss ===\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(log_data[\"Iteration\"], train_losses, label='Training Loss')\n",
    "    plt.plot(log_data[\"Iteration\"], val_losses, label='Validation Loss')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(plot_title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae420b",
   "metadata": {},
   "source": [
    "#### Generating the Test Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c34cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recipe(model, src_tensor, trg_vocab, device, max_len=MAX_RECIPE_LEN, use_attention=False):\n",
    "    \"\"\"\n",
    "    Generates a recipe from a single input using either attention-based or vanilla seq2seq.\n",
    "\n",
    "    Args:\n",
    "        model: full seq2seq model or tuple (encoder, decoder)\n",
    "        src_tensor: tensor of shape (src_len,)\n",
    "        trg_vocab: target vocabulary (word to index)\n",
    "        device: torch device (cpu/cuda)\n",
    "        max_len: max length of the generated recipe\n",
    "        use_attention: set to True if using (encoder, decoder) attention-style models\n",
    "\n",
    "    Returns:\n",
    "        String of generated recipe text.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    trg_vocab_inv = {i: w for w, i in trg_vocab.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Add batch dimension: (1, src_len)\n",
    "        src_tensor = src_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "        if use_attention:\n",
    "            # Expecting (encoder, decoder) as a tuple\n",
    "            encoder, decoder = model\n",
    "            encoder_outputs, hidden = encoder(src_tensor)\n",
    "\n",
    "            input_token = torch.tensor([trg_vocab[SOS_TOKEN]], device=device)\n",
    "            result = []\n",
    "\n",
    "            for _ in range(max_len):\n",
    "                output, hidden, _ = decoder(input_token, hidden, encoder_outputs)\n",
    "                top1 = output.argmax(1).item()\n",
    "\n",
    "                if top1 == trg_vocab[EOS_TOKEN]:\n",
    "                    break\n",
    "                result.append(trg_vocab_inv.get(top1, UNK_TOKEN))\n",
    "                input_token = torch.tensor([top1], device=device)\n",
    "\n",
    "        else:\n",
    "            # Expecting model to be Seq2Seq class with internal encoder+decoder\n",
    "            dummy_trg = torch.zeros((1, max_len), dtype=torch.long, device=device)\n",
    "            output = model(src_tensor, dummy_trg, teacher_forcing_ratio=0.0)\n",
    "            pred_ids = output.argmax(2).squeeze(0).tolist()\n",
    "\n",
    "            result = []\n",
    "            for idx in pred_ids:\n",
    "                token = trg_vocab_inv.get(idx, UNK_TOKEN)\n",
    "                if token == EOS_TOKEN:\n",
    "                    break\n",
    "                if token not in [PAD_TOKEN, SOS_TOKEN]:\n",
    "                    result.append(token)\n",
    "\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a569737a",
   "metadata": {},
   "source": [
    "## The 2 Spicy Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589fbf9",
   "metadata": {},
   "source": [
    "### Coverage mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e7c63",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bba7e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Encoder for Coverage Model ===\n",
    "class EncoderRNNWithCoverage(nn.Module):\n",
    "    def __init__(self, input_size, emb_dim, hidden_dim, dropout=0.3):\n",
    "        super(EncoderRNNWithCoverage, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(input_size, emb_dim)\n",
    "        self.rnn = nn.RNN(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))  # (batch, seq_len, emb_dim)\n",
    "        outputs, hidden = self.rnn(embedded)           # (batch, seq_len, hidden_dim), (1, batch, hidden_dim)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "296efc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Decoder with Coverage Mechanism ===\n",
    "class CoverageDecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, emb_dim, hidden_dim, dropout=0.3):\n",
    "        super(CoverageDecoderRNN, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(output_size, emb_dim)\n",
    "        self.rnn = nn.RNN(emb_dim + hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.attn = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.coverage_attn = nn.Linear(1, 1)\n",
    "        self.out = nn.Linear(hidden_dim, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs, coverage_vector):\n",
    "        # input_step: (batch,)\n",
    "        embedded = self.embedding(input_step)        # (batch, emb_dim)\n",
    "        embedded = embedded.unsqueeze(1)             # → (batch, 1, emb_dim)\n",
    "        embedded = self.dropout(embedded)            # Apply dropout correctly\n",
    "\n",
    "        # === Coverage-Aware Attention ===\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        hidden_repeat = last_hidden.permute(1, 0, 2).repeat(1, seq_len, 1)  # (batch, seq_len, hidden_dim)\n",
    "        concat = torch.cat((hidden_repeat, encoder_outputs), dim=2)        # (batch, seq_len, hidden_dim*2)\n",
    "\n",
    "        coverage_input = coverage_vector.unsqueeze(2)                      # (batch, seq_len, 1)\n",
    "        energy = self.attn(concat).squeeze(2) + self.coverage_attn(coverage_input).squeeze(2)\n",
    "        attn_weights = F.softmax(energy, dim=1).unsqueeze(1)              # (batch, 1, seq_len)\n",
    "\n",
    "        context = torch.bmm(attn_weights, encoder_outputs)               # (batch, 1, hidden_dim)\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)                # (batch, 1, emb_dim + hidden_dim)\n",
    "\n",
    "        output, hidden = self.rnn(rnn_input, last_hidden)                # (batch, 1, hidden_dim)\n",
    "        output = self.out(output.squeeze(1))                             # (batch, output_size)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "\n",
    "        return output, hidden, attn_weights.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "462090ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqCoverageModel(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2SeqCoverageModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        output_dim = self.decoder.output_size\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, output_dim).to(self.device)\n",
    "\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        coverage = torch.zeros(src.size(0), encoder_outputs.size(1), device=src.device)  # ✅ (batch, seq_len)\n",
    "\n",
    "        input_token = trg[:, 0]  # <sos>\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, attn_weights = self.decoder(input_token, hidden, encoder_outputs, coverage)\n",
    "            outputs[:, t] = output\n",
    "\n",
    "            # Update coverage vector\n",
    "            coverage = coverage + attn_weights.detach()\n",
    "\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input_token = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2acce7d",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddfad17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_coverage(model, train_loader, val_loader, optimizer, criterion, output_vocab, device,\n",
    "                               num_iters, print_every, plot_every,\n",
    "                               teacher_forcing_ratio=0.5,\n",
    "                               log_filename=\"coverage_training_log.csv\",\n",
    "                               plot_title=\"Coverage Model Training and Validation Loss\"):\n",
    "    \"\"\"\n",
    "    Trains a Seq2Seq model (with coverage mechanism) using random batches.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_batches = list(train_loader)  # Cache to sample randomly\n",
    "\n",
    "    for iteration in range(1, num_iters + 1):\n",
    "        input_batch, target_batch = random.choice(train_batches)\n",
    "        input_batch = input_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Coverage model forward (assumes model handles coverage internally)\n",
    "        output = model(input_batch, target_batch, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        target = target_batch[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_value = loss.item()\n",
    "        print_loss_total += loss_value\n",
    "        plot_loss_total += loss_value\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            avg_loss = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"[Iter {iteration:05d}] ⏱ Time: {elapsed:.1f}s | Avg Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        if iteration % plot_every == 0:\n",
    "            val_loss_total = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_input, val_target in val_loader:\n",
    "                    val_input = val_input.to(device)\n",
    "                    val_target = val_target.to(device)\n",
    "\n",
    "                    val_output = model(val_input, val_target, teacher_forcing_ratio=0.0)\n",
    "                    val_output = val_output[:, 1:].reshape(-1, output_dim)\n",
    "                    val_target = val_target[:, 1:].reshape(-1)\n",
    "\n",
    "                    val_loss = criterion(val_output, val_target)\n",
    "                    val_loss_total += val_loss.item()\n",
    "\n",
    "            avg_val_loss = val_loss_total / len(val_loader)\n",
    "            train_losses.append(plot_loss_total / plot_every)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            print(f\"📉 Iter {iteration}: Val Loss = {avg_val_loss:.4f}\")\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    # Save log\n",
    "    log_data = {\n",
    "        \"Iteration\": list(range(plot_every, plot_every * len(train_losses) + 1, plot_every)),\n",
    "        \"Training Loss\": train_losses,\n",
    "        \"Validation Loss\": val_losses\n",
    "    }\n",
    "    log_df = pd.DataFrame(log_data)\n",
    "    log_df.to_csv(log_filename, index=False)\n",
    "    print(f\"📁 Training log saved to {log_filename}\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(log_data[\"Iteration\"], train_losses, label='Training Loss')\n",
    "    plt.plot(log_data[\"Iteration\"], val_losses, label='Validation Loss')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(plot_title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a90b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recipe_Coverage(model, src_tensor, trg_vocab, device, max_len=MAX_RECIPE_LEN):\n",
    "    \"\"\"\n",
    "    Generates a recipe from a single input using a coverage-aware Seq2Seq model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained Seq2Seq model (with internal attention or coverage if applicable).\n",
    "        src_tensor: Input tensor of shape (seq_len,) or (1, seq_len).\n",
    "        trg_vocab: Output vocabulary (word to index).\n",
    "        device: PyTorch device ('cuda' or 'cpu').\n",
    "        max_len: Maximum length of the generated recipe.\n",
    "\n",
    "    Returns:\n",
    "        Generated recipe string.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    trg_vocab_inv = {i: w for w, i in trg_vocab.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Add batch dimension if needed\n",
    "        if src_tensor.dim() == 1:\n",
    "            src_tensor = src_tensor.unsqueeze(0)  # (1, seq_len)\n",
    "\n",
    "        src_tensor = src_tensor.to(device)\n",
    "        dummy_trg = torch.zeros((1, max_len), dtype=torch.long, device=device)  # Fake target\n",
    "\n",
    "        # Generate using greedy decoding\n",
    "        output = model(src_tensor, dummy_trg, teacher_forcing_ratio=0.0)  # (1, max_len, vocab_size)\n",
    "        pred_ids = output.argmax(2).squeeze(0).tolist()  # Remove batch dim\n",
    "\n",
    "        result = []\n",
    "        for idx in pred_ids:\n",
    "            token = trg_vocab_inv.get(idx, UNK_TOKEN)\n",
    "            if token == EOS_TOKEN:\n",
    "                break\n",
    "            if token not in [PAD_TOKEN, SOS_TOKEN]:\n",
    "                result.append(token)\n",
    "\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d914a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 00050] ⏱ Time: 23.0s | Avg Train Loss: 8.9924\n",
      "📉 Iter 50: Val Loss = 7.7548\n",
      "[Iter 00100] ⏱ Time: 75.8s | Avg Train Loss: 6.9235\n",
      "📉 Iter 100: Val Loss = 6.2709\n",
      "[Iter 00150] ⏱ Time: 129.9s | Avg Train Loss: 6.1991\n",
      "📉 Iter 150: Val Loss = 6.0399\n",
      "[Iter 00200] ⏱ Time: 184.9s | Avg Train Loss: 6.0755\n",
      "📉 Iter 200: Val Loss = 5.9906\n",
      "[Iter 00250] ⏱ Time: 239.8s | Avg Train Loss: 6.0692\n",
      "📉 Iter 250: Val Loss = 5.9698\n",
      "[Iter 00300] ⏱ Time: 294.7s | Avg Train Loss: 6.0527\n",
      "📉 Iter 300: Val Loss = 5.9571\n",
      "[Iter 00350] ⏱ Time: 347.9s | Avg Train Loss: 6.0246\n",
      "📉 Iter 350: Val Loss = 5.9400\n",
      "[Iter 00400] ⏱ Time: 404.5s | Avg Train Loss: 6.0231\n",
      "📉 Iter 400: Val Loss = 5.9308\n",
      "[Iter 00450] ⏱ Time: 461.1s | Avg Train Loss: 6.0336\n",
      "📉 Iter 450: Val Loss = 5.9254\n",
      "[Iter 00500] ⏱ Time: 518.1s | Avg Train Loss: 6.0126\n",
      "📉 Iter 500: Val Loss = 5.9214\n",
      "[Iter 00550] ⏱ Time: 575.0s | Avg Train Loss: 6.0250\n",
      "📉 Iter 550: Val Loss = 5.9107\n",
      "[Iter 00600] ⏱ Time: 632.9s | Avg Train Loss: 5.9871\n",
      "📉 Iter 600: Val Loss = 5.9075\n",
      "[Iter 00650] ⏱ Time: 687.4s | Avg Train Loss: 6.0076\n",
      "📉 Iter 650: Val Loss = 5.9053\n",
      "[Iter 00700] ⏱ Time: 743.6s | Avg Train Loss: 5.9985\n",
      "📉 Iter 700: Val Loss = 5.8966\n",
      "[Iter 00750] ⏱ Time: 798.6s | Avg Train Loss: 5.9973\n",
      "📉 Iter 750: Val Loss = 5.8902\n",
      "[Iter 00800] ⏱ Time: 851.8s | Avg Train Loss: 5.9843\n",
      "📉 Iter 800: Val Loss = 5.8869\n",
      "[Iter 00850] ⏱ Time: 905.2s | Avg Train Loss: 5.9916\n",
      "📉 Iter 850: Val Loss = 5.8804\n",
      "[Iter 00900] ⏱ Time: 958.2s | Avg Train Loss: 5.9826\n",
      "📉 Iter 900: Val Loss = 5.8754\n",
      "[Iter 00950] ⏱ Time: 1013.9s | Avg Train Loss: 5.9625\n",
      "📉 Iter 950: Val Loss = 5.8723\n",
      "[Iter 01000] ⏱ Time: 1066.9s | Avg Train Loss: 5.9683\n",
      "📉 Iter 1000: Val Loss = 5.8698\n",
      "[Iter 01050] ⏱ Time: 1120.3s | Avg Train Loss: 5.9594\n",
      "📉 Iter 1050: Val Loss = 5.8687\n",
      "[Iter 01100] ⏱ Time: 1173.4s | Avg Train Loss: 5.9465\n",
      "📉 Iter 1100: Val Loss = 5.8658\n",
      "[Iter 01150] ⏱ Time: 1226.5s | Avg Train Loss: 5.9465\n",
      "📉 Iter 1150: Val Loss = 5.8658\n",
      "[Iter 01200] ⏱ Time: 1279.7s | Avg Train Loss: 5.9356\n",
      "📉 Iter 1200: Val Loss = 5.8910\n",
      "[Iter 01250] ⏱ Time: 1333.1s | Avg Train Loss: 5.9329\n",
      "📉 Iter 1250: Val Loss = 5.8938\n",
      "[Iter 01300] ⏱ Time: 1386.2s | Avg Train Loss: 5.9290\n",
      "📉 Iter 1300: Val Loss = 5.8928\n",
      "[Iter 01350] ⏱ Time: 1439.5s | Avg Train Loss: 5.9156\n",
      "📉 Iter 1350: Val Loss = 5.8811\n",
      "[Iter 01400] ⏱ Time: 1492.8s | Avg Train Loss: 5.9075\n",
      "📉 Iter 1400: Val Loss = 5.8736\n",
      "[Iter 01450] ⏱ Time: 1546.3s | Avg Train Loss: 5.9001\n",
      "📉 Iter 1450: Val Loss = 5.8811\n",
      "[Iter 01500] ⏱ Time: 1599.4s | Avg Train Loss: 5.9165\n",
      "📉 Iter 1500: Val Loss = 5.8709\n",
      "[Iter 01550] ⏱ Time: 1653.4s | Avg Train Loss: 5.8869\n",
      "📉 Iter 1550: Val Loss = 5.8732\n",
      "[Iter 01600] ⏱ Time: 1706.5s | Avg Train Loss: 5.9027\n",
      "📉 Iter 1600: Val Loss = 5.8743\n",
      "[Iter 01650] ⏱ Time: 1759.7s | Avg Train Loss: 5.8721\n",
      "📉 Iter 1650: Val Loss = 5.8669\n",
      "[Iter 01700] ⏱ Time: 1812.5s | Avg Train Loss: 5.8792\n",
      "📉 Iter 1700: Val Loss = 5.8571\n",
      "[Iter 01750] ⏱ Time: 1865.1s | Avg Train Loss: 5.8846\n",
      "📉 Iter 1750: Val Loss = 5.8333\n",
      "[Iter 01800] ⏱ Time: 1918.6s | Avg Train Loss: 5.8390\n",
      "📉 Iter 1800: Val Loss = 5.8710\n",
      "[Iter 01850] ⏱ Time: 1971.1s | Avg Train Loss: 5.8542\n",
      "📉 Iter 1850: Val Loss = 5.8574\n",
      "[Iter 01900] ⏱ Time: 2023.9s | Avg Train Loss: 5.8241\n",
      "📉 Iter 1900: Val Loss = 5.8600\n",
      "[Iter 01950] ⏱ Time: 2076.5s | Avg Train Loss: 5.8162\n",
      "📉 Iter 1950: Val Loss = 5.8317\n",
      "[Iter 02000] ⏱ Time: 2129.3s | Avg Train Loss: 5.8156\n",
      "📉 Iter 2000: Val Loss = 5.8524\n",
      "[Iter 02050] ⏱ Time: 2182.3s | Avg Train Loss: 5.7860\n",
      "📉 Iter 2050: Val Loss = 5.8218\n",
      "[Iter 02100] ⏱ Time: 2235.2s | Avg Train Loss: 5.7939\n",
      "📉 Iter 2100: Val Loss = 5.8219\n",
      "[Iter 02150] ⏱ Time: 2288.4s | Avg Train Loss: 5.7595\n",
      "📉 Iter 2150: Val Loss = 5.8197\n",
      "[Iter 02200] ⏱ Time: 2342.2s | Avg Train Loss: 5.7653\n",
      "📉 Iter 2200: Val Loss = 5.8080\n",
      "[Iter 02250] ⏱ Time: 2395.7s | Avg Train Loss: 5.7513\n",
      "📉 Iter 2250: Val Loss = 5.7837\n",
      "[Iter 02300] ⏱ Time: 2449.3s | Avg Train Loss: 5.7331\n",
      "📉 Iter 2300: Val Loss = 5.7574\n",
      "[Iter 02350] ⏱ Time: 2503.2s | Avg Train Loss: 5.7027\n",
      "📉 Iter 2350: Val Loss = 5.7852\n",
      "[Iter 02400] ⏱ Time: 2556.1s | Avg Train Loss: 5.7012\n",
      "📉 Iter 2400: Val Loss = 5.7667\n",
      "[Iter 02450] ⏱ Time: 2609.1s | Avg Train Loss: 5.6817\n",
      "📉 Iter 2450: Val Loss = 5.7614\n",
      "[Iter 02500] ⏱ Time: 2662.1s | Avg Train Loss: 5.6655\n",
      "📉 Iter 2500: Val Loss = 5.7459\n",
      "[Iter 02550] ⏱ Time: 2715.5s | Avg Train Loss: 5.6547\n",
      "📉 Iter 2550: Val Loss = 5.7123\n",
      "[Iter 02600] ⏱ Time: 2768.8s | Avg Train Loss: 5.6420\n",
      "📉 Iter 2600: Val Loss = 5.7275\n",
      "[Iter 02650] ⏱ Time: 2822.0s | Avg Train Loss: 5.6157\n",
      "📉 Iter 2650: Val Loss = 5.7224\n",
      "[Iter 02700] ⏱ Time: 2875.1s | Avg Train Loss: 5.6256\n",
      "📉 Iter 2700: Val Loss = 5.7153\n",
      "[Iter 02750] ⏱ Time: 2928.4s | Avg Train Loss: 5.6210\n",
      "📉 Iter 2750: Val Loss = 5.7124\n",
      "[Iter 02800] ⏱ Time: 2982.5s | Avg Train Loss: 5.5811\n",
      "📉 Iter 2800: Val Loss = 5.7214\n",
      "[Iter 02850] ⏱ Time: 3035.7s | Avg Train Loss: 5.5806\n",
      "📉 Iter 2850: Val Loss = 5.7135\n",
      "[Iter 02900] ⏱ Time: 3089.2s | Avg Train Loss: 5.5787\n",
      "📉 Iter 2900: Val Loss = 5.6809\n",
      "[Iter 02950] ⏱ Time: 3142.0s | Avg Train Loss: 5.5692\n",
      "📉 Iter 2950: Val Loss = 5.7103\n",
      "[Iter 03000] ⏱ Time: 3194.8s | Avg Train Loss: 5.5799\n",
      "📉 Iter 3000: Val Loss = 5.6846\n",
      "[Iter 03050] ⏱ Time: 3247.6s | Avg Train Loss: 5.5533\n",
      "📉 Iter 3050: Val Loss = 5.6838\n",
      "[Iter 03100] ⏱ Time: 3300.4s | Avg Train Loss: 5.5249\n",
      "📉 Iter 3100: Val Loss = 5.6751\n",
      "[Iter 03150] ⏱ Time: 3353.3s | Avg Train Loss: 5.5311\n",
      "📉 Iter 3150: Val Loss = 5.6648\n",
      "[Iter 03200] ⏱ Time: 3406.2s | Avg Train Loss: 5.5104\n",
      "📉 Iter 3200: Val Loss = 5.6731\n",
      "[Iter 03250] ⏱ Time: 3459.7s | Avg Train Loss: 5.5320\n",
      "📉 Iter 3250: Val Loss = 5.6728\n",
      "[Iter 03300] ⏱ Time: 3513.8s | Avg Train Loss: 5.4935\n",
      "📉 Iter 3300: Val Loss = 5.6928\n",
      "[Iter 03350] ⏱ Time: 3568.4s | Avg Train Loss: 5.4850\n",
      "📉 Iter 3350: Val Loss = 5.6934\n",
      "[Iter 03400] ⏱ Time: 3622.1s | Avg Train Loss: 5.4964\n",
      "📉 Iter 3400: Val Loss = 5.6724\n",
      "[Iter 03450] ⏱ Time: 3677.2s | Avg Train Loss: 5.4916\n",
      "📉 Iter 3450: Val Loss = 5.6628\n",
      "[Iter 03500] ⏱ Time: 3730.7s | Avg Train Loss: 5.4930\n",
      "📉 Iter 3500: Val Loss = 5.6551\n",
      "[Iter 03550] ⏱ Time: 3786.3s | Avg Train Loss: 5.4525\n",
      "📉 Iter 3550: Val Loss = 5.6588\n",
      "[Iter 03600] ⏱ Time: 3840.6s | Avg Train Loss: 5.4650\n",
      "📉 Iter 3600: Val Loss = 5.6724\n",
      "[Iter 03650] ⏱ Time: 3893.1s | Avg Train Loss: 5.4339\n",
      "📉 Iter 3650: Val Loss = 5.6625\n",
      "[Iter 03700] ⏱ Time: 3946.9s | Avg Train Loss: 5.4378\n",
      "📉 Iter 3700: Val Loss = 5.6582\n",
      "[Iter 03750] ⏱ Time: 4001.7s | Avg Train Loss: 5.4372\n",
      "📉 Iter 3750: Val Loss = 5.6508\n",
      "[Iter 03800] ⏱ Time: 4057.4s | Avg Train Loss: 5.4383\n",
      "📉 Iter 3800: Val Loss = 5.6717\n",
      "[Iter 03850] ⏱ Time: 4111.2s | Avg Train Loss: 5.4332\n",
      "📉 Iter 3850: Val Loss = 5.6728\n",
      "[Iter 03900] ⏱ Time: 4163.3s | Avg Train Loss: 5.3950\n",
      "📉 Iter 3900: Val Loss = 5.6929\n",
      "[Iter 03950] ⏱ Time: 4217.0s | Avg Train Loss: 5.4171\n",
      "📉 Iter 3950: Val Loss = 5.6612\n",
      "[Iter 04000] ⏱ Time: 4271.3s | Avg Train Loss: 5.4161\n",
      "📉 Iter 4000: Val Loss = 5.6774\n",
      "[Iter 04050] ⏱ Time: 4325.3s | Avg Train Loss: 5.3895\n",
      "📉 Iter 4050: Val Loss = 5.6618\n",
      "[Iter 04100] ⏱ Time: 4378.7s | Avg Train Loss: 5.3970\n",
      "📉 Iter 4100: Val Loss = 5.6548\n",
      "[Iter 04150] ⏱ Time: 4432.4s | Avg Train Loss: 5.3912\n",
      "📉 Iter 4150: Val Loss = 5.6478\n",
      "[Iter 04200] ⏱ Time: 4485.6s | Avg Train Loss: 5.4070\n",
      "📉 Iter 4200: Val Loss = 5.6357\n",
      "[Iter 04250] ⏱ Time: 4538.3s | Avg Train Loss: 5.3668\n",
      "📉 Iter 4250: Val Loss = 5.6483\n",
      "[Iter 04300] ⏱ Time: 4592.2s | Avg Train Loss: 5.3795\n",
      "📉 Iter 4300: Val Loss = 5.6397\n",
      "[Iter 04350] ⏱ Time: 4645.6s | Avg Train Loss: 5.3401\n",
      "📉 Iter 4350: Val Loss = 5.6524\n",
      "[Iter 04400] ⏱ Time: 4698.7s | Avg Train Loss: 5.3529\n",
      "📉 Iter 4400: Val Loss = 5.6482\n",
      "[Iter 04450] ⏱ Time: 4751.9s | Avg Train Loss: 5.3577\n",
      "📉 Iter 4450: Val Loss = 5.6648\n",
      "[Iter 04500] ⏱ Time: 4804.8s | Avg Train Loss: 5.3645\n",
      "📉 Iter 4500: Val Loss = 5.6637\n",
      "[Iter 04550] ⏱ Time: 4858.9s | Avg Train Loss: 5.3366\n",
      "📉 Iter 4550: Val Loss = 5.6617\n",
      "[Iter 04600] ⏱ Time: 4912.3s | Avg Train Loss: 5.3521\n",
      "📉 Iter 4600: Val Loss = 5.6565\n",
      "[Iter 04650] ⏱ Time: 4965.4s | Avg Train Loss: 5.3216\n",
      "📉 Iter 4650: Val Loss = 5.6482\n",
      "[Iter 04700] ⏱ Time: 5018.2s | Avg Train Loss: 5.3484\n",
      "📉 Iter 4700: Val Loss = 5.6502\n",
      "[Iter 04750] ⏱ Time: 5071.3s | Avg Train Loss: 5.3304\n",
      "📉 Iter 4750: Val Loss = 5.6389\n",
      "[Iter 04800] ⏱ Time: 5126.5s | Avg Train Loss: 5.3056\n",
      "📉 Iter 4800: Val Loss = 5.6461\n",
      "[Iter 04850] ⏱ Time: 5181.6s | Avg Train Loss: 5.3118\n",
      "📉 Iter 4850: Val Loss = 5.6330\n",
      "[Iter 04900] ⏱ Time: 5235.7s | Avg Train Loss: 5.3206\n",
      "📉 Iter 4900: Val Loss = 5.6494\n",
      "[Iter 04950] ⏱ Time: 5289.4s | Avg Train Loss: 5.3395\n",
      "📉 Iter 4950: Val Loss = 5.6387\n",
      "[Iter 05000] ⏱ Time: 5342.2s | Avg Train Loss: 5.2772\n",
      "📉 Iter 5000: Val Loss = 5.6273\n",
      "[Iter 05050] ⏱ Time: 5395.0s | Avg Train Loss: 5.2975\n",
      "📉 Iter 5050: Val Loss = 5.6436\n",
      "[Iter 05100] ⏱ Time: 5472.5s | Avg Train Loss: 5.3044\n",
      "📉 Iter 5100: Val Loss = 5.6271\n",
      "[Iter 05150] ⏱ Time: 5526.2s | Avg Train Loss: 5.3183\n",
      "📉 Iter 5150: Val Loss = 5.6263\n",
      "[Iter 05200] ⏱ Time: 5579.5s | Avg Train Loss: 5.3022\n",
      "📉 Iter 5200: Val Loss = 5.6243\n",
      "[Iter 05250] ⏱ Time: 5632.9s | Avg Train Loss: 5.2666\n",
      "📉 Iter 5250: Val Loss = 5.6173\n",
      "[Iter 05300] ⏱ Time: 5685.9s | Avg Train Loss: 5.2920\n",
      "📉 Iter 5300: Val Loss = 5.6387\n",
      "[Iter 05350] ⏱ Time: 5738.8s | Avg Train Loss: 5.2708\n",
      "📉 Iter 5350: Val Loss = 5.6217\n",
      "[Iter 05400] ⏱ Time: 5792.0s | Avg Train Loss: 5.2600\n",
      "📉 Iter 5400: Val Loss = 5.6204\n",
      "[Iter 05450] ⏱ Time: 5845.3s | Avg Train Loss: 5.2700\n",
      "📉 Iter 5450: Val Loss = 5.6338\n",
      "[Iter 05500] ⏱ Time: 5898.8s | Avg Train Loss: 5.2456\n",
      "📉 Iter 5500: Val Loss = 5.6144\n",
      "[Iter 05550] ⏱ Time: 5952.8s | Avg Train Loss: 5.2468\n",
      "📉 Iter 5550: Val Loss = 5.6180\n",
      "[Iter 05600] ⏱ Time: 6006.0s | Avg Train Loss: 5.2508\n",
      "📉 Iter 5600: Val Loss = 5.6135\n",
      "[Iter 05650] ⏱ Time: 6060.3s | Avg Train Loss: 5.2386\n",
      "📉 Iter 5650: Val Loss = 5.6194\n",
      "[Iter 05700] ⏱ Time: 6113.6s | Avg Train Loss: 5.2400\n",
      "📉 Iter 5700: Val Loss = 5.5991\n",
      "[Iter 05750] ⏱ Time: 6166.8s | Avg Train Loss: 5.2132\n",
      "📉 Iter 5750: Val Loss = 5.6188\n",
      "[Iter 05800] ⏱ Time: 6220.8s | Avg Train Loss: 5.2376\n",
      "📉 Iter 5800: Val Loss = 5.6106\n",
      "[Iter 05850] ⏱ Time: 6273.8s | Avg Train Loss: 5.2453\n",
      "📉 Iter 5850: Val Loss = 5.6044\n",
      "[Iter 05900] ⏱ Time: 6327.6s | Avg Train Loss: 5.2140\n",
      "📉 Iter 5900: Val Loss = 5.6033\n",
      "[Iter 05950] ⏱ Time: 6381.3s | Avg Train Loss: 5.2201\n",
      "📉 Iter 5950: Val Loss = 5.5964\n",
      "[Iter 06000] ⏱ Time: 6434.4s | Avg Train Loss: 5.2042\n",
      "📉 Iter 6000: Val Loss = 5.5984\n",
      "[Iter 06050] ⏱ Time: 6487.8s | Avg Train Loss: 5.1969\n",
      "📉 Iter 6050: Val Loss = 5.6188\n",
      "[Iter 06100] ⏱ Time: 6540.7s | Avg Train Loss: 5.1875\n",
      "📉 Iter 6100: Val Loss = 5.5979\n",
      "[Iter 06150] ⏱ Time: 6594.5s | Avg Train Loss: 5.1976\n",
      "📉 Iter 6150: Val Loss = 5.6001\n",
      "[Iter 06200] ⏱ Time: 6647.6s | Avg Train Loss: 5.1921\n",
      "📉 Iter 6200: Val Loss = 5.5935\n",
      "[Iter 06250] ⏱ Time: 6700.6s | Avg Train Loss: 5.2094\n",
      "📉 Iter 6250: Val Loss = 5.6034\n",
      "[Iter 06300] ⏱ Time: 6753.4s | Avg Train Loss: 5.2103\n",
      "📉 Iter 6300: Val Loss = 5.5774\n",
      "[Iter 06350] ⏱ Time: 6806.4s | Avg Train Loss: 5.1843\n",
      "📉 Iter 6350: Val Loss = 5.5886\n",
      "[Iter 06400] ⏱ Time: 6859.6s | Avg Train Loss: 5.1763\n",
      "📉 Iter 6400: Val Loss = 5.6047\n",
      "[Iter 06450] ⏱ Time: 6913.2s | Avg Train Loss: 5.1708\n",
      "📉 Iter 6450: Val Loss = 5.5805\n",
      "[Iter 06500] ⏱ Time: 6966.1s | Avg Train Loss: 5.1417\n",
      "📉 Iter 6500: Val Loss = 5.5962\n",
      "[Iter 06550] ⏱ Time: 7019.1s | Avg Train Loss: 5.1555\n",
      "📉 Iter 6550: Val Loss = 5.6044\n",
      "[Iter 06600] ⏱ Time: 7072.0s | Avg Train Loss: 5.1693\n",
      "📉 Iter 6600: Val Loss = 5.6070\n",
      "[Iter 06650] ⏱ Time: 7124.8s | Avg Train Loss: 5.1772\n",
      "📉 Iter 6650: Val Loss = 5.6082\n",
      "[Iter 06700] ⏱ Time: 7178.0s | Avg Train Loss: 5.1549\n",
      "📉 Iter 6700: Val Loss = 5.5755\n",
      "[Iter 06750] ⏱ Time: 7231.2s | Avg Train Loss: 5.1747\n",
      "📉 Iter 6750: Val Loss = 5.5697\n",
      "[Iter 06800] ⏱ Time: 7284.7s | Avg Train Loss: 5.1130\n",
      "📉 Iter 6800: Val Loss = 5.5834\n",
      "[Iter 06850] ⏱ Time: 7338.2s | Avg Train Loss: 5.1676\n",
      "📉 Iter 6850: Val Loss = 5.5848\n",
      "[Iter 06900] ⏱ Time: 7391.5s | Avg Train Loss: 5.1371\n",
      "📉 Iter 6900: Val Loss = 5.5854\n",
      "[Iter 06950] ⏱ Time: 7444.3s | Avg Train Loss: 5.1430\n",
      "📉 Iter 6950: Val Loss = 5.5811\n",
      "[Iter 07000] ⏱ Time: 7497.2s | Avg Train Loss: 5.1575\n",
      "📉 Iter 7000: Val Loss = 5.5975\n",
      "[Iter 07050] ⏱ Time: 7550.3s | Avg Train Loss: 5.1230\n",
      "📉 Iter 7050: Val Loss = 5.5830\n",
      "[Iter 07100] ⏱ Time: 7603.7s | Avg Train Loss: 5.1298\n",
      "📉 Iter 7100: Val Loss = 5.5781\n",
      "[Iter 07150] ⏱ Time: 7656.8s | Avg Train Loss: 5.1441\n",
      "📉 Iter 7150: Val Loss = 5.5639\n",
      "[Iter 07200] ⏱ Time: 7709.7s | Avg Train Loss: 5.1339\n",
      "📉 Iter 7200: Val Loss = 5.5717\n",
      "[Iter 07250] ⏱ Time: 7762.8s | Avg Train Loss: 5.1362\n",
      "📉 Iter 7250: Val Loss = 5.5809\n",
      "[Iter 07300] ⏱ Time: 7815.7s | Avg Train Loss: 5.1121\n",
      "📉 Iter 7300: Val Loss = 5.5681\n",
      "[Iter 07350] ⏱ Time: 7868.5s | Avg Train Loss: 5.1463\n",
      "📉 Iter 7350: Val Loss = 5.5712\n",
      "[Iter 07400] ⏱ Time: 7921.6s | Avg Train Loss: 5.1096\n",
      "📉 Iter 7400: Val Loss = 5.5705\n",
      "[Iter 07450] ⏱ Time: 7974.9s | Avg Train Loss: 5.1069\n",
      "📉 Iter 7450: Val Loss = 5.5626\n",
      "[Iter 07500] ⏱ Time: 8027.7s | Avg Train Loss: 5.0980\n",
      "📉 Iter 7500: Val Loss = 5.5814\n",
      "[Iter 07550] ⏱ Time: 8080.3s | Avg Train Loss: 5.1215\n",
      "📉 Iter 7550: Val Loss = 5.5822\n",
      "[Iter 07600] ⏱ Time: 8133.0s | Avg Train Loss: 5.0697\n",
      "📉 Iter 7600: Val Loss = 5.5866\n",
      "[Iter 07650] ⏱ Time: 8185.9s | Avg Train Loss: 5.0762\n",
      "📉 Iter 7650: Val Loss = 5.5780\n",
      "[Iter 07700] ⏱ Time: 8238.7s | Avg Train Loss: 5.1136\n",
      "📉 Iter 7700: Val Loss = 5.5810\n",
      "[Iter 07750] ⏱ Time: 8291.4s | Avg Train Loss: 5.0783\n",
      "📉 Iter 7750: Val Loss = 5.5916\n",
      "[Iter 07800] ⏱ Time: 8344.7s | Avg Train Loss: 5.0815\n",
      "📉 Iter 7800: Val Loss = 5.5949\n",
      "[Iter 07850] ⏱ Time: 8397.5s | Avg Train Loss: 5.0803\n",
      "📉 Iter 7850: Val Loss = 5.5600\n",
      "[Iter 07900] ⏱ Time: 8450.2s | Avg Train Loss: 5.0917\n",
      "📉 Iter 7900: Val Loss = 5.5691\n",
      "[Iter 07950] ⏱ Time: 8503.2s | Avg Train Loss: 5.0861\n",
      "📉 Iter 7950: Val Loss = 5.5620\n",
      "[Iter 08000] ⏱ Time: 8556.0s | Avg Train Loss: 5.1025\n",
      "📉 Iter 8000: Val Loss = 5.5813\n",
      "[Iter 08050] ⏱ Time: 8608.7s | Avg Train Loss: 5.0809\n",
      "📉 Iter 8050: Val Loss = 5.5743\n",
      "[Iter 08100] ⏱ Time: 8661.6s | Avg Train Loss: 5.0616\n",
      "📉 Iter 8100: Val Loss = 5.5792\n",
      "[Iter 08150] ⏱ Time: 8715.0s | Avg Train Loss: 5.0878\n",
      "📉 Iter 8150: Val Loss = 5.5624\n",
      "[Iter 08200] ⏱ Time: 8767.7s | Avg Train Loss: 5.0788\n",
      "📉 Iter 8200: Val Loss = 5.5668\n",
      "[Iter 08250] ⏱ Time: 8820.6s | Avg Train Loss: 5.0685\n",
      "📉 Iter 8250: Val Loss = 5.5723\n",
      "[Iter 08300] ⏱ Time: 8873.4s | Avg Train Loss: 5.0666\n",
      "📉 Iter 8300: Val Loss = 5.5638\n",
      "[Iter 08350] ⏱ Time: 8926.2s | Avg Train Loss: 5.0518\n",
      "📉 Iter 8350: Val Loss = 5.5828\n",
      "[Iter 08400] ⏱ Time: 8979.2s | Avg Train Loss: 5.0451\n",
      "📉 Iter 8400: Val Loss = 5.5590\n",
      "[Iter 08450] ⏱ Time: 9032.1s | Avg Train Loss: 5.0954\n",
      "📉 Iter 8450: Val Loss = 5.5773\n",
      "[Iter 08500] ⏱ Time: 9085.6s | Avg Train Loss: 5.0423\n",
      "📉 Iter 8500: Val Loss = 5.5584\n",
      "[Iter 08550] ⏱ Time: 9139.2s | Avg Train Loss: 5.0332\n",
      "📉 Iter 8550: Val Loss = 5.5726\n",
      "[Iter 08600] ⏱ Time: 9192.1s | Avg Train Loss: 5.0658\n",
      "📉 Iter 8600: Val Loss = 5.5706\n",
      "[Iter 08650] ⏱ Time: 9244.5s | Avg Train Loss: 5.0627\n",
      "📉 Iter 8650: Val Loss = 5.5638\n",
      "[Iter 08700] ⏱ Time: 9297.0s | Avg Train Loss: 5.0654\n",
      "📉 Iter 8700: Val Loss = 5.5726\n",
      "[Iter 08750] ⏱ Time: 9349.5s | Avg Train Loss: 5.0465\n",
      "📉 Iter 8750: Val Loss = 5.5477\n",
      "[Iter 08800] ⏱ Time: 9402.2s | Avg Train Loss: 5.0110\n",
      "📉 Iter 8800: Val Loss = 5.5717\n",
      "[Iter 08850] ⏱ Time: 9455.4s | Avg Train Loss: 5.0532\n",
      "📉 Iter 8850: Val Loss = 5.5764\n",
      "[Iter 08900] ⏱ Time: 9508.0s | Avg Train Loss: 5.0347\n",
      "📉 Iter 8900: Val Loss = 5.5695\n",
      "[Iter 08950] ⏱ Time: 9560.8s | Avg Train Loss: 5.0374\n",
      "📉 Iter 8950: Val Loss = 5.5661\n",
      "[Iter 09000] ⏱ Time: 9613.7s | Avg Train Loss: 5.0754\n",
      "📉 Iter 9000: Val Loss = 5.5778\n",
      "[Iter 09050] ⏱ Time: 9666.6s | Avg Train Loss: 5.0275\n",
      "📉 Iter 9050: Val Loss = 5.5599\n",
      "[Iter 09100] ⏱ Time: 9719.5s | Avg Train Loss: 5.0163\n",
      "📉 Iter 9100: Val Loss = 5.5802\n",
      "[Iter 09150] ⏱ Time: 9772.5s | Avg Train Loss: 5.0171\n",
      "📉 Iter 9150: Val Loss = 5.5763\n",
      "[Iter 09200] ⏱ Time: 9825.9s | Avg Train Loss: 5.0247\n",
      "📉 Iter 9200: Val Loss = 5.5896\n",
      "[Iter 09250] ⏱ Time: 9878.9s | Avg Train Loss: 5.0097\n",
      "📉 Iter 9250: Val Loss = 5.5773\n",
      "[Iter 09300] ⏱ Time: 9931.9s | Avg Train Loss: 5.0350\n",
      "📉 Iter 9300: Val Loss = 5.5586\n",
      "[Iter 09350] ⏱ Time: 9984.8s | Avg Train Loss: 5.0011\n",
      "📉 Iter 9350: Val Loss = 5.5682\n",
      "[Iter 09400] ⏱ Time: 10037.7s | Avg Train Loss: 4.9881\n",
      "📉 Iter 9400: Val Loss = 5.5571\n",
      "[Iter 09450] ⏱ Time: 10090.5s | Avg Train Loss: 5.0129\n",
      "📉 Iter 9450: Val Loss = 5.5804\n",
      "[Iter 09500] ⏱ Time: 10143.5s | Avg Train Loss: 5.0805\n",
      "📉 Iter 9500: Val Loss = 5.5724\n",
      "[Iter 09550] ⏱ Time: 10197.0s | Avg Train Loss: 4.9908\n",
      "📉 Iter 9550: Val Loss = 5.5751\n",
      "[Iter 09600] ⏱ Time: 10249.8s | Avg Train Loss: 5.0330\n",
      "📉 Iter 9600: Val Loss = 5.5561\n",
      "[Iter 09650] ⏱ Time: 10302.7s | Avg Train Loss: 4.9953\n",
      "📉 Iter 9650: Val Loss = 5.5633\n",
      "[Iter 09700] ⏱ Time: 10355.6s | Avg Train Loss: 5.0008\n",
      "📉 Iter 9700: Val Loss = 5.5621\n",
      "[Iter 09750] ⏱ Time: 10408.6s | Avg Train Loss: 5.0082\n",
      "📉 Iter 9750: Val Loss = 5.5869\n",
      "[Iter 09800] ⏱ Time: 10461.5s | Avg Train Loss: 5.0247\n",
      "📉 Iter 9800: Val Loss = 5.5822\n",
      "[Iter 09850] ⏱ Time: 10514.4s | Avg Train Loss: 5.0337\n",
      "📉 Iter 9850: Val Loss = 5.5830\n",
      "[Iter 09900] ⏱ Time: 10567.8s | Avg Train Loss: 5.0202\n",
      "📉 Iter 9900: Val Loss = 5.5911\n",
      "[Iter 09950] ⏱ Time: 10620.9s | Avg Train Loss: 4.9884\n",
      "📉 Iter 9950: Val Loss = 5.5640\n",
      "[Iter 10000] ⏱ Time: 10674.0s | Avg Train Loss: 5.0285\n",
      "📉 Iter 10000: Val Loss = 5.5557\n",
      "📁 Training log saved to CoverageModel_log.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAJOCAYAAAAqFJGJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACuVUlEQVR4nOzdd3hTZQPG4V+SpntB6QIKZW/ZyBSQvRy4AVniwoWIKPqJguIeuHEwFBRRQUQBGcpQ2TIc7NUyyh4FStu0yffHaUJLyyjrNOW5r+tcmJMz3qQveJ6+y+JyuVyIiIiIiIhcBKvZBRAREREREe+nYCEiIiIiIhdNwUJERERERC6agoWIiIiIiFw0BQsREREREbloChYiIiIiInLRFCxEREREROSiKViIiIiIiMhFU7AQEREREZGLpmAhIpfU33//TZ8+fShTpgz+/v4EBwdTp04dXn/9dQ4dOmR28bzKuHHjsFgsWCwW5s+fn+t9l8tF+fLlsVgstGjR4rKVo0WLFlSvXv2yXf9s3N/B9u3bTbm/m/vncK4tr59TfrzwwgtYLJYLOnf+/PmXpAwXc+/vv//+it9bRAoOH7MLICKFx2effUb//v2pVKkSTz75JFWrVsXhcLBixQpGjRrF4sWL+eGHH8wuptcJCQlh9OjRucLDggUL2LJlCyEhIeYU7Aro1KkTixcvJjY21tRyLF68OMfrF198kXnz5vHbb7/l2F+1atWLuk+/fv1o3779BZ1bp04dFi9efNFlEBG5UAoWInJJLF68mAcffJA2bdowdepU/Pz8PO+1adOGJ554gl9++cXEEp5ZSkoKgYGBZhfjjO644w6++uorPvzwQ0JDQz37R48eTaNGjUhOTjaxdJdXZGQkkZGRZheDhg0b5ngdGRmJ1WrNtf90+a1bJUuWpGTJkhdUxtDQ0HOWR0TkclJXKBG5JF5++WUsFguffvppjlDh5uvryw033OB57XQ6ef3116lcuTJ+fn5ERUXRs2dPdu7c6TlmwIABBAUF5fngfMcddxAdHY3D4fDsmzRpEo0aNSIoKIjg4GDatWvHqlWrcpzXu3dvgoOD+eeff2jbti0hISG0atUKgDlz5nDjjTdSsmRJ/P39KV++PPfffz8HDhzIdf8ff/yRa665Bj8/P8qWLcu7776bZzcWl8vFRx99RK1atQgICKBIkSLceuutbN269Ty/WbjrrrsAmDhxomff0aNHmTx5Mn379s3znPT0dF566SXP9xsZGUmfPn3Yv39/rmO//vprGjVqRHBwMMHBwdSqVYvRo0fnOm758uU0a9aMwMBAypYty6uvvorT6fS8n5qayhNPPEGtWrUICwujaNGiNGrUiB9//DHXtSwWCw8//DDjx4+nSpUqBAYGUrNmTX7++eccx+XVFWrVqlV07tyZqKgo/Pz8KF68OJ06dcpRd9zXHzt2LJUqVSIgIIB69eqxZMkSXC4Xb7zxBmXKlCE4OJjrr7+ezZs3n+HbP3/uLmMLFy6kcePGBAYGen4+kyZNom3btsTGxhIQEECVKlV4+umnOXHiRI5r5FWH4uPj6dy5M7/88gt16tQhICCAypUrM2bMmBzH5dUVyl3fN2/eTMeOHQkODiYuLo4nnniCtLS0HOfv3LmTW2+9lZCQEMLDw+nevTvLly/HYrEwbty4i/5+AP79919uvPFGihQpgr+/P7Vq1eKLL77IcYzT6eSll17y/NzCw8O55pprePfddz3H7N+/n/vuu4+4uDhP/W7SpAlz5869JOUUkQujYCEiFy0zM5PffvuNunXrEhcXd17nPPjggzz11FO0adOGadOm8eKLL/LLL7/QuHFjz4N83759SUlJ4dtvv81x7pEjR/jxxx/p0aMHdrsdMILNXXfdRdWqVfn2228ZP348x44do1mzZqxduzbH+enp6dxwww1cf/31/PjjjwwbNgyALVu20KhRIz7++GNmz57N0KFDWbp0KU2bNs0RYH755Re6du1KREQEkyZN4vXXX2fixIm5HpAA7r//fgYMGEDr1q2ZOnUqH330Ef/99x+NGzdm79695/VdhYaGcuutt+Z4kJw4cSJWq5U77rgj1/FOp5Mbb7yRV199lW7dujF9+nReffVV5syZQ4sWLTh58qTn2KFDh9K9e3eKFy/OuHHj+OGHH+jVqxcJCQk5rrlnzx66d+9Ojx49mDZtGh06dGDIkCFMmDDBc0xaWhqHDh1i0KBBTJ06lYkTJ9K0aVO6du3Kl19+mauc06dP54MPPmD48OFMnjyZokWLcvPNN581dJ04cYI2bdqwd+9ePvzwQ+bMmcPIkSMpVaoUx44dy3Hszz//zOeff86rr77KxIkTOXbsGJ06deKJJ57gzz//5IMPPuDTTz9l7dq13HLLLbhcrnP/MM4hKSmJHj160K1bN2bMmEH//v0B2LRpEx07dmT06NH88ssvDBgwgG+//ZYuXbqc13XXrFnDE088weOPP+4Jtffccw8LFy4857kOh4MbbriBVq1a8eOPP9K3b1/eeecdXnvtNc8xJ06coGXLlsybN4/XXnuNb7/9lujo6Dzr14XasGEDjRs35r///uO9995jypQpVK1ald69e/P66697jnv99dd54YUXuOuuu5g+fTqTJk3innvu4ciRI55j7r77bqZOncrQoUOZPXs2n3/+Oa1bt+bgwYOXrLwicgFcIiIXac+ePS7Adeedd57X8evWrXMBrv79++fYv3TpUhfgeuaZZzz76tSp42rcuHGO4z766CMX4Prnn39cLpfLlZiY6PLx8XE98sgjOY47duyYKyYmxnX77bd79vXq1csFuMaMGXPWMjqdTpfD4XAlJCS4ANePP/7oea9+/fquuLg4V1paWo57RUREuLL/s7p48WIX4HrrrbdyXHvHjh2ugIAA1+DBg89ahrFjx7oA1/Lly13z5s1zAa5///3XU4bevXu7XC6Xq1q1aq7mzZt7zps4caILcE2ePDnH9ZYvX+4CXB999JHL5XK5tm7d6rLZbK7u3buftRzNmzd3Aa6lS5fm2F+1alVXu3btznheRkaGy+FwuO655x5X7dq1c7wHuKKjo13JycmefXv27HFZrVbXK6+8kus72LZtm8vlcrlWrFjhAlxTp049a5kBV0xMjOv48eOefVOnTnUBrlq1armcTqdn/8iRI12A6++//z7rNbPr1auXKygoKMc+9/f066+/nvVcd91asGCBC3CtWbPG897zzz/vOv1/zaVLl3b5+/u7EhISPPtOnjzpKlq0qOv+++/37HPXkXnz5uUoJ+D69ttvc1yzY8eOrkqVKnlef/jhhy7ANXPmzBzH3X///S7ANXbs2LN+Jve9v/vuuzMec+edd7r8/PxciYmJOfZ36NDBFRgY6Dpy5IjL5XK5Onfu7KpVq9ZZ7xccHOwaMGDAWY8RkStPLRYicsXNmzcPMLppZNegQQOqVKnCr7/+6tnXp08fFi1axIYNGzz7xo4dS/369T0zFc2aNYuMjAx69uxJRkaGZ/P396d58+Z5zpJzyy235Nq3b98+HnjgAeLi4vDx8cFut1O6dGkA1q1bBxi/2V2xYgU33XQTvr6+nnODg4Nz/fb5559/xmKx0KNHjxzliomJoWbNmvmavad58+aUK1eOMWPG8M8//7B8+fIzdoP6+eefCQ8Pp0uXLjnuW6tWLWJiYjz3nTNnDpmZmTz00EPnvH9MTAwNGjTIse+aa67J1bLx3Xff0aRJE4KDgz3f4ejRoz3fX3YtW7bMMfA8OjqaqKioXNfMrnz58hQpUoSnnnqKUaNG5WqNOv36QUFBntdVqlQBoEOHDjm6G7n3n+2+56tIkSJcf/31ufZv3bqVbt26ERMTg81mw26307x5c4A8v5vT1apVi1KlSnle+/v7U7FixfMqs8ViyVU3T//ZLViwgJCQkFwDx93d8C6F3377jVatWuVq1ezduzcpKSmeAfINGjRgzZo19O/fn1mzZuXZFbJBgwaMGzeOl156iSVLluRoURQR8yhYiMhFK1asGIGBgWzbtu28jnd3V8hrpp/ixYvn6M7QvXt3/Pz8PH28165dy/Lly+nTp4/nGHeXovr162O323NskyZNyjVGIjAwMMcgaDC6D7Vt25YpU6YwePBgfv31V5YtW8aSJUsAPN2HDh8+jMvlIjo6OlfZT9+3d+9ez7Gnl2vJkiV5jt04E4vFQp8+fZgwYQKjRo2iYsWKNGvWLM9j9+7dy5EjR/D19c113z179nju6x5vcT6DhSMiInLt8/Pzy9GtasqUKdx+++2UKFGCCRMmsHjxYk8ASk1NvaBrni4sLIwFCxZQq1YtnnnmGapVq0bx4sV5/vnncz1cFi1aNMdrdxA80/68yphfedXp48eP06xZM5YuXcpLL73E/PnzWb58OVOmTAE46+d1u5Dvyi0wMBB/f/9c52b/vAcPHjyvOn0xDh48eMa/8+73AYYMGcKbb77JkiVL6NChAxEREbRq1YoVK1Z4zpk0aRK9evXi888/p1GjRhQtWpSePXuyZ8+eS1ZeEck/zQolIhfNZrPRqlUrZs6cyc6dO8/5oOp+SEpKSsp17O7duylWrJjndZEiRbjxxhv58ssveemllxg7diz+/v45fpPqPv7777/3tDCcTV7rBPz777+sWbOGcePG0atXL8/+0wf1FilSBIvFkuf4iNMfaooVK4bFYuH333/Pc0B7XvvOpnfv3gwdOpRRo0YxYsSIMx5XrFgxIiIizjgLl7uVwD3b0s6dO897bMzZTJgwgTJlyjBp0qQc3/Hpg4QvVo0aNfjmm29wuVz8/fffjBs3juHDhxMQEMDTTz99Se+VX3nVrd9++43du3czf/58TysFkGPMgNkiIiJYtmxZrv2X8kE9IiKCpKSkXPt3794NnPp77OPjw8CBAxk4cCBHjhxh7ty5PPPMM7Rr144dO3YQGBhIsWLFGDlyJCNHjiQxMZFp06bx9NNPs2/fvgI7+5zI1UAtFiJySQwZMgSXy8W9995Lenp6rvcdDgc//fQTgKerSPaBv2DMOrRu3TrPLE1uffr0Yffu3cyYMYMJEyZw8803Ex4e7nm/Xbt2+Pj4sGXLFurVq5fndi7uB8LTH/Y/+eSTHK+DgoKoV68eU6dOzfE5jx8/nmtGo86dO+Nyudi1a1eeZapRo8Y5y5VdiRIlePLJJ+nSpUuO8HO6zp07c/DgQTIzM/O8b6VKlQBo27YtNpuNjz/+OF/lOBOLxYKvr2+Oh+s9e/bkOSvUpbpfzZo1eeeddwgPD2flypWX5T4X63zrlpmaN2/OsWPHmDlzZo7933zzzSW7R6tWrTwhK7svv/ySwMDAPKfKDQ8P59Zbb+Whhx7i0KFDeS6UWKpUKR5++GHatGlTYOuAyNVCLRYickm4Z1Pq378/devW5cEHH6RatWo4HA5WrVrFp59+SvXq1enSpQuVKlXivvvu4/3338dqtdKhQwe2b9/Oc889R1xcHI8//niOa7dt25aSJUvSv39/9uzZk6MbFBjTcQ4fPpxnn32WrVu30r59e4oUKcLevXtZtmwZQUFBnpmfzqRy5cqUK1eOp59+GpfLRdGiRfnpp5+YM2dOrmOHDx9Op06daNeuHY899hiZmZm88cYbBAcH51hdvEmTJtx333306dOHFStWcN111xEUFERSUhJ//PEHNWrU4MEHH8zX9/zqq6+e85g777yTr776io4dO/LYY4/RoEED7HY7O3fuZN68edx4443cfPPNxMfH88wzz/Diiy9y8uRJ7rrrLsLCwli7di0HDhw453d2us6dOzNlyhT69+/Prbfeyo4dO3jxxReJjY1l06ZN+brWmfz888989NFH3HTTTZQtWxaXy8WUKVM4cuQIbdq0uST3uNQaN25MkSJFeOCBB3j++eex2+189dVXrFmzxuyiefTq1Yt33nmHHj168NJLL1G+fHlmzpzJrFmzALBaz+/3kO6ug6dr3rw5zz//PD///DMtW7Zk6NChFC1alK+++orp06fz+uuvExYWBkCXLl2oXr069erVIzIykoSEBEaOHEnp0qWpUKECR48epWXLlnTr1o3KlSsTEhLC8uXLPbO1iYh5FCxE5JK59957adCggWcqyz179mC326lYsSLdunXj4Ycf9hz78ccfU65cOUaPHs2HH35IWFgY7du355VXXsnVn9xqtdKzZ09efvll4uLicrVogNFiUrVqVd59910mTpxIWloaMTEx1K9fnwceeOCcZbfb7fz000889thj3H///fj4+NC6dWvmzp2bY9AsQPv27Zk8eTJDhw7ljjvuICYmhv79+7N7927Gjx+f49hPPvmEhg0b8sknn/DRRx/hdDopXrw4TZo0yTUY+lKx2WxMmzaNd999l/Hjx/PKK6/g4+NDyZIlad68eY6WkuHDh1OhQgXef/99unfvjo+PDxUqVODRRx/N93379OnDvn37GDVqFGPGjKFs2bI8/fTT7Ny5M98h5UwqVKhAeHg4r7/+Ort378bX15dKlSrl6sJWkERERDB9+nSeeOIJevToQVBQEDfeeCOTJk2iTp06ZhcPMFrifvvtNwYMGMDgwYOxWCy0bduWjz76iI4dO+ZoITybt956K8/98+bNo0WLFixatIhnnnmGhx56iJMnT1KlShXGjh2bYyKHli1bMnnyZD7//HOSk5OJiYmhTZs2PPfcc9jtdvz9/bn22msZP34827dvx+FwUKpUKZ566ikGDx58Cb4NEblQFpfrEkzcLSJylXM4HNSqVYsSJUowe/Zss4sjckm8/PLL/O9//yMxMfGCVwQXkauHWixERC7APffcQ5s2bYiNjWXPnj2MGjWKdevW5VgdWMSbfPDBB4DRLdDhcPDbb7/x3nvv0aNHD4UKETkvChYiIhfg2LFjDBo0iP3792O326lTpw4zZsygdevWZhdN5IIEBgbyzjvvsH37dtLS0jzdi/73v/+ZXTQR8RLqCiUiIiIiIhdN082KiIiIiMhFU7AQEREREZGLpmAhIiIiIiIX7aobvO10Otm9ezchISE5VocVEREREZGcXC4Xx44do3jx4udcLPOqCxa7d+8mLi7O7GKIiIiIiHiNHTt2nHPq6asuWISEhADGlxMaGnrF7utwOJg9ezZt27bFbrdfsftKwaO6IG6qC5Kd6oO4qS6IW0GoC8nJycTFxXmeoc/mqgsW7u5PoaGhVzxYBAYGEhoaqn8krnKqC+KmuiDZqT6Im+qCuBWkunA+Qwg0eFtERERERC6agoWIiIiIiFw0BQsREREREbloV90YCxERERFv5HQ6SU9PN7sYcgU5HA58fHxITU0lMzPzstzDbrdjs9kuybUULEREREQKuPT0dLZt24bT6TS7KHIFuVwuYmJi2LFjx2Vdfy08PJyYmJiLvoeChYiIiEgB5nK5SEpKwmazERcXd85FyqTwcDqdHD9+nODg4Mvyc3e5XKSkpLBv3z4AYmNjL+p6ChYiIiIiBVhGRgYpKSkUL16cwMBAs4sjV5C7+5u/v/9lC5QBAQEA7Nu3j6ioqIvqFqXIKyIiIlKAufvW+/r6mlwSKazcgdXhcFzUdRQsRERERLzA5exjL1e3S1W3FCxEREREROSiKViIiIiIiFdo0aIFAwYMOO/jt2/fjsViYfXq1ZetTHKKgoWIiIiIXFIWi+WsW+/evS/oulOmTOHFF1887+Pj4uJISkqievXqF3S/86UAY9CsUCIiIiJySSUlJXn+e9KkSQwdOpQNGzZ49rlnInJzOBzY7fZzXrdo0aL5KofNZiMmJiZf58iFU4uFiIiIiFxSMTExni0sLAyLxeJ5nZqaSnh4ON9++y0tWrTA39+fCRMmcPDgQe666y5KlixJYGAgNWrUYOLEiTmue3pXqPj4eF5++WX69u1LSEgIpUqV4tNPP/W8f3pLwvz587FYLPz666/Uq1ePwMBAGjdunCP0ALz00ktERUUREhJCv379ePrpp6lVq9YFfx9paWk8+uijREVF4e/vT9OmTVm+fLnn/cOHD9O9e3ciIyMJCAigQoUKjB07FjAWR3zkkUeIjY3F39+f+Ph4XnnllQsuy+WkYCEiIiLiRVwuFynpGaZsLpfrkn2Op556ikcffZR169bRrl07UlNTqVu3Lj///DP//vsv9913H3fffTdLly4963Xeeust6tWrx6pVq+jfvz8PPvgg69evP+s5zz77LG+99RYrVqzAx8eHvn37et776quvGDFiBK+99hp//fUXpUqV4uOPP76ozzp48GAmT57MF198wcqVKylfvjzt2rXj0KFDADz33HOsXbuWmTNnsm7dOj7++GOKFSsGwCeffMJPP/3Et99+y4YNG5gwYQLx8fEXVZ7LxdSuUMeOHeO5557jhx9+YN++fdSuXZt3332X+vXrn/GcBQsWMHDgQP777z+KFy/O4MGDeeCBB65gqUVERETMc9KRSdWhs0y599rh7Qj0vTSPjwMGDKBr16459g0aNMjz34888gi//PIL3333Hddee+0Zr9OxY0f69+8PGGHlnXfeYf78+VSuXPmM54wYMYLmzZsD8PTTT9OpUydSU1Px9/fn/fff55577qFPnz4ADB06lNmzZ3P8+PEL+pwnTpzg448/Zty4cXTo0AGAzz77jDlz5jB69GiefPJJEhMTqV27NvXq1QPwBAen08nOnTupUKECTZs2xWKxULp06Qsqx5VgaotFv379mDNnDuPHj+eff/6hbdu2tG7dml27duV5/LZt2+jYsSPNmjVj1apVPPPMMzz66KNMnjz5CpdcRERERC6G+yHaLTMzkxEjRnDNNdcQERFBcHAws2fPJjEx8azXueaaazz/7e5ytW/fvvM+JzY2FsBzzoYNG2jQoEGO409/nR9btmzB4XDQpEkTzz673U6DBg1Yt24dAA8++CDffPMNtWrVYvDgwSxatMhzbLdu3Vi9ejWVKlXi0UcfZfbs2RdclsvNtBaLkydPMnnyZH788Ueuu+46AF544QWmTp3Kxx9/zEsvvZTrnFGjRlGqVClGjhwJQJUqVVixYgVvvvkmt9xyy5UsvoiIiIgpAuw21g5vZ9q9L5WgoKAcr9966y3eeecdRo4cSY0aNQgKCmLAgAGkp6ef9TqnD/q2WCw4nc7zPse9OFz2c05fMO5iuoC5z83rmu59HTp0ICEhgenTpzN37lxatWrFQw89xOuvv07NmjXZsmULs2bNYu7cudx+++20bt2a77///oLLdLmYFiwyMjLIzMzE398/x/6AgAD++OOPPM9ZvHgxbdu2zbGvXbt2jB49+oyzCaSlpZGWluZ5nZycDBizD1zssuX54b7XlbynFEyqC+KmuiDZqT6I2+l1weFw4HK5cDqdnodffx9zOp24XK58P2S7y5zXn9kf5hcuXMgNN9xAt27dPO9v2rSJypUr5zjO/V2c6XX2faffK697n76vUqVKLF26lO7du3uut2LFihzHnu0znn5M2bJl8fX1ZeHChZ7P5nA4WLFiBY899pjn+IiICHr27EnPnj1p0qQJTz31FK+99hoAISEh3Hbbbdx222107dqVjh07cuDAgXzPknUmTqcTl8uFw+HAZssZHvPzb5JpwSIkJIRGjRrx4osvUqVKFaKjo5k4cSJLly6lQoUKeZ6zZ88eoqOjc+yLjo4mIyODAwcOeJqysnvllVcYNmxYrv2zZ88mMDDw0nyYfJgzZw6jN1jJdEH3ck6Czj2zmhRSc+bMMbsIUkCoLkh2qg/i5q4LPj4+xMTEcPz48XP+9r4gSk1NxeVyeX656x6rcOLECc8+gFKlSjFt2jTmzJlDeHg4H330EUlJSZQvX95zXEZGBunp6Z7XTqeT1NTUHNfJzMwkLS2N5OTkXPdKSUkBjHG+VqvV8567XMnJyfTt25cBAwZQrVo1GjRowA8//MCaNWuIj4/PcZ/s3PdZvXq153pulSpVom/fvgwePBh/f39KlizJe++9x4kTJ7jttttITk7m5ZdfplatWlSuXJm0tDR+/PFHKlasyLFjx/joo4+Ijo6mRo0aWK1WJk6cSHR0NFar9Yzlya/09HROnjzJwoULycjIyPGe+zs7H6YO3h4/fjx9+/alRIkS2Gw26tSpQ7du3Vi5cuUZzzlT09Tp+92GDBnCwIEDPa+Tk5OJi4ujbdu2hIaGXoJPcX4cDgdz5syhTZs2DFo2H0emi6YtWhAb5n/uk6VQyV4XzmfObim8VBckO9UHcTu9LqSmprJjxw6Cg4Nz9fTwBv7+/lgsFs9zV3BwMGB0hcr+LDZ8+HB27drFrbfeSmBgIPfeey833XQTR48e9Rzn4+ODr6+v57XVasXf3z/HdWw2G35+foSGhua6l/uXyiEhIZ5z3F2ygoODCQ0NpV+/fuzZs4ehQ4eSmprKbbfdRu/evVm+fPkZnx3d97nnnntyvbdlyxbeeustfHx8ePDBBzl27Bj16tXjl19+oVSpUp7yvPTSS2zfvp2AgACaNm3KpEmTCAkJISgoiA8++IBNmzZhs9moX78+06dPJzw8/AJ+GnlLTU0lICCA6667Llcdy094sbgu5bxhF8idImNjY7njjjs4fvw406dPz3Xcdddd55k5yu2HH37g9ttvJyUl5bz+IU5OTiYsLCxHJb0SHA4HM2bMoGPHjtQYPpdUh5PfB7ckruiVbzURc2WvC3p4uLqpLkh2qg/idnpdSE1NZdu2bZQpU8Yrg0Vh0KZNG2JiYhg/fvwVva/T6SQ5OZnQ0FBPC8vlcLY6lp9n5wKx8nZQUBBBQUEcPnyYWbNm8frrr+d5XKNGjfjpp59y7Js9ezb16tXzqn+Ebe5BQuZnOhERERHJJiUlhVGjRtGuXTtsNhsTJ05k7ty56qZ4HkydbnbWrFn88ssvbNu2jTlz5tCyZUsqVarkmTd4yJAh9OzZ03P8Aw88QEJCAgMHDmTdunWMGTOG0aNH55jz2BvYrEawyHAqWIiIiIgUJBaLhRkzZtCsWTPq1q3LTz/9xOTJk2ndurXZRSvwTG2xOHr0KEOGDGHnzp0ULVqUW265hREjRnhaH5KSknLMXVymTBlmzJjB448/zocffkjx4sV57733vG6qWR+bkeecChYiIiIiBUpAQABz5841uxheydRgcfvtt3P77bef8f1x48bl2te8efOzDu72BlaLWixEREREpHAxtSvU1conqytUpoKFiIiIiBQSChYmsClYiIiIiEgho2BhAk+w0KxQIiIiIlJIKFiYQC0WIiIiIlLYKFiYQMFCRERERAobBQsTuBfIU7AQERERObMWLVowYMAAz+v4+HhGjhx51nMsFgtTp0696HtfqutcTRQsTKAWCxERESnMunTpcsYF5RYvXozFYrmg5QOWL1/Offfdd7HFy+GFF16gVq1aufYnJSXRoUOHS3qv040bN47w8PDLeo8rScHCBAoWIiIiUpjdc889/PbbbyQkJOR6b8yYMdSqVYs6derk+7qRkZEEBgZeiiKeU0xMDH5+flfkXoWFgoUJFCxERESkMOvcuTNRUVG5FjtOSUlh0qRJ3HPPPRw8eJC77rqLkiVLEhgYSI0aNZg4ceJZr3t6V6hNmzZx3XXX4e/vT9WqVZkzZ06uc5566ikqVqxIYGAgZcuW5bnnnsPhcABGi8GwYcNYs2YNFosFi8XiKfPpXaH++ecfrr/+egICAoiIiOC+++7j+PHjnvd79+7NTTfdxJtvvklsbCwRERE89NBDnntdiMTERLp160ZoaCihoaHcfvvt7N271/P+mjVraNmyJSEhIYSGhlK3bl1WrFgBQEJCAl26dKFIkSIEBQVRrVo1ZsyYccFlOR+mrrx9tXIHC628LSIiIvnmcoEjxZx72wMha6zo2fj4+NCzZ0/GjRvH0KFDsWSd891335Genk737t1JSUmhbt26PPXUU4SGhjJ9+nTuvvtuypYty7XXXnvOezidTrp27UqxYsVYsmQJycnJOcZjuIWEhDBu3DiKFy/OP//8w7333ktISAiDBw/mjjvu4N9//+WXX35h7ty5AISFheW6RkpKCu3bt6dhw4YsX76cffv20a9fPx5++OEc4WnevHnExsYyb948Nm/ezB133EGtWrW49957z/l5TudyuejatSt+fn7MmzcPp9NJ//79ueOOO5g/fz4A3bt3p3bt2nz88cfYbDZWr16N3W4H4KGHHiI9PZ2FCxcSFBTE2rVrCQ4Oznc58kPBwgRqsRAREZEL5kiBl4ubc+9ndoNv0Hkd2rdvX9544w3mz59Py5YtAaMbVNeuXSlSpAhFihRh0KBBnuMfeeQRfvnlF7777rvzChZz585l3bp1bN++nZIlSwLw8ssv5xoX8b///c/z3/Hx8TzxxBNMmjSJwYMHExAQQHBwMD4+PsTExJzxXl999RUnT57kyy+/JCjI+PwffPABXbp04bXXXiM6OhqAIkWK8MEHH2Cz2ahcuTKdOnXi119/vaBgMXfuXP7++29Wr15N1apVsVqtjB8/nmrVqrF8+XLq169PYmIiTz75JJUrVwagQoUKnvMTExO55ZZbqFGjBgBly5bNdxnyS12hTOCZFUoL5ImIiEghVblyZRo3bsyYMWMA2LJlC7///jt9+/YFIDMzkxEjRnDNNdcQERFBcHAws2fPJjEx8byuv27dOkqVKuUJFQCNGjXKddz3339P06ZNiYmJITg4mOeee+6875H9XjVr1vSECoAmTZrgdDrZsGGDZ1+1atWw2Wye17Gxsezbty9f98p+z7i4uByfr2rVqoSHh7Nu3ToABg4cSL9+/WjdujWvvvoqW7Zs8Rz76KOP8tJLL9GkSROef/55/v777wsqR36oxcIEPjZ3i4XT5JKIiIiI17EHGi0HZt07H+655x4efvhhPvzwQ8aOHUvp0qVp1aoVAG+99RbvvPMOI0eOpEaNGgQFBTFgwADS09PP69quPH5Bazmtm9aSJUu48847GTZsGO3atSMsLIxvvvmGt956K1+fw+Vy5bp2Xvd0d0PK/p7zAp/3znTP7PtfeOEFunXrxvTp05k5cybPP/8833zzDTfffDP9+vWjXbt2TJ8+ndmzZ/PKK6/w1ltv8cgjj1xQec6HWixMcKorlMkFEREREe9jsRjdkczYzmN8RXa33347NpuNr7/+mi+++II+ffp4Hop///13brzxRnr06EHNmjUpW7YsmzZtOu9rV61alcTERHbvPhWyFi9enOOYP//8k9KlS/Pss89Sr149KlSokGumKl9fXzIzM895r9WrV3PixIkc17ZarVSsWPG8y5wf7s+3c+dOz761a9dy9OhRqlSp4tlXsWJFHn/8cWbPnk3Xrl0ZO3as5724uDgeeOABpkyZwhNPPMFnn312WcrqpmBhglML5ClZiIiISOEVHBzMHXfcwTPPPMPu3bvp3bu3573y5cszZ84cFi1axLp167j//vvZs2fPeV+7devWVKpUiZ49e7JmzRp+//13nn322RzHlC9fnsTERL755hu2bNnCe++9xw8//JDjmPj4eLZt28bq1as5cOAAaWlpue7VvXt3/P396dWrF//++y/z5s3jkUce4e677/aMr7hQmZmZrF69Ose2du1aWrduzTXXXMN9993HypUrWbZsGT179qR58+bUq1ePkydP8vDDDzN//nwSEhL4888/Wb58uSd0DBgwgFmzZrFt2zZWrlzJb7/9liOQXA4KFiZQi4WIiIhcLe655x4OHz5M69atKVWqlGf/c889R506dWjXrh0tWrQgJiaGm2666byva7Va+eGHH0hLS6NBgwb069ePESNG5Djmxhtv5PHHH+fhhx+mVq1aLFq0iOeeey7HMbfccgvt27enZcuWREZG5jnlbWBgILNmzeLQoUPUr1+fW2+9lVatWvHBBx/k78vIw/Hjx6ldu3aOrWPHjlgsFqZMmUJ4eDgtWrSgdevWlC1blkmTJgFgs9k4ePAgPXv2pGLFitx+++106NCBYcOGAUZgeeihh6hSpQrt27enUqVKfPTRRxdd3rOxuPLqoFaIJScnExYWxtGjRwkNDb1i93U4HMyYMYOOHTvy6KS/mfnvHl68sRp3N4q/YmWQgiF7XTi9L6ZcXVQXJDvVB3E7vS6kpqaybds2ypQpg7+/v9nFkyvI6XSSnJxMaGgoVuvlaw84Wx3Lz7OzWixMoOlmRURERKSwUbAwgRbIExEREZHCRsHCBO5g4by6eqGJiIiISCGmYGEC96xQarEQERERkcJCwcIE7gXynAoWIiIiIlJIKFiYwKoWCxEREcmnq2wiT7mCLnR18NP5XJKrSL74WNViISIiIufHbrdjsVjYv38/kZGRnpWrpfBzOp2kp6eTmpp6WaabdblcpKens3//fqxWK76+vhd1PQULE1g1K5SIiIicJ5vNRsmSJdm5cyfbt283uzhyBblcLk6ePElAQMBlDZSBgYGUKlXqosOLgoUJfLSOhYiIiORDcHAwFSpUwOFwmF0UuYIcDgcLFy7kuuuuu2wLZ9psNnx8fC5JcFGwMIFVwUJERETyyWazYbPZzC6GXEE2m42MjAz8/f0vW7C4lDR42wQ+6golIiIiIoWMgoUJbFn917RAnoiIiIgUFgoWJtACeSIiIiJS2ChYmEAL5ImIiIhIYaNgYQItkCciIiIihY2ChQm0QJ6IiIiIFDYKFibQAnkiIiIiUtgoWJjAs0CeZoUSERERkUJCwcIEngXyMhUsRERERKRwULAwgVosRERERKSwUbAwgXsdi0yNsRARERGRQkLBwgQ2q4KFiIiIiBQuChYmULAQERERkcJGwcIENs90s06TSyIiIiIicmkoWJjA5lkgz+SCiIiIiIhcIgoWJlCLhYiIiIgUNgoWJjg13azJBRERERERuUQULEzgWSBPLRYiIiIiUkgoWJjA02KhXCEiIiIihYSpwSIjI4P//e9/lClThoCAAMqWLcvw4cNxnuU3+fPnz8diseTa1q9ffwVLfnFOLZCnZCEiIiIihYOPmTd/7bXXGDVqFF988QXVqlVjxYoV9OnTh7CwMB577LGznrthwwZCQ0M9ryMjIy93cS8ZrWMhIiIiIoWNqcFi8eLF3HjjjXTq1AmA+Ph4Jk6cyIoVK855blRUFOHh4Ze5hJeHgoWIiIiIFDamdoVq2rQpv/76Kxs3bgRgzZo1/PHHH3Ts2PGc59auXZvY2FhatWrFvHnzLndRLylPsHApWIiIiIhI4WBqi8VTTz3F0aNHqVy5MjabjczMTEaMGMFdd911xnNiY2P59NNPqVu3LmlpaYwfP55WrVoxf/58rrvuulzHp6WlkZaW5nmdnJwMgMPhwOFwXPoPdQbuezkcDlzOTAAyMl1XtAxSMGSvC3J1U12Q7FQfxE11QdwKQl3Iz70tLpd5vzb/5ptvePLJJ3njjTeoVq0aq1evZsCAAbz99tv06tXrvK/TpUsXLBYL06ZNy/XeCy+8wLBhw3Lt//rrrwkMDLyo8l+onSfgjb99CLO7GF4v05QyiIiIiIicS0pKCt26dePo0aM5xjfnxdRgERcXx9NPP81DDz3k2ffSSy8xYcKEfM3yNGLECCZMmMC6detyvZdXi0VcXBwHDhw455dzKTkcDubMmUObNm3YejCVzh8uJiLIlyVPt7hiZZCCIXtdsNvtZhdHTKS6INmpPoib6oK4FYS6kJycTLFixc4rWJjaFSolJQWrNecwD5vNdtbpZvOyatUqYmNj83zPz88PPz+/XPvtdrspPyC73Y6/n9FK4XS59A/GVcysOigFj+qCZKf6IG6qC+JmZl3Iz31NDRZdunRhxIgRlCpVimrVqrFq1Srefvtt+vbt6zlmyJAh7Nq1iy+//BKAkSNHEh8fT7Vq1UhPT2fChAlMnjyZyZMnm/Ux8s2atY5FhmaFEhEREZFCwtRg8f777/Pcc8/Rv39/9u3bR/Hixbn//vsZOnSo55ikpCQSExM9r9PT0xk0aBC7du0iICCAatWqMX369POaSaqg8MlqpdF0syIiIiJSWJgaLEJCQhg5ciQjR4484zHjxo3L8Xrw4MEMHjz48hbsMnP3/lKwEBEREZHCwtR1LK5WarEQERERkcJGwcIEWiBPRERERAobBQsTuIOFywVOtVqIiIiISCGgYGECd7AAtVqIiIiISOGgYGGCHMFCLRYiIiIiUggoWJjAR8FCRERERAoZBQsTuBfIAy2SJyIiIiKFg4KFCbK3WGjwtoiIiIgUBgoWJrBa1WIhIiIiIoWLgoVJ3K0WTs0KJSIiIiKFgIKFSdytFmqxEBEREZHCQMHCJJ4WCwULERERESkEFCxMYrOoxUJERERECg8FC5PYbEawyHQ6TS6JiIiIiMjFU7AwibvFIlO5QkREREQKAQULk9g8g7eVLERERETE+ylYmOTU4G2TCyIiIiIicgkoWJjEqhYLERERESlEFCxMogXyRERERKQwUbAwiafFIlPBQkRERES8n4KFSdwtFplqsRARERGRQkDBwiRWz3SzChYiIiIi4v0ULEziY1OwEBEREZHCQ8HCJDa1WIiIiIhIIaJgYRL3AnkKFiIiIiJSGChYmETBQkREREQKEwULk9g0K5SIiIiIFCIKFiZRi4WIiIiIFCYKFiaxWY2vXgvkiYiIiEhhoGBhkqzZZtUVSkREREQKBQULk7hbLNQVSkREREQKAwULk/hojIWIiIiIFCIKFibR4G0RERERKUwULEyiYCEiIiIihYmChUkULERERESkMFGwMIkWyBMRERGRwkTBwiQ2i1osRERERKTwULAwic2mYCEiIiIihYeChUncLRYZChYiIiIiUggoWJjEPcbCqWAhIiIiIoWAgoVJ3MFCLRYiIiIiUhgoWJjEvfK2U7NCiYiIiEghoGBhEqu7xSJTwUJEREREvJ+ChUl8PAvkOU0uiYiIiIjIxVOwMInVogXyRERERKTwULAwyakWCwULEREREfF+ChYmsSpYiIiIiEghYmqwyMjI4H//+x9lypQhICCAsmXLMnz4cJznGHewYMEC6tati7+/P2XLlmXUqFFXqMSXjo+mmxURERGRQsTHzJu/9tprjBo1ii+++IJq1aqxYsUK+vTpQ1hYGI899lie52zbto2OHTty7733MmHCBP7880/69+9PZGQkt9xyyxX+BBdOC+SJiIiISGFiarBYvHgxN954I506dQIgPj6eiRMnsmLFijOeM2rUKEqVKsXIkSMBqFKlCitWrODNN9/0ymChFgsRERERKQxMDRZNmzZl1KhRbNy4kYoVK7JmzRr++OMPT2jIy+LFi2nbtm2Ofe3atWP06NE4HA7sdnuO99LS0khLS/O8Tk5OBsDhcOBwOC7dhzkH973cf1pcRnevjEznFS2HmO/0uiBXL9UFyU71QdxUF8StINSF/Nzb1GDx1FNPcfToUSpXrozNZiMzM5MRI0Zw1113nfGcPXv2EB0dnWNfdHQ0GRkZHDhwgNjY2BzvvfLKKwwbNizXdWbPnk1gYOCl+SD5MGfOHADW7rUANnbtTmLGjF1XvBxiPnddEFFdkOxUH8RNdUHczKwLKSkp532sqcFi0qRJTJgwga+//ppq1aqxevVqBgwYQPHixenVq9cZz7NkrQHh5spaC+L0/QBDhgxh4MCBntfJycnExcXRtm1bQkNDL9EnOTeHw8GcOXNo06YNdrudE3/t5Nuta4mMiqZjx9pXrBxivtPrgly9VBckO9UHcVNdELeCUBfcvX3Oh6nB4sknn+Tpp5/mzjvvBKBGjRokJCTwyiuvnDFYxMTEsGfPnhz79u3bh4+PDxEREbmO9/Pzw8/PL9d+u91uyg/IfV+7j/HVO7P2ydXHrDooBY/qgmSn+iBuqgviZmZdyM99TZ1uNiUlBas1ZxFsNttZp5tt1KhRruag2bNnU69ePa/6y+dj0zoWIiIiIlJ4mBosunTpwogRI5g+fTrbt2/nhx9+4O233+bmm2/2HDNkyBB69uzpef3AAw+QkJDAwIEDWbduHWPGjGH06NEMGjTIjI9wwawWBQsRERERKTxM7Qr1/vvv89xzz9G/f3/27dtH8eLFuf/++xk6dKjnmKSkJBITEz2vy5Qpw4wZM3j88cf58MMPKV68OO+9955XTTUL4JPVUqNgISIiIiKFganBIiQkhJEjR551etlx48bl2te8eXNWrlx5+Qp2Bdiy2ooULERERESkMDC1K9TVzOZusXApWIiIiIiI91OwMIlaLERERESkMFGwMIm7xSIjU8FCRERERLyfgoVJbFmzQjnVFUpERERECgEFC5PYrEawyFBXKBEREREpBBQsTOJeIM+pYCEiIiIihYCChUncC+SpxUJERERECgMFC5P4WLXytoiIiIgUHgoWJrEpWIiIiIhIIaJgYRJPsNCsUCIiIiJSCChYmEQtFiIiIiJSmChYmETBQkREREQKEwULk7gXyFOwEBEREZHCQMHCJGqxEBEREZHCRMHCJAoWIiIiIlKYKFiYxEezQomIiIhIIaJgYRJrthYLl8KFiIiIiHg5BQuTuFssQN2hRERERMT7KViYxJo9WKjFQkRERES8nIKFSdRiISIiIiKFiY/ZBbgqLR+NryONAKI5ib+ChYiIiIh4PQULM8x4Eh9XJqF8oGAhIiIiIoWCukKZwWYHwG7JBNQVSkRERES8n4KFGaxZwQIFCxEREREpHBQszGAzeqD5W41AoVmhRERERMTbKViYwd1iYc0AICNTwUJEREREvJuChRmyxli4WyycarEQERERES+nYGEGq9EVyteS1WKhMRYiIiIi4uUULMyQ1WLhZ3UC4FSwEBEREREvp2BhBs+sUEawUIuFiIiIiHg7BQszZM0K5WfVdLMiIiIiUjgoWJghq8XCVwvkiYiIiEghoWBhBps7WKgrlIiIiIgUDgoWZjitxULTzYqIiIiIt1OwMEPWGAt71hgLLZAnIiIiIt5OwcIMWetY+KEWCxEREREpHBQszJDVFconqyuUxliIiIiIiLdTsDCDzb3ythbIExEREZHCQcHCDO4WC9RiISIiIiKFg4KFGWxax0JEREREChcFCzOcNsZCwUJEREREvJ2ChRncYyyyukJlalYoEREREfFyChZmyNVi4TSzNCIiIiIiF03BwgxZYyzs7hYL5QoRERER8XIKFmbIWiDvVLBQshARERER76ZgYQabe7rZDEAtFiIiIiLi/UwNFvHx8VgsllzbQw89lOfx8+fPz/P49evXX+GSX6TT1rFQi4WIiIiIeDsfM2++fPlyMjMzPa///fdf2rRpw2233XbW8zZs2EBoaKjndWRk5GUr42WRNSuUFsgTERERkcLC1GBxeiB49dVXKVeuHM2bNz/reVFRUYSHh1/Gkl1m1tO7QilYiIiIiIh3KzBjLNLT05kwYQJ9+/bFYrGc9djatWsTGxtLq1atmDdv3hUq4SVkzdlioWAhIiIiIt7O1BaL7KZOncqRI0fo3bv3GY+JjY3l008/pW7duqSlpTF+/HhatWrF/Pnzue666/I8Jy0tjbS0NM/r5ORkABwOBw6H45J+hrNx38vhcGDFio1TLRaOjMwrWhYxV/a6IFc31QXJTvVB3FQXxK0g1IX83NvichWMZZ/btWuHr68vP/30U77O69KlCxaLhWnTpuX5/gsvvMCwYcNy7f/6668JDAy8oLJerPgDv1FzxziW+9TltuNP0DEuk3YlC8SPQURERETEIyUlhW7dunH06NEcY5zzUiBaLBISEpg7dy5TpkzJ97kNGzZkwoQJZ3x/yJAhDBw40PM6OTmZuLg42rZte84v51JyOBzMmTOHNm3a4PvfIdgBwQF+cBzKl69Ix+vLXbGyiLmy1wW73W52ccREqguSneqDuKkuiFtBqAvu3j7no0AEi7FjxxIVFUWnTp3yfe6qVauIjY094/t+fn74+fnl2m+32035Adntdnzs/sCpMRYui0X/cFyFzKqDUvCoLkh2qg/iprogbmbWhfzc1/Rg4XQ6GTt2LL169cLHJ2dxhgwZwq5du/jyyy8BGDlyJPHx8VSrVs0z2Hvy5MlMnjzZjKJfuFwL5KkblIiIiIh4N9ODxdy5c0lMTKRv37653ktKSiIxMdHzOj09nUGDBrFr1y4CAgKoVq0a06dPp2PHjleyyBcva1Yom0uzQomIiIhI4WB6sGjbti1nGj8+bty4HK8HDx7M4MGDr0CpLrOsFgubWixEREREpJAoMOtYXFWyFsizuYxgoZW3RURERMTbKViYwZazK5SzYMz4KyIiIiJywRQszJDVYmFVi4WIiIiIFBIKFmY4bYyFU8FCRERERLycgoUZ3C0WTrVYiIiIiEjhoGBhBs8YC80KJSIiIiKFg4KFGbLWsbAqWIiIiIhIIaFgYYbTBm8rWIiIiIiIt1OwMINNLRYiIiIiUrgoWJjB02JhrGOhwdsiIiIi4u0ULMyQNd2sJWtWKC2QJyIiIiLeTsHCDO4WC5xYcKrFQkRERES8noKFGbLGWADYydQCeSIiIiLi9RQszJDVYgHgQyYZTqeJhRERERERuXgKFmawZQ8WGShXiIiIiIi3U7AwgzVnVyi1WIiIiIiIt1OwMIPF4gkXPmSSqSEWIiIiIuLlFCzMkjXOwm7JJFMtFiIiIiLi5RQszJI1zsKHDDKVK0RERETEyylYmCV7Vyi1WIiIiIiIl1OwMEtWsDAGb2uQhYiIiIh4NwULs3i6QmmBPBERERHxfgoWZvG0WGSoxUJEREREvJ6ChVmyWixsONViISIiIiJeT8HCLFnTzfpYNMZCRERERLyfgoVZbKe6QjldChYiIiIi4t0ULMxiPTV4Wy0WIiIiIuLtFCzMkjXGwk4mmQoWIiIiIuLlFCzMkq3FQsFCRERERLydgoVZbO6VtzMULERERETE6ylYmCWrxcJuUYuFiIiIiHg/BQuzZFt5O1OzQomIiIiIl1OwMIvV3RUqE5cLLZInIiIiIl5NwcIsnlmhMgDUaiEiIiIiXk3BwizZWiwAjbMQEREREa+mYGEW66l1LAAtkiciIiIiXk3Bwiw2tViIiIiISOGhYGEW9wJ5lqwxFgoWIiIiIuLFFCzM4plu1gkoWIiIiIiId1OwMEvW4G1fi7pCiYiIiIj3U7AwS1aLhSdYaLpZEREREfFiFxQsduzYwc6dOz2vly1bxoABA/j0008vWcEKPfesUO5gkalgISIiIiLe64KCRbdu3Zg3bx4Ae/bsoU2bNixbtoxnnnmG4cOHX9ICFlpZs0LZ1WIhIiIiIoXABQWLf//9lwYNGgDw7bffUr16dRYtWsTXX3/NuHHjLmX5Cq+sFgtfz3SzTjNLIyIiIiJyUS4oWDgcDvz8/ACYO3cuN9xwAwCVK1cmKSnp0pWuMLOd1hVKuUJEREREvNgFBYtq1aoxatQofv/9d+bMmUP79u0B2L17NxEREZe0gIVWrpW3lSxERERExHtdULB47bXX+OSTT2jRogV33XUXNWvWBGDatGmeLlJyDqeNsVCuEBERERFvdkHBokWLFhw4cIADBw4wZswYz/777ruPUaNGnfd14uPjsVgsubaHHnrojOcsWLCAunXr4u/vT9myZfN1vwLFvfK2WixEREREpBC4oGBx8uRJ0tLSKFKkCAAJCQmMHDmSDRs2EBUVdd7XWb58OUlJSZ5tzpw5ANx22215Hr9t2zY6duxIs2bNWLVqFc888wyPPvookydPvpCPYS7raS0WmhVKRERERLyYz4WcdOONN9K1a1ceeOABjhw5wrXXXovdbufAgQO8/fbbPPjgg+d1ncjIyByvX331VcqVK0fz5s3zPH7UqFGUKlWKkSNHAlClShVWrFjBm2++yS233HIhH8U8ttPGWGgdCxERERHxYhcULFauXMk777wDwPfff090dDSrVq1i8uTJDB069LyDRXbp6elMmDCBgQMHYrFY8jxm8eLFtG3bNse+du3aMXr0aBwOB3a7Pdc5aWlppKWleV4nJycDxsxWDocj3+W8UO57uf+0uCz4cKorVNoVLo+Y5/S6IFcv1QXJTvVB3FQXxK0g1IX83PuCgkVKSgohISEAzJ49m65du2K1WmnYsCEJCQkXckmmTp3KkSNH6N279xmP2bNnD9HR0Tn2RUdHk5GRwYEDB4iNjc11ziuvvMKwYcNy7Z89ezaBgYEXVNaL4e7uFXNkDdcClkwj9CxesozD69VqcTVx1wUR1QXJTvVB3FQXxM3MupCSknLex15QsChfvjxTp07l5ptvZtasWTz++OMA7Nu3j9DQ0Au5JKNHj6ZDhw4UL178rMed3prhyhqbcKZWjiFDhjBw4EDP6+TkZOLi4mjbtu0Fl/VCOBwO5syZQ5s2bbDb7Vg222Hbu/jZjHLXrVeP5hUjz3EVKQxOrwty9VJdkOxUH8RNdUHcCkJdcPf2OR8XFCyGDh1Kt27dePzxx7n++utp1KgRYLQC1K5dO9/XS0hIYO7cuUyZMuWsx8XExLBnz54c+/bt24ePj88Z18/w8/PzLOaXnd1uN+UH5Lmvrz9wqiuUxWrTPx5XGbPqoBQ8qguSneqDuKkuiJuZdSE/972gYHHrrbfStGlTkpKSPGtYALRq1Yqbb74539cbO3YsUVFRdOrU6azHNWrUiJ9++inHvtmzZ1OvXj3v+4vnmW42A4AMp7pBiYiIiIj3uqDpZsFoPahduza7d+9m165dADRo0IDKlSvn6zpOp5OxY8fSq1cvfHxy5pwhQ4bQs2dPz+sHHniAhIQEBg4cyLp16xgzZgyjR49m0KBBF/oxzGPLuY6FU8FCRERERLzYBQULp9PJ8OHDCQsLo3Tp0pQqVYrw8HBefPFFnPlc6G3u3LkkJibSt2/fXO8lJSWRmJjoeV2mTBlmzJjB/PnzqVWrFi+++CLvvfee9001C2qxEBEREZFC5YK6Qj377LOMHj2aV199lSZNmuByufjzzz954YUXSE1NZcSIEed9rbZt23oGYJ9u3LhxufY1b96clStXXkixCxab8dXbXFogT0RERES83wUFiy+++ILPP/+cG264wbOvZs2alChRgv79++crWFy1rDm7QmmBPBERERHxZhfUFerQoUN5jqWoXLkyhw4duuhCXRWyxljYsrpCZarFQkRERES82AUFi5o1a/LBBx/k2v/BBx9wzTXXXHShrgpWd1coI1ikZ+RvbIqIiIiISEFyQV2hXn/9dTp16sTcuXNp1KgRFouFRYsWsWPHDmbMmHGpy1g4nTYrVKoj08zSiIiIiIhclAtqsWjevDkbN27k5ptv5siRIxw6dIiuXbvy33//MXbs2EtdxsIpq8XCmtVioWAhIiIiIt7sglosAIoXL55rkPaaNWv44osvGDNmzEUXrNDLGrxtxYUVJycVLERERETEi13wAnlykWynMp2dDE6ma4yFiIiIiHgvBQuzZLVYgDHOQi0WIiIiIuLNFCzMYjsVLGxkaoyFiIiIiHi1fI2x6Nq161nfP3LkyMWU5epizd4VKpOT6QoWIiIiIuK98hUswsLCzvl+z549L6pAVw2LxQgXzgx8yCRFLRYiIiIi4sXyFSw0lewlZrWDMwO7JZNUtViIiIiIiBfTGAszeRbJy9DgbRERERHxagoWZsoaZ6FZoURERETE2ylYmCmrxUKDt0VERETE2ylYmMnq7gql6WZFRERExLspWJgpa/Vtu8ZYiIiIiIiXU7AwU7YWi5OOTFwul8kFEhERERG5MAoWZnIP3rZk4nJBWobT5AKJiIiIiFwYBQszebpCGd2gNM5CRERERLyVgoWZsrpC+VuNlgqNsxARERERb6VgYaas6WYDfbKChaacFREREREvpWBhpqwWi0CbMWg7RcFCRERERLyUgoWZssZYBPgYwUJjLERERETEWylYmCmrxSJAYyxERERExMspWJgpa4yFu8VCYyxERERExFspWJgpax0LzQolIiIiIt5OwcJM7hYLmxEsNMZCRERERLyVgoWZssZY+Fk13ayIiIiIeDcFCzPZTu8K5TSzNCIiIiIiF0zBwkyelbeNlgqNsRARERERb6VgYSZbzq5QGmMhIiIiIt5KwcJMWbNC+VqyWiw0xkJEREREvJSChZncwSKrxSJFwUJEREREvJSChZmyukK5WyzUFUpEREREvJWChZmyBm/b0eBtEREREfFuChZmyppu1q4xFiIiIiLi5RQszORusbC417FQsBARERER76RgYaasMRY+aIyFiIiIiHg3BQszWd3BIgNQi4WIiIiIeC8FCzNljbFwt1hojIWIiIiIeCsFCzO5WyxcmhVKRERERLybgoWZssZY2LK6QmmMhYiIiIh4KwULM2WtvG1zGcHCkenCkek0s0QiIiIiIhdEwcJMWS0W1qxgAeoOJSIiIiLeScHCTFljLCzODKwWY1eqBnCLiIiIiBcyPVjs2rWLHj16EBERQWBgILVq1eKvv/464/Hz58/HYrHk2tavX38FS32JZHWFsjgdBNhtgFosRERERMQ7+Zh588OHD9OkSRNatmzJzJkziYqKYsuWLYSHh5/z3A0bNhAaGup5HRkZeRlLeplkTTdLZgYBvjZOpGcqWIiIiIiIVzI1WLz22mvExcUxduxYz774+PjzOjcqKuq8AkiBltUVCqcDf3eLhbpCiYiIiIgXMrUr1LRp06hXrx633XYbUVFR1K5dm88+++y8zq1duzaxsbG0atWKefPmXeaSXiZZg7fJVFcoEREREfFuprZYbN26lY8//piBAwfyzDPPsGzZMh599FH8/Pzo2bNnnufExsby6aefUrduXdLS0hg/fjytWrVi/vz5XHfddbmOT0tLIy0tzfM6OTkZAIfDgcPhuDwfLA/ue2W/p8VpwQdwZTrwtxsZ7/jJ9CtaLrny8qoLcnVSXZDsVB/ETXVB3ApCXcjPvS0ul8t1GctyVr6+vtSrV49FixZ59j366KMsX76cxYsXn/d1unTpgsViYdq0abnee+GFFxg2bFiu/V9//TWBgYEXVvBLJCxlOy02DCXVJ5xOlg/ZcsxC74qZ1I4w7UciIiIiIuKRkpJCt27dOHr0aI7xzXkxtcUiNjaWqlWr5thXpUoVJk+enK/rNGzYkAkTJuT53pAhQxg4cKDndXJyMnFxcbRt2/acX86l5HA4mDNnDm3atMFuz+oCtW8dbAA/Xx9KRBRjy7GDVKl+DR1rl7hi5ZIrL8+6IFcl1QXJTvVB3FQXxK0g1AV3b5/zYWqwaNKkCRs2bMixb+PGjZQuXTpf11m1ahWxsbF5vufn54efn1+u/Xa73ZQfUI77+gUAxnSzQX7GvnSnRf+IXCXMqoNS8KguSHaqD+KmuiBuZtaF/NzX1GDx+OOP07hxY15++WVuv/12li1bxqeffsqnn37qOWbIkCHs2rWLL7/8EoCRI0cSHx9PtWrVSE9PZ8KECUyePDnfrRwFgjXbdLNZg7e1QJ6IiIiIeCNTg0X9+vX54YcfGDJkCMOHD6dMmTKMHDmS7t27e45JSkoiMTHR8zo9PZ1Bgwaxa9cuAgICqFatGtOnT6djx45mfISLY8s23ayvESxSFCxERERExAuZGiwAOnfuTOfOnc/4/rhx43K8Hjx4MIMHD77MpbpCrJpuVkREREQKB1PXsbjquVsscBGYFfFSFSxERERExAspWJjJeqrBKMhuTDGrlbdFRERExBspWJjJdmqUfaAtK1ioxUJEREREvJCChZmytVgoWIiIiIiIN1OwMFP2YOFjBAqNsRARERERb6RgYSaLxRMuAmwaYyEiIiIi3kvBwmxZU84G2JyAukKJiIiIiHdSsDCbTcFCRERERLyfgoXZTusKlaquUCIiIiLihRQszJbVYuGvWaFERERExIspWJgta4yFn9UIFClqsRARERERL6RgYTab0RXK32qMsUjLcOJ0uswskYiIiIhIvilYmM3TYuH07ErNUKuFiIiIiHgXBQuzZY2x8OVUsNBaFiIiIiLibRQszJY1K5TVlYGfj/Hj0ABuEREREfE2ChZmy2qxwOkgwNcGQKqChYiIiIh4GQULs2WNsSDTQYDdCBYn051nOUFEREREpOBRsDBb9hYLd7BQi4WIiIiIeBkFC7NZjTBBZgb+ChYiIiIi4qUULMxmzT3GQrNCiYiIiIi3UbAwm2+Q8WfaMQI1eFtEREREvJSChdnC44w/j+zwdIVKUYuFiIiIiHgZBQuzhZUy/jySoMHbIiIiIuK1FCzMFu4OFomeYKGuUCIiIiLibRQszOYOFkd3aPC2iIiIiHgtBQuzucdYnDxMqOWk8Z9qsRARERERL6NgYTa/EAgoAkCUcz+gYCEiIiIi3kfBoiAIM1otimXuASBVXaFERERExMsoWBQEWeMsimXsBeDAiXQzSyMiIiIikm8KFgVBeGkASlkPALA68TBOp8vMEomIiIiI5IuCRUEQ7u4KtY8Au43k1Aw27z9ucqFERERERM6fgkVBkNUVyno0kVpx4QCs2H7YxAKJiIiIiOSPgkVBkDV4myM7qBdvzBC1IuGQiQUSEREREckfBYuCwL1IXsoB6pfwA+CvBLVYiIiIiIj3ULAoCALCwS8MgDphx7FYIOFgCvuPpZlbLhERERGR86RgUVBkDeAOPplEpegQAP5SdygRERER8RIKFgWFuzvUkQTqljbGWSzXAG4RERER8RIKFgWFJ1gkZhvArWAhIiIiIt5BwaKgyD4zVOmiAPy36ygn0zNNLJSIiIiIyPlRsCgosrVYlCwSQHSoHxlOF2t2HjG1WCIiIiIi50PBoqAId7dYJGKxWDytFpp2VkRERES8gYJFQRFe2vjzxD5wnPQM4P5z8wFS0jNMLJiIiIiIyLn5mF0AyRJQBHyDIf04HN1JvfhIABZtOUiNF2ZTKTqExuUiuK95WaJC/E0urIiIiIhITmqxKCgslmwDuBOpUSKMXo1KExvmT6bTxdqkZD7/YxvXv7mAUQu2kJahQd0iIiIiUnAoWBQk2QZwWywWht1YncVDWrF4yPV80K02NUuGcTwtg1dnrqftOwtZs+OIqcUVEREREXFTsChIsgWL7GLDAuh8TXF+6N+Et26rSVSIHwkHU+jx+VIN7hYRERGRAkHBoiBxB4ukNXm+bbVauKVuSX59ojnXlinKsbQMeo5eyvLth3Id68h0MnftXkYt2EJyquNyllpERERExPxgsWvXLnr06EFERASBgYHUqlWLv/7666znLFiwgLp16+Lv70/ZsmUZNWrUFSrtZVahLVissOVX2LbwjIeF+NsZ26c+jctFcCI9k15jlvHer5sYv3g7U1bu5IVp/3Hty7/S78sVvDpzPZ3e+53V2bpNHT6RzheLtvP7pv1X4EOJiIiIyNXA1FmhDh8+TJMmTWjZsiUzZ84kKiqKLVu2EB4efsZztm3bRseOHbn33nuZMGECf/75J/379ycyMpJbbrnlyhX+coiqDPX6wvLPYebTcP9CsOX9Iwr09WF0r/rc++UK/th8gLfnbMx1TLFgP3xtFnYcOsmtHy/ikesrsCf5JFNW7iItw4mP1cK3DzSiTqkil/uTiYiIiEghZ2qweO2114iLi2Ps2LGeffHx8Wc9Z9SoUZQqVYqRI0cCUKVKFVasWMGbb77p/cECoOWz8M/3sO8/WDkO6vc746EBvjY+71WP0X9sY9uBExxPzeB4WgbFgn25sXYJmpUvxon0TJ6Z8g/T/0ninbmnwkd4oJ0jKQ4e/mol0x9tRpEgXwC2HzjB3HV7qRQTQsOyEdhtpjdqiYiIiIgXMDVYTJs2jXbt2nHbbbexYMECSpQoQf/+/bn33nvPeM7ixYtp27Ztjn3t2rVj9OjROBwO7HZ7jvfS0tJIS0vzvE5OTgbA4XDgcFy5sQfue53znvYQrNc9jW3207h+e4mMSjcYa1ycgQ24r2npPN9zOTMJ9IF3bqvOtWXC+XDeVmrGhdGncWkqRYfQddQSth9M4fFJq/ike20mr9rNi9PXcdLhBCDU34eWlSIpFxlEgK+NQLuNcpFB1CkVjsViuaDvQfJRF6TQU12Q7FQfxE11QdwKQl3Iz70tLpfLdRnLclb+/sZCbwMHDuS2225j2bJlDBgwgE8++YSePXvmeU7FihXp3bs3zzzzjGffokWLaNKkCbt37yY2NjbH8S+88ALDhg3LdZ2vv/6awMDAS/hpLh2LK5MW6/9HaOoutke0ZE1cb2Odi0ts5wl45x8bGS4LsYEuklKMe5QIdHE0HY5n5H3PuCAX1xd3ck1RF7tTYNNRCztPWCge5OKaoi6iAy55UUVERETEBCkpKXTr1o2jR48SGhp61mNNDRa+vr7Uq1ePRYsWefY9+uijLF++nMWLF+d5TsWKFenTpw9Dhgzx7Pvzzz9p2rQpSUlJxMTE5Dg+rxaLuLg4Dhw4cM4v51JyOBzMmTOHNm3a5GpVyYtl20J8vu4KgLNiBzI7v3fWlosL9c3ynTw3bS0APlYLA1qVp1/TeABWJh5hwcYDHDyRzsn0TI6nZbBk2yHSMowWDZvVQqYzd/UpWyyQO+vH0bNhKWxWtWycLr91QQov1QXJTvVB3FQXxK0g1IXk5GSKFSt2XsHC1K5QsbGxVK1aNce+KlWqMHny5DOeExMTw549e3Ls27dvHz4+PkREROQ63s/PDz8/v1z77Xa7KT+g875vxVbQ4Q2Y9QzWjTOxft4Cun4G8U0uaXl6NIpn19E0ViYc5tlOVagZF+55r3GFKBpXiMpx/MHjaXy5OIEvF2/ncIqDEH8fGpaNoEaJMFYmHubPzQfYeiCFl2du4Nf1+3n7jlqUCD/VhOFyudSNKotZdVAKHtUFyU71QdxUF8TNzLqQn/uaGiyaNGnChg0bcuzbuHEjpUvnPWYAoFGjRvz000859s2ePZt69eoVvr98194HcQ3g+75waAuM6wjlWkGj/safl+AB3WKx8HSHyud9fESwH4+3qciDLcqx+8hJSkcE5WiVOJbqYOqqXbw6cz1Ltx2i/ciF3N2wNImHUvh751F2HzlJvfgitK0aQ5uq0cQVLZjd0UREREQkf0yd8ufxxx9nyZIlvPzyy2zevJmvv/6aTz/9lIceeshzzJAhQ3KMt3jggQdISEhg4MCBrFu3jjFjxjB69GgGDRpkxke4/IrXgvsXQO0ep9a4mHALfNQI1s8Ak3qy+dttlI0MztXVKcTfzt2N4pnxWDPqlArnWGoGH83fws9/J5F4KIUMp4slWw8x/Oe1NHt9Hrd/spjZ/+3BmUeXKhERERHxHqa2WNSvX58ffviBIUOGMHz4cMqUKcPIkSPp3r2755ikpCQSExM9r8uUKcOMGTN4/PHH+fDDDylevDjvvfde4Zhq9kz8QuDGD6HZIFj6CawaD/vXwTd3QYV20OFVKFrW7FLmUDoiiG/vb8S4Rdv5Z9dRKseEck3JMKJD/Vi48QCz1+5h2bZDnq1MsSDaVI3GZrVgAUID7HSoHkPpiCCzP4qIiIiInAdTgwVA586d6dy58xnfHzduXK59zZs3Z+XKlZexVAVU0TJGiGg5BP54BxZ9AJtmwdb5UKsbVL0R4puCrWB0CfOxWenXLHfgKR8VQt+mZdhzNJVxi7bz9dIEth04wacLt+Y47tWZ67m2TFFurVuSqsVDiQz2o2iQLz5aW0NERESkwDE9WMgF8A+D1i9Are4w40nYOg/+Gmts/uFQriXE1oSYGhBdA4KjLst0tRcrJsyfpztU5pHryzNl1S627T+BC6NL1OZ9x/lj8wGWbjvE0m2HPOdYLBAT6k+pooHERwRRrUQoXeuUJNhPVVlERETETHoa82bFKsDdPxgtFmunwvrpcGI//PeDsbn5hhitHRHloUJbqHoD+BacLkZBfj7c3TD3gP3dR04yZeVOZq/dS9LRVA4eT8PpgqSjqSQdTTUCxwp4c9YGejWOp3fjeCKCc88AdjpHplMriouIiIhcYgoW3s5iMVooyrWETm9D4hLYsRT2/AN7/oaDWyD9mPHfe/6G/6bAjEFGt6myLSA4OmuLMtbJKEAtG8XDA3j4+go8fH0FADKdLg6eSGPn4ZMkHkxh24ET/PT3brbuP8H7v23mk4VbaVg2gusqFKNZhUgqRgfnmNp2xfZDvDh9HZv3HuODbnVoWTnqTLcWERERkXxSsChMrDZjnYvsa104UuFIghEw9vwNf0+CQ1th9VfGlp3NF4KiIDQWyjSHSh2heG2wFozf7tusFqJC/IkK8adOKWOxwEdbVWDO2j18NH8Lf+88ysKN+1m4cT+wjqgQP5qWL0bj8sVYuHE/09bs9lzr/gl/MbZ3fZqULwZAqiOT6X8nUTE6hBolw8z4eCIiIiJeTcGisLP7Q2QlY6vcEZo/ZbRo/D0JDmyC4/vg+F5IPQKZ6ZC809h2Loff34TgGChznbGeRsn6EF3tyg8OP7oTDicY5Ty+D1yZ4OMP9gBsYSVpX7Up7arFsGHvMf7YdIDfNx1g6baD7DuWxpRVu5iyahdgNMbcXjeOgyfSmbtuL/2+WMG4PvXZk5zK679sYNeRk/j5WPmibwMals292KKIiIiInJmCxdXGYoFSDY0tO0eqMT7j+D44sBE2/gKb58LxPfDPt8YGxloaIbEQVhLCS0OJulDqWoiufukDh9MJc56DxR+c/bjw0ljq9aFy7bup3Kws/ZqVJdWRycqEwyzcdIDFWw8SEeTLwDYVqV4ijLSMTO778i8WbNzPHZ8u8VzGbrOQluGk3xcrmHhvw1wtF6mOTDbuPca2AydoXK4YkSHnHs8hIiIicrVQsBCD3R/C44ytZF2odRdkpEHCIqOFY8dS2LkC0pIheZex7Vh6KnDYAyGqKkRVMf4sWhZCoo0Wj6BIsOWzqmWkwQ/3nxqEXrSsca3gSLDaISMVHCdh1wqjq9fcF+C3EUarStkW+JduROOj22h8YgGk/A4Of1jbFXzuwC+6Kp/cXZd+YxaxYVsiEb4OetWPpnPVIgycdZg5iRn0GruMj7vXYU9yKku2HuSvhMNs2X+CzKyF/KrGhjLt4Saa+lZEREQki4KFnJmP36mB4WC0IJzYZ3RNOrrTaNnYsQx2LoPUo8ZD/q4Vua9jsRrhIiTGGMPhG2QEEXsABBUz9ofEGgsBYgFcMO8VSPjDCBE3fQTX3J53GdNTjAHpy0fD7pWQuMjY8vLnSGMLKY5/+gkmpB0F/6z3/jK2z4DtQaWZl1aZUZ9fwx/OGjiy/TUpEmgnLcPJ2qRkvvh9I/ccetsIOI0eNlpuRERERK5SChZy/qzWrBAQAyXrndrvdMLBzbDvP9i7FvatNYLHsT1GEHE5s8ZH7M3f/fxC4Y7xxuxVZ+IbCLV7GNvBLbBtAWxdYIwRCStpnFumOaQcgDWTYNNsOLY72wUsWUEnwBi8nryL+MwE+vgk0IdZHLcEsSniejKr3kLJOu2JDvPnuxU7GTz5b/x+GwrWWcZl1k2D0k2hzt1G0DixHzIdRrmK5J5KV0RERKSwUbCQi2e1QmRFY6t2c873nJlw4gAcSzo1+NpxEjJOQvoJ4wH82B5I3g2OlFPnBUVBh9cgpvr5lyOinLHV65v3+1VvhJRDRktLQBGjFcU/POesVycOwvbfydw6H8uGGQQf30vtAz/Bwp/gyB3Q5T1uq1eSXX9+TY8jRqhwVe4MG2dhSfjDaGXJbtV46PWTseYIQKYD65IPqLJ7BWS2BnvBWCVdRERE5GIpWMjlZbUZYy1Cos0uiSGwaO6B69kFRUC1m7BVuwk6vQWJi+Gf72DleM9UvZY2w3nsxHsAfJRxA8tPPsKm1Pb0tk6nlnULKbZQalepSMi+v+DABhjXCXr9bAxun3Ivtp3LqQg4p/WHW8cY35GIiIiIl1OwEDkTqw3imxpbtZvh215GF6uxHbACO0Nr89a+28jcsB8oyp8VBvLdkVQ27D1Gia0BTOn1DNFT74S9/8LYDsaA9PRjuPxCcKWnYF07FX4Ogy7vFqiFCUVEREQuhKa0ETkfZVvAvb9BRHnjdWAxivWeQPPKsTQpH8Gk+xoytk8DxvdrQHxEILuOnOSur7aw+vovcEVXN8Z4pB+DuGvJuHchf5V+EJfFCiu/gFnPwu7VsHuVsR3aagyGd7nM/MQiIiIi+aIWC5HzFVEO+s2Fv8ZBxfb4Fy3JmN4lcxwSFeLPV/c25PZRi9l64AQ3jd1AnP/jvBbyHWnh5VhVsjusTOek61pqdyyPz/QBsORDYzud1QdiroG6vaHGrcYgcxEREZECSsFCJD8CikDTx896SInwACbe25A3Zm9g4cb97DgJ3VJ7wn5g0/aso2yExDXm0c7vwB8jjVXPLVajlSItGdKPgzPDmEJ390qY/T9jhqnr/6eAISIiIgWSgoXIZVAqIpD376pNptPFmp1HWLT5AIdTHGRkOtl/LJUZ/+7l7bmbCezUgn4D8pjFypFqzKK19kdYMQYOb4MlH0HCn3DXJAiNvfIfSkREROQsFCxELiOb1UKdUkWoU6qIZ5/D4cB1ZCYzd9p4afo6MpwuAuw2Fm7cz8rEw/RsFM/jbSoa6180edRYfG/TbPixPyStgc+uh26TIPYaEz+ZiIiISE4avC1ignYlXdzXLB6AV2eu5/lp//Hr+n0cTnHw7q+b+G7FjlMHW61QqT30+xWKVTQW+BvTHjbNyXnRk0fgy5vgo0awdf4V+iQiIiIiBgULERNYLDCoTQXuv64s/nYrjcpG8FT7yvRpEg/AMz/8w4rth3KeVLQM3DPHWEnccQIm3gn/fG+8l3IIvrwBts4zVj7/8kaY9ogRNkRERESuAHWFEjGJxWJhSMcqDOlYxbPP6XSx52gqM//dw/3j/+LjHnXZfeQkf+88SnpmJnc1KEW1HpNh6oPGwn2T+8GRBPh3irFeRmAxqNgeVk+AlV/ChpkQ3wxiahgzTMU3Bbu/iZ9aRERECisFC5ECxGq18NbtNUk8lMJ/u5O5/ZPFOd6fsCSR1lWieLjl69QKKArLPoFfhxtvBkdDz2kQVRlqdTNaLA5tgf+mGBtAaElo+QzUvFMrfouIiMglpa5QIgVMoK8Pn/WsR4nwAPztVuqWLkLvxvF0viYWiwXmrtvHTR8t5tEjd3KiyVPGSSHFofcMI1QAxDeB/ouhxxRoPQyq3wrBMZC80xgE/nET2LrAvA8pIiIihY5aLEQKoOLhAfw+uCUujJml3B7ff5yP5m3hh1U7mfZ3EgsD6/FG86m0blgLS0CRnBfx8YPyrYwNjClsl30Kv78F+9fBhFug51Sje5SIiIjIRVKLhUgBZbVacoQKgHKRwbx1e02mPtSEKrGhHElxcO+sFB6eso2MTOfZL2j3N6avfWw1VO4MTgdM6gEHt5w6Ju0YbJwNe/6BjLRL/6FERESk0FKLhYgXuqZkONMebsLnv2/jnTkbmf5PEn4+Vt68rSbW08JILgFF4JbPYVwn2PUXfH270Y3qvx9g4RuQcsA4zupjTG9boo4xALx0EwiPy3mt1GRjjY2EP6FoOaN1JLKyMe2ViIiIXFUULES8lN1m5cEW5SgfFcwDE/5iyqpdBPv7MOyGaljO9WBvD4A7J8LnreDgZninmtGCARASC44USD1qTF27by2smmC8F1gMQosbW2Y6bP/D+NNt9rMQWgLq94Omj+cMGI6TkLjYCCg+fpf2yxARERHTKViIeLk2VaN5+/aaDJi0mi8XJ3AiLZMaJUIJ8vMhJsyfxuWK5epSBUBINNz1DYxpB+nHjcHdLZ6C2ncbrRXJuyDpbyMMJPwJu1cbrRkpB2DP36euU6wilGsFBzYaxyXvgl+HGbNONXnMOCbtGIzvCjuXQVxDuGsiBBa9It+PiIiIXBkKFiKFwI21SnA8LYNnf/iXySt3MnnlqfcalCnKm7fWpFREYO4TY6pD31+M0FD9FvDNdkxYSWOr3NF4nXYcDm2FY0nGlpEGZVtAZKVT5zhOwuIP4bcXYc5Q4/yK7eHrO4xQAbBjCYztAD0mG+9fCmnHYPNco4xOB7icRtgpWubSXP9iuFywY+mp71NERKSQUrAQKSS6X1uaiCBfflu/jxNpmRxPy2DF9kMs23aI9u8u5H+dqnJXg7jc3aRiahjbufgFQ+w1xnYm9gC4bhCcOABLP4YfHjCuvesv8AuFjm/A3GGwfz2MbgvNngB7oNE1KizOGM+R3/U1EhbBlPvhaOJpZQmEjm8aa3qYNeYj5RBMH2iMXwkoAn1n5QxiIiIihYiChUgh0r56LO2rx3pe7ziUwhPfrWHZtkM888M//Lh6F891rkr1EmGXtyDtRsDRHbD+ZyNU+AYbLRRxDYwxFhO6Gl2npg/MeV5gMajYDip1gPJtcq8Snp4C6SfAkjWh3eL34Y+RgMtY/C+6GtjsRnes3auMNTu2zofOb4NfyOX9zNllOozxJ1P7w7Hdxr6Th43uYP3mGGNUAMuOJVTZ/R0crAAxVa9c+URERC4DBQuRQiyuaCDf3NuQMX9u441ZG1i67RBdPviDW+uU5Im2lYgJ8z/3RS6E1WbMPDXxTmOcxh0TjFABxsxSfWfBgtfgSKLRpSojFfb8a4zfWP2VsfmFQbWboMoNRgvHplmQsPjUIPPsavWA9q+Af6jx2pkJf7wD816Gf741wkX1rlDtZijZAKxnmGnbmQlrp8Ki9+HYHiPkVL/FCENna0lJPwGznjVWOE8/Ac6MU+9FlIcOr8HMp+HgJmP9kJtHwe9v47N2KhUB1yczoG5vaPE0BEfl++vON8dJI+j4hYA96Mzfh4iISD4oWIgUclarhX7NytKhRiyvzVzPtDW7+e6vnUxZtYsWFSO5rV5Jrq8cja/PJX64tAfA3VONh2ybPed7gUWNh+3sMh1Gt6YNM2HdNKPVYeUXxnYmwTFG96qqN+Tcb7UZXbLim8LkfkbrydJRxhYSC+WuN7bSTYwgcGQ77N8Ay0fDoWzrevw1ztiCIo0uXREVoFgFKFEXYmsa90n6G77va4SG7Cw2qNsL2r4EvkFGi83otsYsW59cB4DLYuVIQGmKpGyDFaPh70lQ9UajXKUbQ5H4S9uNKyPN+A4WvAHpx9wFNQKGe/MPMz5ndDVjK1Hnyrb2iIiI11KwELlKlAgP4L27atO7STyvzlzPsm2H+HX9Pn5dv4+IIF96NCzN3Y1KUyz4Ek4Fa7HkDhVnYrND2ebG1u5lSPgD1kyCrfOMh/kKbaFCO4goZwyIdjmNLlFn+217qYbwyF+wZZ4xzmH9dGPgubtVJC8BReDaB43wsHaqEXJO7Ictvxmbm18YxNWHbb9DZpoRWG5433gYtwcYLQE+vqeOL1LaCBdjO0BaMpRtQcb1w1j4VwKdqoXh89sw2L0yZ9lCSxgBo3QTKHOd8dlPd2ibEVyyt3Skn4DVX8P23yGkuHGePRB+f9MYgA+ABXAZW1qysbntWHrqv612owwV2kJ0VWMa4pOHjZ9BpY4Qeqrr3VmlHYOdK4yAFlTs/M4RERGvomAhcpWpU6oI397fiM37jvHdXzv5YeUu9h1L491fN/Hxgi10rV2CJ9pWIjLExLUmrFbjQbrMdXm/b7EA59nC4uMHldobmyPVmBJ36zzYMh/2/mM8cBeJh/DSUKYZ1OllDFQHqNAaOr1tjBM5uAkObDK6ZSUugbSjxkxUYMx8deNHEBRx9rLEVIcHfofj+6BkfcjIABJwlW4C9/5mdNnatsBoudm10mi1+ec7YwNjocIG9xn32zQLFn8EiYsAixGEKrU3QsWKsZB6JO8yBEdD6xfgmjuNLmjpx42H/rRk48+Ug7BvPez912iNOZpolGnbgtzXmvGk0V2s5l1G+Nr+h/HdBBWDhg9C9VuNVp3VX8GvL8KJfUZQqdwR6vSEsi1zdjFzOmHNROM6194HxWuf38/4dKnJxrgedfESEbmiFCxErlLlo0IY0qEKT7atxC//7eGz37exZscRvlm+g0VbDjLhnmvznqLWm9n9jdXBy7cyXjtOgo//2bsb+fhC6UbG5paZAXvWGAEgrCRUven8uywViTe201ksUK6lsYExUH3nciMIbf/TWE9k++/GZvMzWknA6HLlyoRdK4zNrWhZY0as1KNwcIsRUsq1gmYDT3Vt8g00ttPHdVTL9t8Ht8DGWcYK68f3gn+40aqTcsBo2dgww9iyO7Ybpj5ohInACCPAgdHNKvUorP3R2EJLQu3uUKu7Ub5fnoakNcaxayYa710/1Fhz5Xw4ncaA/l+HQ5Ey0PF1o8tbXvb+Z7RiVe504QFGRERyULAQucr52Kx0vqY4nWrE8lfCYQZ+u4bEQyncMmoRX/ZtQJXYULbsP870v5M4dCKdclHBlI8MpkpsCOGBvue+QUFmD7iw82w+RgtBibqXtjzZ+Qae6hoGcHSnMQZk5RdGq0JAEajbBxrcC1hg4y/Gw78z0xjbUbF9/qfuzUtEOWjU39hOt38D/PWFESzCShotKqUbGV2elo4yAsax3Ua3seaDjdaWAxtg5XhjPEnyTmMQ/4LXMbplYUxLXKqR0SKzagL8NxUiKxsB0MfXaIkIKGJsocWN7m7R1Y3A8sMDxnlgtDCNvxmqdIFmg4xxPfYgYzayP0ca3xfA728b43GaDcrZdU1ERPJNwUJEALBYLNSLL8r3DzSi55hlrN9zjDs+WUxc0UD+252c63h/u5WPu9elZeUrMIuRGA/urZ+H5k8Zv22PqmyMrXCr18fYrqTIStD+ZWPLrsx10OghowvX4QQjUARHGu/F1DBaEtoMN6YjXvml0c3KYjW6obV81jh2x3L45SmjG1r2lpi8+IUZY3RSDhitOe1GGGNJln4C634ytlwsRte0Pf8Y4WbDTKNL19GdcCTBGOgeUd4Y3xMSA3vXGmNgDmyEMs2N8ru7zGWkw+9vGa1JxWsb41FKNbrwoHIsCX4dapSxw2tXZqYwEZFLQMFCRHKICvVn0n2NuOeL5axIOMx/u5PxsVq4rmIk5aOC2bLvOOuSktl9NJUnvlvDL481Iyr0Mk1bK7nZ/aHkZWwpuVR8/KB2jzO/b/eHGrcaW/JuI1iExJx6P64+3DPXWLE95ZDR9SsjzRgHcvKIMYD8wEajO1baUeOciPJw27hTCz7W7gGznzMCQXqKcQ2bH9S8Exo/CsXKw7+TYfoTsOdvY8tu85y8y35wszFOp+vnRqvXlPtOdfdK+BMWf2C0rJSsByXqGeNpwktlDeoPhIBw4/vJQ8zRlfh8NgBOHjJ2bP/DmJ7Y3X3vbJxOo1vcuSZMOLYXrD7nHhN0eLuxHd9vjI85eQQcWWvJ+IdCo0dOBUYRERQsRCQPYYF2xt9zLZ/9vpWIYF86VI+laNCp376mZWRy84eLWJuUzBPfreGLPg2wWk1a3Vq8X9aCgblYrUZXp7PJzDAe6o/ugrItTrUigDFD191Tch6LK+eDd/VboHRTWPCqsWJ8kdLGQH6rjxEgDmw0WhCKVTKm3g2OhjnPGy0iY9oagSgzHQKKQtPHs9ZcmWM8iG+db2y5PpfdaNko3QiK1zHOP3kE266/uHbrN8YxMTWMoLDvP2NByTo9jTEqKYeMgfaRlY3vpkQ9o0vav98b3cZcTmPdmOxjgtxOHja6nS37FHwCjBBWofWp952Zxgxqm2Yb2+FtZ//ut8yDPjNzfucXK3m3MQFAhbaX9rpmcWXNumYPMrpQihRyquUikqcAXxuPtqqQ53t+Pjbeu6sWnd//g983HWDMn9vo16zsFS6hCMbDWvHa5zcA+0wPdiHR0Pmd879n+Vbw8+PG4G8wxrN0ee/UIHN3INi53BhvsnOF0U3LcdLYnA6jJWbnshyXdc9hldnwIWytnzdCwqxnjTVOVn6Zswx5du/KMv4mIzRU6mC8TjsOq8YbXb5OHjb2pR+Dr2+DDq9D/X6w+VeYM9Qot6dAdmOMTVCk0R0roIjR4mIPhOWfGy083/WGu77J/0Ozy5VzwoP0FGNhyj9HGq0igcWMoFavrzHeqCBwOo0JDAKLnrHFidRkY2KC9dONYHZ0pzHzWkyNrBCmNWEuq9Rko4tlUKQxWUVBmBnOcdIYAxYcnfckHymHjKnMt/9hTN5R9cYrX8ZLSMFCRC5I+agQ/tepKv+b+i+v/bKeIykO/O1WbFYrQX42wgLshAbYKRkeQPmoYCzZ/kE9mZ7Jn5sPUL1E2OVb/VvkcgkoAreOhRq3GwtAVumS84HBajUeJGNqGA/G2blcRveixMXGrGL71hpjZQKKkOkXzuJjxbm21RPYfLJaVTq/bfz2fsN0Y2B7YITRpSppjfGb/cPbjG5XlTsbK9X/Nc4YmP5Nd7j+f8a9/p1sPNwCRFYxxoes/RFWT4AZg4yQsH+98b5/mLFCfYW2xliZMz0IV2gL4zoZ3cWmD4Qu7+b8Do7tgcUfGg9LjpOQcdKY7tn9Z2aa8VkiKhjhZdtCYyFLMD5nygGY/Swses+Y0jiqqtFKU6Ku0Q3rTA5tNVqJipY1xsJcyAKTm+fCprlZ3e/SjRB2cKvRgpVx0vi+y7eCih2MMTjHkoyWlp0rjMCXcTL3Nff8Y3SZu+Orcz/sulxY1v9M2X2zseyOMbo+2nyMYHN0h3Gv2JoXFrjSjsMf7xgtbdc9mXscUKbj/NceuhJOHjZmojv953h4O+xYZrR2Fok3WhiXfmJMcOHuGlm0rDG+q1b3s9eZ0+3faIztim9idGG8GBtmGou0ph83/m5FVjbWJ8pMN7YT+42/yy6ncfxfY6Hjm1mTcngni8vlcpldiCspOTmZsLAwjh49SmhoPiraRXI4HMyYMYOOHTtitxegv7RyxRWmuuByubhv/F/MWbv3rMfFRwTSoUYsdUoVYe7avUz/J4njaRlEBPnyRd8GVC8RdoVKXLAUprogF++C6kPKoaxWhKyAnpkBPz1mhIbsipaFxo9A7Z7GQ6rLZTxg/jrMeN/mazyENXvC+I38+Vg/AyZ1Nx6KSjeBuAYQc40RJlZNODUl8vkKLQlth0OVG2DNN7DwdTiSmPMY3xBjjZNGDxvldGYaD2ab5hgP9e6xLmCEkUYPQfk2Rte05CRj7IrVx3h49vE3yute5DHlEMx8Cv75Nn/lPl1EeWMcT4m6EBZnrFsz/mbj+2g2CFo9Zxznchn3DCx66sH56C6Y9ghs+TXbZw6GomWMxTDdATG0BLR9Eap1zfnQ7XQa4WrPGiOAlGxgjPWx2mDrApj28KnvtHQTuH28MdYm9SjMHWYE0ypdjIdb9/gZZ6axUOief43xQQFFjBaB4nVyjrE5tM3oQhcUCdW75vxO0o7B6onGz2f/BmNNoMCIUwuAlqhrTFBh9zfCzYYZsGKMERJja0GXkUarpMtltODN+l/eAQ6gaDmjW6M7YPiHQ/tXjZ/JuYLmv1Ngav9T1y5WEeKbGiHg+D5jRr74ptD86XMHu6WfGhNQuEPD2URVMz6/e1a7VkONv4sUjP9P5OfZWcHiCikIFUMKhsJWF46lOvhi0XaSjqaS6XThyHSRkp7B0ZMOjqQ42LL/OGkZuf9h9fWxkp7hJMTPh9G969OgzHk+zBQiha0uyMW5ZPXB5YJ5I4yWiPJtjOmHSzfJ+6Fq0xxjVq76/fJeX+Vcln1mtHrkJe5aI6wERRqtLD7+xmb3NwbRH9+TNY5ls/HAWvvunA9rGelG68uev2HfulMLNoLxsB3f1PittXugOxjrupSsb7QQOE6c32eIqmb8dvq/qUYAsViNNWDC4owAYg801kUpVsH4Dfaev2HDL7BxphEMQmKNcFIk3ljTpkTd3N/1mm/gh/uN/271vNGlav10owUiONr4+RSrAEtGQdpRXD7+7AuoQJQjEUvq0VPXsdqNFi73ApilmxjdZw5uObWApzt8uAUUhdhrTo33CYszgkRasjGeqMljsPBNY2ro7Od0fMP47wWvGWON8hJRwRh7tOcfo/XNrWF/aPuSEWgOJ8DEO3O+fyZBUcYEBCkHc+63WKHB/UYLnXuq6MgqRlg7kmi0HJZsYHSfq9je6E739zfG93lwk3F8hbbQ5kVIWm0EiG0LIbqqMX6p2s3w53vw+5tZ31EpYzrsM4WCImXgpo+MYJSabLRA7l9v1GvfQNi92ghAYFy/3SvGbHP71xuTJ/j4Zv1dCDT+noSVyPp7+7IRqMH4O1m3D46iFZkxc6aCRUGlYCFmu9rqwvG0DOat38eMf5L4Z9dRGpWN4Na6JakcG8q9X65g2bZD+PlY+bhHHa6vfJ4LoRUSV1tdkLPz2vqwf4PxYLV7ldF6EBRltI7EN72wrkhn4nQav8le8KrxIOvmF2p026rU0RhXEljUmMFq5RdG95jkXcaYjdBY409XpvFb8dTkrIfdbI9BkZXhxg+N3/JfarOfM7p2nUuJujg6f8CMZZvo2KE99kMbjYfniPJGy5MzwxiP8vvbef/W3sffmLggOAYS/jBChFu9e6DNMKNlZOIdRpcityJljDVdlozK2fIDxm/9q95gdGM7edgYO7J/Xc5jLDajVcE9PXTlzkaw/L6v0bUtOMYIuZGVjECSvMuYRS1hkREcHSmnrhUUZTyQV+5kdKn79/tT79l8ofUwuPYBo1tZZoYRkgKK5K5vmQ74810jHGWmn/k7dy80CkbdbT3MuObWBUa3KP/QrDESVuPhP3kXYDHW0Nm39tS5p2v1vBF28vP34M93jfFOWVwhxUnwrUTJLk/jE3+OySwuEwWLs1CwELOpLpyS6sik/1cr+W39PnysFj7sXod21WLOfWIhobog2ak+nCeXy1gNfv/6rJmx6p55XIDLZTxcnmlNkRMHjamDt/9uPFg3fPDMA7MvljPT6G+f8CeUb208eJdubKxLk/Cn8Vvu0o3h2gdwOF3nrgtHdhiD3dOOGa0dERVOPbS7B9NnZhhTMu9YanxXpRufOj/lEHzXy3iwb/yIsUaOPcBoKfrjbVj4htEy1Phho7Xg9HEKKYeM6+5ebQSeCm2MUPfP9zD1wZwP8jE14K5Jxm/m8+JyZQWWHcY4kJL1c/7MNs+FX4YYv+G/8UNjDZr82Lfe6Aa2c7nRvalaV6MFI+FPY2KDAxuN1oYb3jO6TJ1N6lFjUoVV40/tKxJv1EOXM2uChkwjGFW9IX/ldFv3k7GQ6LaFnvCY2f4NbA3vu7DrXSQFi7NQsBCzqS7k5Mh08vik1fz8dxI+VgsfdKtD++pXR7hQXZDsVB/E7YrVBZfLeBDOa7zA8f3G/uwLcZ6v7X/CN92MLluVOkHXT82fPtg99a9faM4WBJfLWOvGP9yYSOB87VxhtPjEXQvhcZe6tAbHSTI2zyfx18+Ju+st7BHxl+c+55CfZ2dT5+F64YUXsFgsObaYmDM/UMyfPz/X8RaLhfXr11/BUovIpWS3WRl5Ry1uqFmcDKeLh79eyXcrdvDz37t58ee13PvlCn5cvSvHOSnpGQz98V/6jlvO4RNnad4WEZEzs1jOPAg5OPLCQgUYY1Ye/NOYiviOCeaHCjA+q39Y7m5JFovR2pCfUAFGd7kat16+UAFgD8BVvjX/xPU0Bux7AdOnm61WrRpz5871vLbZbOc8Z8OGDTkSU2SkVv4U8WY+Nitv314TiwV+XL2bJ7/PuQLynLV7WbBhP8Nvqs7uIyfp/9VKNu8zBigO+m4Nn/eql2M6WxERMVlYSWOTq4rpwcLHx+esrRR5iYqKIjw8/PIUSERMYYSLWvj5WJmychdVYkOpFReO3WZl3KJtTFm1i2XbD3HweDonHZlEhvhx9KSDX9fvY/QfWqBPRETEbKYvSbhp0yaKFy9OmTJluPPOO9m6des5z6lduzaxsbG0atWKefPmXYFSisiVYLNaeP3Wmmwa0YGfHmnKizdVZ2iXqky6vxElwgPYefgkJx2ZNC1fjJmPNeO5zlUBeO2X9azeccTcwouIiFzlTG2xuPbaa/nyyy+pWLEie/fu5aWXXqJx48b8999/RERE5Do+NjaWTz/9lLp165KWlsb48eNp1aoV8+fP57rrrsvzHmlpaaSlnVqkJzk5GTAGRjkcjsvzwfLgvteVvKcUTKoL+VerRAg/9m/IB/O2UDw8gJ4NS2GzWrijTix/bNzHrLX7ePjrlYzqVouK0cYq3y6Xi6XbDvP9yl0cOemgfGQQFaKCKVkkgFRHJifSMnE4XVxfqRgh/uYMlFVdkOxUH8RNdUHcCkJdyM+9C9SsUCdOnKBcuXIMHjyYgQMHntc5Xbp0wWKxMG3atDzff+GFFxg2bFiu/V9//TWBgedYNVFECryUDHjjbxuH0owxFkX9XFQMc7E12cK+1HOPu6gQ6qR/VSdWDdEQERHJJSUlhW7dunnndLNt2rShfPnyfPzxx+d1/IgRI5gwYQLr1q3L8/28Wizi4uI4cODAFZ9uds6cObRp00bTCF7lVBcuvc37jvParI0s2nqI9GyrfAf52bjhmlgqx4Swef8JNu09xr5jaQT42gj09eGfXUdJdTh5un1F7mkSf8XLrbog2ak+iJvqgrgVhLqQnJxMsWLFzitYmD54O7u0tDTWrVtHs2bNzvucVatWERsbe8b3/fz88PPLvdiN3W435Qdk1n2l4FFduHSqlCjCuL7XkpKewZ+bD7Js20HKRQbTpWZxgvzO/M/cV0sTePaHf3l7zmauqxhN1eLGP5ipjkzSHE7CAq/Mz0d1QbJTfRA31QVxM7Mu5Oe+pgaLQYMG0aVLF0qVKsW+fft46aWXSE5OplevXgAMGTKEXbt28eWXXwIwcuRI4uPjqVatGunp6UyYMIHJkyczefJkMz+GiBQQgb4+tKkaTZuq0ed1fLcGpZi3fj9z1+1lwKRVfNS9Dt8s28Gk5TvIcLoY07s+jcrlHu8lIiIiuZkaLHbu3Mldd93FgQMHiIyMpGHDhixZsoTSpUsDkJSURGJiouf49PR0Bg0axK5duwgICKBatWpMnz6djh07mvURRMSLWSwWXrulBu1GHmHj3uO0fnthjvfv/XIF39zXkOolwkwqoYiIiPcwNVh88803Z31/3LhxOV4PHjyYwYMHX8YSicjVJiLYjzduu4Y+Y5cD0KxCMXo2iufz37eydNsheo9dxvcPNCa+mLECrSPTidPlwm61YrVacDpdpGU4SXVkYrVYrlj3KRERkYKmQI2xEBExQ8tKUfz8SFP87TbKRwUDcG3Zotz5yRLWJiVz12dLKFU0kMRDKexJTsU95YXVAs7Tpr+ICvGjcmwo1YqH0rdJGSJDco/xEhERKYwULEREIFd3p1B/O1/0bcCtoxaRcDCFpKOpuc45PVQA7DuWxr5j+1m40dgmP9gYf7vtchVbRESkwFCwEBE5g8gQP765ryHTVu8mKtSPUkWDKFU0EF8fKxmZTjKcLqwWC4G+NvztNlIdmWzce4x1Scd4c/YG/tudzIjp63jxpuoAuFwuvlm+gyVbD+LnY8XXZuHwbguNUxxEhqkLlYiIeDcFCxGRs4gNC+D+5uXO69ggPx9qlypC7VJFKB7uT++xyxm/JIFG5SJoWqEYT363hln/7T3tLBsbPl/GhH4NiQnzP+c9dh85ya/r9tL5muIUCfK9gE8kIiJyeShYiIhcBi0qRfFgi3J8PH8LT33/N8VC/Nh24AS+Niv3NCtDsJ8PJ1IdfLV4C5v3n+DWUYuYcM+1xBcLItWRycrEwzidUKNEGGGBdo6lOvh4/hZG/7GNtAwnU1fvZtJ9DfGxWc3+qCIiIoCChYjIZfNEm4os33aIFQmHOZaWQYnwAD7sXodaceGAsaJqseSNfJEQSsKhFG4dtZiK0cGsSDicYwXx0hGBHEvN4NCJdAAsFvgr4TAfztvCY60rmPHRREREctGvukRELhMfm5X37qpN9RKhtK8Ww0+PNPWECrcIf5jYrz6VY0I4cDyNRVsOkp7hJCbUn1JFAwFIOJjCoRPplC0WxGc96/HO7bUAeO+3TaxMPOy51tb9x9mw59iV+ngiIiI5qMVCROQyKh4ewM+PNDvrMZEhfky6vxGfLdxKVKgfTcoXo2yxICwWC0dS0vl751HSMpy0qBSJPavr07wN+/hx9W4GfLOa5zpXZfySBBZu3I/VAl/1a6gVw0VE5IpTsBARKQDCAuwMalcp1/7wQF+uqxiZa//wG6uzYvthEg+lcO+XKzz7nS54fNJqZj7W7KyDu9MyMvln51GWbz/MSUcmDzYvR4CvpsUVEZELp2AhIuKFwgLsvHNHLXqMXordauGO+qW4o34cD371F1v3n2Dw5L/59O66WCzG6uDLth/iv93JbNp7jA17j/Hf7uQc4ziWbTvI6F71CfI79b+F/cfSCA3wwc9HgUNERM5NwUJExEs1KFOUP55qSaCvD8FZgeC9O2vT9aNFzFm7l89/34a/3cqYP7ez7cCJXOcXC/alTqkiLNpykCVbD9F77DLG9mnA0ZMO3pq9gR9W7aJSdAgT722Yo/Xjl3+TmLpqN32axHNtWXW5EhERg4KFiIgXiwrJufZF9RJhPN2hMsN/XsuIGes8+0P9fWhcrhgVo4OpEB1CteKhlMkax7F6xxHuHr2U5dsP0+X9P9h15KSnNWP9nmP0Hrecr/pdS7CfD+OXJDD0x39xueCX//ZwR704hnSsTHjg+a+pse3ACT5ZsIXmFSPpUCP20nwRIiJiOgULEZFCpk+TeBZtOcDcdfsoVTSQvk3iua1eXI5uTtnVigtn4r0N6TF6qadlo2HZonS/tjRDf/yXNTuOcO8XK2hcLoK35mwEoGZcOGt2HGHSih38un4vr996DddXjj5ruTKdLsb+uY03Zm0gLcPJT2t207h8McICtOq4iEhhoGAhIlLIWCwWPu5Rl/VJx6haPBSb1XLOc6qXCGPSfY0Yt2gbbavG0KJSJBaLhVJFA+n22RIWbz3I4q0HAXi4ZXmeaFuRFQmHGTLlHzbvO06/L1bwwg3V6NkoPte1T6Zn8sfmA3yyYAsrEozpce02CyfSM/lqaQL9W5Q/r8+1fk8yIf52SoQHnP+XISIiV4yChYhIIWS3WalRMixf51SKCeGVrtfk2FczLpzPe9Wn19hlpGc4eaZjZe67rhwA9eOLMv3Rprww7T8mLtvB0B//I/FgCoPaVWLDnmOs3nGEPzYf4PdN+0l1GF2rgnxtPNupKr4+VgZ9t4axf27nnqZlzjpAfMnWg3zw22b+2HwAu81Cz0bxPHp9BcIC1dIhIlKQKFiIiMhZNSoXwYxHm5Gc6qBOqSI53vPzsfHyzTUoWSSQN2Zt4PM/tjF20XYyna4cx5UID6BN1Wj6NStDySKBpGc4eWv2BpKOpjJ11S7uqF/Kc2x6hpN/dh1h2bbD/Lpur6eVw2oBR6aL0X9sY/LKnTzeuiI9G5XGYjl3i4yIiFx+ChYiInJO5aOCz/iexWLhoZblKVkkgCe/+5v0TCfhgXZqxYVTt1QRWlWJpkpsSI4A4OtjpW+TMoyYsY5PF27ltrpxOJxO3pq9kS8Xb/e0cAD42qzcXr8kDzQvx9b9JxgxfR0b9h7j+Wn/kZaR6WlBcdu87zgxYf6embJEROTK0L+6IiJySdxYqwQtKkZxOCWd0hGB52xJuLNBHO/9uokt+0/w2e9b+WHVLtbvOQZA0SBf6pUuQoMyRel8TXFiwozZr0oWCaRxuQg+nr+Ft+Zs5NWZ66kSG0qzCpG4XC7enrOR93/bTHSoH+/eWZuGmg5XROSKUbAQEZFLJizQft5jH0L87XRvWJpRC7bwysz1AEQE+fLqLdfQukrUGYOJj83Kw9eXJ/FQCt/9tZNHJq5iyoON+Xj+Fr77aycAe5PT6PbZEh5rVZGHry9/XgPYRUTk4ljNLoCIiFy9+jSJx9dm/K+oecVIZg5oRpuq0eds7bBYLLx4U3VqxoVzJMVB+3d/57u/dmK1wLAbqnFb3ZI4XfDO3I3c8vEifli1k5PpmQAcOJ7GF4u2c9+XK5i7du9l/4wiIlcLtViIiIhpokP9+freazlwPJ22VaOx5qNlwd9uY1SPOnR5/w8OHE/H327lw251+H97dx4XVb3/D/x1ZpgZ9mHfkVUEBVzABVNx1zTL227m0nrdyuVa2XK/WVZa3brmrbT8WZpaammWZiYu4YYiIIosiuwoO8giywzM5/cHMTlhLiCg8no+Hjwe8jmfc87nzHln8/azjQho3E8jzMcWb2w/g/icS4jffAn/p0qEv7MF4rIv6SeXRyQX4NV7/fHcYG9OAiciaiUmFkRE1KFCPW1afK6z2gRrn+qHr49kYmqYB3q6W+mPPdjHDWE+tthyIhc/xOUgp7QGJzIbV5jq6aaGi5UJfj2Tj/d2pSC96DKWTAwEAFRrGlB6WYOsksvIKqlGWbUGIwMcEeh6c8v3EhF1NkwsiIjojhboqsZHj/a86jFntQnmjuyKF4b74nhGKc4XVmJQV3t42ZlBCIGvj2RiyS9J2HQiB9/H5jZbJrfJ8r2pCPWwxrSBnvB1MEe1ph6X6xrQ1dEczurmG/ZV1moRlVaCQ6nFOJ5RgmA3Kyx7MAhGco5AJqK7FxMLIiK668lkEsJ8bBHm8+cqUZIk4elBXuhiY4r5m+NRWVevP2askMHT1gxdbEwhScC+5ELEZJXp99RoopTL8OkTvTG6h5O+bN3RTLz7SzI0DX8umXuuoAoyCXj/oWAOuSKiuxYTCyIi6tRGdndE9OsjUVatgalSDhOlHEq5zCABKKioxcbj2dgam4u6eh3MVHI06ARyy2owc2McPnw4GPf3dMGSnUlYF5UFAPC0NcUQP3u4WJngg90p2BKTC1tzFV4Z699Rj0pE1KaYWBARUadnopTDRNl8SFMTR0tjLBjlhwWj/PRl9Q06LNqWgB9ic7FgyymsOZyBxIsVAIBX7/XH80P+nBBuZaLAom0JWPl7GiprtajR6BCfU4bCijo82McVc0f6wULJngwiurMxsSAiImoBI7kMHzwUDHOVEdYezUTixQoYK2RY/lgvjA10Nqj7eL8uKLmswYe/ncWGY9kGx9ZFZWHbyQuYGe4Fu4aWtaW8WosV+1NxPKMEdVod6up1MFXKsehefwzt5tDSRyQiuilMLIiIiFpIJpPw5oTucFYbY19KIV4fF2CwMtWVZg31AQDEZJYiyFWNXl2sIEHCh7+dRVJeBT74LRVySY7N+dG4x9cOg/3sEdLF2mAJ3tyyakSllcBZbYIeLpawMlVgW9wFLP01GcVVmmb3fHZdDD58JBj/6O3WJs9PRHQlJhZEREStIEkS/hnug3+G+1y33uxhvs3Kh/jZ48eTF7Bi3zlkl9YgNvsSYrMvYcX+83CwUGFsoBO87Mzwa0I+ojNLDc61NlWgrFoLAPB1MMeLI7rCzlwJlZEc66MysT3+IuZvPoWSKg2eHex96x6aiOgqmFgQERF1ILlMwsMhbrg/yAHrf/wVJh7BOJ55CftTClFYWYdv/pgMDgCSBPR0s0JZteaPPTa0MFHI8eKIrnhmkBeURn8uZ9vb3Qo2Zip8dSQD7/ySjMhzRRjWzQFD/OzhY2/W4tWphBAQAje1mSERdQ5MLIiIiG4DkiTBzhgYF+KGJwZ4QVOvw5HzxfglIQ8XymowzN8eE3q66PfNqKjVIrWgEh62ZrAzVzW7nkwm4d/3BcDOQokPdp/FodRiHEotBgDYW6gQ6GKJQFc1+nnZYJCv3TUTjaq6ehxOLcLB1GIcPFeE0ssa/HOID14Y7qtPMAora/HfiFQ4Wqowb6Tf316LiO5eTCyIiIhuQ0ojGYb5O2CY/9UnX1saKxDice1dyyVJwqyhvhjd3RH7UwoRea4IJzLKUFRZhwNni3DgbBEAYOZQH7w8pluz5KL0sgZfH8nA2qOZqKytNzj2373nEJ9Thv8+1gvH0kvw6rYE/bCswV3tEeJhra+7L7kAr2xNwLyRXfHkAI+b/iyI6M7AxIKIiOgu5+tgAV8HCzw/xAc1mgYk5VUg8WI54rLKsD3+Ilb+ngaFTMKC0d0AAIUVtVh9KB0bj2ejWtO4VFUXG1MM93fAED87FFXW4f9+SsSBs0UI//B3lNc0JhRKIxk09Tp8EZmGL6eGAgA09Tq8tSMJxVV1eGP7GZgo5HgopPlk8vIaLdYczsDJ7DL8+77u8HO0aKdPh4huFSYWREREnYiJUo4QD2uEeFhjapgngtyssGRnElbsPw9Ng8DlunpsjsmBpr5x5/AeLpZ4YbgvRnd3MphXEeiqxowNscgprYFMAmaE++C+YBeMW3EIEckFOF9YBV8Hc2yJyUF2aTXkMgkNOoGXt56GhbGRfrfyS9UafBOVhdWH0vW9Ik+vPYGfZt8D26sM8QKAsssaFFTWws/B4obneuSUVuPw+WL8o7crjBXy1nyERPQ3mFgQERF1Ys8M8kKDTof3dqVgVWSavjzEwxpzhvliaDf7q86/6OGixs45g7HheBYG+tiid5fGoU8jAxyxN7kAqw+m460HemDFvlQAwBvjA5B4sQI/xOZizrcnMSbQCYkXy5FedFl/TT9Hc9RoG5BTWoOZG+Kw4dn+BhPSi6vq8OXBdKyPykKNtgGuViZ4oJcLxgU5Q5Iah25V1NQj1NMajpbG+vMKKmrx8KqjKKiow5HzxfjfpN4tnrxORH+PiQUREVEn9/wQH+gE8OFvZzHA2wZzhnXFAG+b6375Vpsqmi2hO3OoN/YmF2DbyVyYGxuhsLIOrlYmeKJ/F8glCRU1WuxJKsCOUxf15/g7WWD2MF+MD3JGenEV/vHZUURnluL/fjqDhWO6ISazFEfOl+CH2FzUaBuHZinkEi5cqsHnv6fh89/TDNpgaWyElU+G4B5fO9RoGvDcNzEoqKgDAOw8nYc+Xazx9CCvW/HREdEVmFgQERERZoT74Ol7DJesbYkQDxuEelgjJqsMaw5nAADmjewKlVHj8KMVk3pj5e9pjUvnulsh2FVtMOTJ18ECK57ojWfWnsCmEznYdCLH4PrBbmrMH+mHMB9b7EsuxI8nL+BoWjFMlUawNVOitr4BWSXVmPZVNN56oAeOppXgdG45rE0VeDTUHV8cTMd7u5IR5KZGX89rT34/nXsJ2+Iu4Lkh3nC1MmnV50LUGTCxICIiIgBodVLRZEa4D579JgYA4GNvhn/0dtUfM1bIMX/UtZejHdbNAa+NC8A7vyQDALo5WqCvlzVGBjgi3O/PoVnjg50xPtjZ4NxabQMWbT2N7fEX8fqPZwA09m6sejIE/bxscLG8FjtOXcSsjXFY8XhvuFqZwN5CBROl4byLH0/m4pWtCdDU65CSX4Hvnhvwtz04+1MKsPNUHv41phsTEOrUmFgQERHRLTXc3wH+ThZIya/EwtHdYCS/+YTl2cHeGNrNAXbmSliZKm/4PGOFHP99rBe87c3xccQ5AMC7E4PQ39sWALDswSCk5FUgtbAKk1Yf05/nYWuKUQGOGN3DCftTCg3mmxxLL8X+lEKMCHBsdr8zF8oxY0McNPU6JOdXYuvMMJgqW/71SgiBfcmFSCiVcK8QLb4OUUdgYkFERES3lEwm4Zun+yGj+LL+C31L+DqYt+g8SZLw4oiu6Odlg8t19QYJgZnKCKunhuKtHYlIK7qMwspa1Gp1yCqpxv87nIH/98fwLQCYNdQH9TqBLw+mY+mvKQj3szdIkipqtZj9bZx+Ba3kvAq8/MPpG5ocXlffgNSCKrhbm0JtqgAAnMq5hLd3JiE2qwyAHIU/nMHSh4Jhpmr7r2v55bVYsT8VU8M84O9k2eb3o7sTEwsiIiK65RwsjeFwxcpMHWHA3yQ1nnZm+PqpfgAaewgqauoRlV6MPYkF2JdSiLr6Brz/UDAe6OWK8hotvo/JwfnCKmyJycUT/bvoz3vp+1PIKqmGq5UJ3pzQHbM2xmHn6Tx0d7HErKGNk9prNA3Q6nQwVchhJJfhfGEVNkVnY2tcrn5DQXcbE7hameBYeikAwEQhQ522AT+fzkNiXgU+nxyCbk6G+3qUXtbg39vPQCaTMKq7I4Z1s4eFsaLFn9Wr207jwNkixGWV4ZcXB0N+g8v4El2JiQURERF1WpIkQW2qwNhAZ4wNdEZ9gw6aBp1+OJPaRIEXhnfF2zuT8HHEOdzfywVFlXXYfCIHvyUWQCmX4fPJfdDT3QqL7++BN7afwYe/ncXP8ReRV16r3zwQAJRyGTQNOv3v5iojVNXVI6e0BjmlNQCAB3u7Yv5IH3y/az82Z5shregyHvjsMF69NwBTBnhAJmtcDWvKmuP6pXp3nLoIpVyGQV3t8EAvF4zu7tRszsi1RJ77cxf2lPxK/BR/AQ/2ab6JYXsSQuBQajGCXNWwNrvxoXC30qHUIrz2YwLenRiEIX72HdKGOw0TCyIiIqI/GMllzeaEPDnAA+uiMpFVUo2+7+zVL3kLAP++LwA93a309RIvVuC76Gyk5Fc2u7amQQeZBAz3d8QT/d0R7ueAqtp6JOaVI62wCr3crRHkpoZWq4WPJfDT7DC8vC0RB88V4c2fE7H7TD5mDPXBoq2nkVdeCxe1MSb0dEFEcgHSiy5jf0oh9qcUwkwpx8jujnC3NoWliRGsTJQY6GsLN2vTZm2qb9DhnZ1JAABXKxNcuFSDj/acw/hgZ/1KXgbPUK/Dyewy2Jgp4aQ2hoWxAg06gZKqOhRW1sHFygQ2tyARWL43FZ/sS0UvdytsmznwhjdCvFWEEFj2awpySmvwxcE0JhY3iIkFERER0TUojWRYNNYfMzfGoUbbAKVchiA3Ne4LdsaTAzwM6i55oAeGdrOHykgGFysTOKmNoZTLUKttQLWmAaZKucFkdLWpAgN97DDQx67ZfW3NlFg7vS82HM/C0l0piEovQVR6CYDG+SffPN0PLlYmeHVcAM4XVuLn+Iv4Mf4Cckpr8FP8RYNrKeQSHu/bBXOG+xpsHvjdiRykFlbBylSBbbMG4v5PD+PCpRpsOJaNZ/6y14e2QYdnv4nBwXNF+jIThRx19Q3Q/THP3Fghw0tj/DF9oGeLh1MdOV+MFfsbN1aMz7mELTE5eLxflxZdq6Xisi8h8WIFgMbJ+5eqNTe1iEBnxcSCiIiI6DruDXLGpucHQCGXIdDV8qr/mg809niM6eHUrNxYIYdV8w6D65LJJEwN88SQrvZ46YdTOJFZhp7uVlg7va/BECFfBwssGN0N80f5ISarDIdSi1FerUFFbT0ySy7jZPYlrD+WhS0xOXiwjyvCfOwQ4GSB//6xctb8kX5wtDTG/JF+WLQtAZ/uT8UjoW6w/GPehhACb/x4BgfPFUEpl8FEKUd5jVbfeyOTAAtjBcprtFiyMwm/JuThg4eD4W1vOAG/olaLV7clwMnSGPNGdm02L6SwohZzN52EEICnrSkyS6rx/u4UjA10atcv9uuOZur/3KAT2JtciIdDOnZ42J2AiQURERHRDfi7yeDtwdPODJueD0PixXL4O1n+7Z4jkiShr6dNs83/otJK8J89ZxGbVYbvonPwXfSfGw/62JvpJ6U/HOKG1YfSkVZ0Ge/sTMKCUd3gpDbG//afx+aYHMgkYOWTfTAiwBHVmnoUVtTBVCWHrZkKMgn4Njob7/2SjJisMoxbcQjrn+lv0JYlO5Lwy+k8AMCuhDy8MzFQv2pXg07gxU0nUVylgb+TBX6YORAPfn4E5wqq8NGec1gyMfCWfqZ/p7CiFrsSGts4MsARe5ML8FtiPhOLG3BrdsIhIiIiojYll0kIdrNq0UaGYT62+GFGGNY/0w9P3eOJIFc1ZFJjT8ObE3pA8ce8EiO5DC+P9QcAbInJxYCl+3DvJ4f0e4K89cCfiYCp0giedmZwsDCGXCZBkiRM7u+B3+YPwQBvG9RqdZi5IRZ55Y0T0/clF+D72FxIUuN8jrzyWjyzLgb3f3oYIz+ORO+39+BYeinMlHJ8NrkPzFVGeOv+xmRi4/EsnLlQ3uLPbn9KAf615RRySquvW/e76BzU6wRCPKzxr9GNmzkePFeEak29vs7RtGLsPpPXorZUa+rxa0IePt5zFiezy65Zt65eh6KaFt2mQ3RoYrF48WJIkmTw4+TUvPvwSpGRkQgJCYGxsTG8vb2xatWqdmotERER0Z1LkiQM7mqPNyf0wI4XBuH04jE4umhEs4nJo7s74oOHgxHiYQ1JatyfAwD+Ge6NKX+ZU3I1btam+Gp6XwQ4W6K4SoMZ62ORX16LRdsSAADPDvLC3gXh+OcQb8gk4HRuOc4XVqGith7GChk+fKQnfP4YQhXmY4sJPV2gE8DcTSfxU/wF1F4xeb6JtkGHE5mlWBWZhoikAogrNhdcdzQTz6yLwda4XEz/Otpgpa6rXWfj8SwA+GNPDwt0sTFFXb0OkX+snJV4sRxT10RjxoY4/BR/4bqfB9A4lGx/SgGe+yYGvd+OwMyNcVix/zz+8flRTPryGA6lFhm0ucl/96big9PyZnNmblcdPhSqR48e2Lt3r/53ufzvl0fLyMjAuHHj8Nxzz2HDhg04cuQIZs2aBXt7ezz00EPt0VwiIiKiu4K5ygjmV9l8T5IkPBrqjkdD3VFYUYuI5ALoBDD5JiZQmyqN8OWUENz/6WGcyi3HmOUHUV6jhY+9Gf41uhuMFXK8Oi4Aj4S6IfFiBezNVXCwVMFJbdKsTa+PC8Ch1CKkFV3G3E3xsDJVYHg3B8hkEjT1Olyq0SI2sxSXNX8mHMFuaiwc3Q1H0orxRWQ6gMaJ5WlFlzHn2zh8Pb3vVXeE330mH4WVdbC3UOHeQGdIkoSxgU748mA6difmY0SAI/615RTq/5it/uq2BPRwUV9zM8dzBZVYsjMJh1KL9WXuNibwd7LEgZRC/aT8sT2c8OkTvfXtOpxajDVHsgBIMDfu8K/sN6TDW2lkZHTdXoomq1atQpcuXbB8+XIAQEBAAGJiYvCf//yHiQURERHRLeZgaYzJ/a/fS3E17jam+PSJPpj6VWMvgUwCPnq0F4wVf/4jsq+DBXwdLK5xFcBJbYzdc4dg04lsbDmRg4vltdh2snlPgY2ZEn26WOFoWglO55Zj6lfR+mMvjemGod3s8ciqKBxKLcZbO5KazdnIKa3GR3vOAgCe6NdFP+RsTA9HfHkwHfuTC/FRxFmk5FfCxkwJH3sznMgsw+yNcdg++x6DvUMuVWtwLL0E+5ILse3kBTToBJRyGaaGeeChEDf4O1lAkhr3JFl9MB3fHs/G7sR8vP7jGSx7KAiXqrVYsCUeAHCPow4j/B1u7sPvIB2eWKSmpsLFxQUqlQr9+/fHe++9B29v76vWjYqKwujRow3KxowZgzVr1kCr1UKhaL7jZF1dHerq6vS/V1Q0dudptVpotX/fFXarNd2rPe9JtyfGAjVhLNCVGA/U5G6KhX4earx+bzcs2ZWCucN90cPJrEXPZWsqx+xwL8wY7IkjfyQOCrkMSiMZTBRyBLtZwt/RAjKZhJKqOqw8mIFvo3MgBPDuxO54sLcrAOCjh4Mw67t4rD+WhQZdA/452AsuViY4nVuO5zecRMllDZwsVZgU6qJvZ6CTOezNlSiq0uh7Pxbf549QD2vc/3kUzhZUYuH38ejnaY2kvEokXChHcn4lrhzZNCrAAa+M9YOHTePSYPX1jfM1HMyM8Pq9fujnYYU5m+KxOSYHtmYKpBZWobCyDt52ppjoUdGhsXAz95bE1QZ0tZNff/0V1dXV8PPzQ0FBAd555x2kpKQgMTERtrbNV17w8/PD9OnT8dprr+nLjh49invuuQcXL16Es7Nzs3MWL16Mt956q1n5t99+C1PTFqz7RkREREQ3pa4BUN34ZuC3RIUG0OoAW2PD8n0XJPyc3dgYGQQCbQRSLknQ6CS4mgr8M6AB6r+sbLslXYYjBY09GH1sdZjm17iDemq5hM+SZBBovmeHo4mAn6VALzsdfC2v394jBRK2pP/5IcklgQVBDXAzu4mHbgPV1dV44oknUF5eDkvLaz9Ih/ZY3Hvvvfo/BwUFISwsDD4+Pli3bh0WLFhw1XMkyfDFNeVFfy1v8uqrrxpcq6KiAu7u7hg9evR1P5xbSavVIiIiAqNGjbpqzwp1HowFasJYoCsxHqgJY6FtjQMwMbUYqw9nIiq9FKdLG79DDulqi08e63nVeSe2GaU48lUM7MyVWPX8QFhfsaeG9bFsfH0kE152ZujhYonuzhYI8bCGg4XqptvluP88/negsVfkpTHdMLWfa4fHQtNonxvR4UOhrmRmZoagoCCkpqZe9biTkxPy8/MNygoLC2FkZHTVHg4AUKlUUKmav1iFQtEhL6ij7ku3H8YCNWEs0JUYD9SEsdB2hnd3xvDuzjhzoRzro7Jgb6HCvJFdrzqhGwAG+Tniq+mh8LW3gIPacMTLM4N98Mxgn1vSrgWj/WFjboyq2no8P8QXDQ2NQ6Y6MhZu5r63VWJRV1eH5ORkDB48+KrHw8LCsGPHDoOyPXv2IDQ0lP/hEREREdFNCXRV4/2Hg2+o7nB/xzZuTeMInKfu8dL/3tB8Zd3bWofuY7Fw4UJERkYiIyMDx48fx8MPP4yKigpMmzYNQOMwpqlTp+rrz5gxA1lZWViwYAGSk5Px1VdfYc2aNVi4cGFHPQIREREREaGDeyxyc3MxadIkFBcXw97eHgMGDMCxY8fg4dG4rFleXh6ys7P19b28vLBr1y7Mnz8fn332GVxcXLBixQouNUtERERE1ME6NLHYtGnTNY+vXbu2WVl4eDji4uLaqEVERERERNQSHToUioiIiIiI7g5MLIiIiIiIqNWYWBARERERUasxsSAiIiIiolZjYkFERERERK3GxIKIiIiIiFqNiQUREREREbUaEwsiIiIiImo1JhZERERERNRqTCyIiIiIiKjVmFgQEREREVGrMbEgIiIiIqJWY2JBREREREStxsSCiIiIiIhajYkFERERERG1GhMLIiIiIiJqNSYWRERERETUakYd3YD2JoQAAFRUVLTrfbVaLaqrq1FRUQGFQtGu96bbC2OBmjAW6EqMB2rCWKAmt0MsNH1nbvoOfS2dLrGorKwEALi7u3dwS4iIiIiI7gyVlZVQq9XXrCOJG0k/7iI6nQ4XL16EhYUFJElqt/tWVFTA3d0dOTk5sLS0bLf70u2HsUBNGAt0JcYDNWEsUJPbIRaEEKisrISLiwtksmvPouh0PRYymQxubm4ddn9LS0v+JUEAGAv0J8YCXYnxQE0YC9Sko2Phej0VTTh5m4iIiIiIWo2JBRERERERtRoTi3aiUqnw5ptvQqVSdXRTqIMxFqgJY4GuxHigJowFanKnxUKnm7xNRERERES3HnssiIiIiIio1ZhYEBERERFRqzGxICIiIiKiVmNi0Q4+//xzeHl5wdjYGCEhITh06FBHN4laYenSpejbty8sLCzg4OCAiRMn4uzZswZ1hBBYvHgxXFxcYGJigqFDhyIxMdGgTl1dHV544QXY2dnBzMwM999/P3Jzcw3qlJWVYcqUKVCr1VCr1ZgyZQouXbrU1o9ILbR06VJIkoR58+bpyxgLncuFCxfw5JNPwtbWFqampujVqxdiY2P1xxkPnUN9fT3eeOMNeHl5wcTEBN7e3nj77beh0+n0dRgLd6+DBw9iwoQJcHFxgSRJ2L59u8Hx9nz32dnZmDBhAszMzGBnZ4cXX3wRGo2mLR5b/3DUhjZt2iQUCoVYvXq1SEpKEnPnzhVmZmYiKyuro5tGLTRmzBjx9ddfizNnzoj4+Hgxfvx40aVLF1FVVaWvs2zZMmFhYSG2bt0qEhISxGOPPSacnZ1FRUWFvs6MGTOEq6uriIiIEHFxcWLYsGGiZ8+eor6+Xl9n7NixIjAwUBw9elQcPXpUBAYGivvuu69dn5duTHR0tPD09BTBwcFi7ty5+nLGQudRWloqPDw8xPTp08Xx48dFRkaG2Lt3rzh//ry+DuOhc3jnnXeEra2t2Llzp8jIyBDff/+9MDc3F8uXL9fXYSzcvXbt2iVef/11sXXrVgFA/PjjjwbH2+vd19fXi8DAQDFs2DARFxcnIiIihIuLi5gzZ06bPTsTizbWr18/MWPGDIMyf39/sWjRog5qEd1qhYWFAoCIjIwUQgih0+mEk5OTWLZsmb5ObW2tUKvVYtWqVUIIIS5duiQUCoXYtGmTvs6FCxeETCYTu3fvFkIIkZSUJACIY8eO6etERUUJACIlJaU9Ho1uUGVlpejatauIiIgQ4eHh+sSCsdC5vPLKK2LQoEF/e5zx0HmMHz9ePP300wZlDz74oHjyySeFEIyFzuSviUV7vvtdu3YJmUwmLly4oK/z3XffCZVKJcrLy9vkeTkUqg1pNBrExsZi9OjRBuWjR4/G0aNHO6hVdKuVl5cDAGxsbAAAGRkZyM/PN3jvKpUK4eHh+vceGxsLrVZrUMfFxQWBgYH6OlFRUVCr1ejfv7++zoABA6BWqxk/t5nZs2dj/PjxGDlypEE5Y6Fz+fnnnxEaGopHHnkEDg4O6N27N1avXq0/znjoPAYNGoR9+/bh3LlzAIBTp07h8OHDGDduHADGQmfWnu8+KioKgYGBcHFx0dcZM2YM6urqDIZo3kpGbXJVAgAUFxejoaEBjo6OBuWOjo7Iz8/voFbRrSSEwIIFCzBo0CAEBgYCgP7dXu29Z2Vl6esolUpYW1s3q9N0fn5+PhwcHJrd08HBgfFzG9m0aRPi4uJw4sSJZscYC51Leno6Vq5ciQULFuC1115DdHQ0XnzxRahUKkydOpXx0Im88sorKC8vh7+/P+RyORoaGvDuu+9i0qRJAPh3Q2fWnu8+Pz+/2X2sra2hVCrbLD6YWLQDSZIMfhdCNCujO9OcOXNw+vRpHD58uNmxlrz3v9a5Wn3Gz+0jJycHc+fOxZ49e2BsbPy39RgLnYNOp0NoaCjee+89AEDv3r2RmJiIlStXYurUqfp6jIe73+bNm7FhwwZ8++236NGjB+Lj4zFv3jy4uLhg2rRp+nqMhc6rvd59e8cHh0K1ITs7O8jl8mZZYWFhYbMMku48L7zwAn7++WccOHAAbm5u+nInJycAuOZ7d3JygkajQVlZ2TXrFBQUNLtvUVER4+c2ERsbi8LCQoSEhMDIyAhGRkaIjIzEihUrYGRkpH9PjIXOwdnZGd27dzcoCwgIQHZ2NgD+3dCZvPTSS1i0aBEef/xxBAUFYcqUKZg/fz6WLl0KgLHQmbXnu3dycmp2n7KyMmi12jaLDyYWbUipVCIkJAQREREG5RERERg4cGAHtYpaSwiBOXPmYNu2bdi/fz+8vLwMjnt5ecHJycngvWs0GkRGRurfe0hICBQKhUGdvLw8nDlzRl8nLCwM5eXliI6O1tc5fvw4ysvLGT+3iREjRiAhIQHx8fH6n9DQUEyePBnx8fHw9vZmLHQi99xzT7Olp8+dOwcPDw8A/LuhM6muroZMZvgVSy6X65ebZSx0Xu357sPCwnDmzBnk5eXp6+zZswcqlQohISFt84BtMiWc9JqWm12zZo1ISkoS8+bNE2ZmZiIzM7Ojm0YtNHPmTKFWq8Xvv/8u8vLy9D/V1dX6OsuWLRNqtVps27ZNJCQkiEmTJl11KTk3Nzexd+9eERcXJ4YPH37VpeSCg4NFVFSUiIqKEkFBQVxG8DZ35apQQjAWOpPo6GhhZGQk3n33XZGamio2btwoTE1NxYYNG/R1GA+dw7Rp04Srq6t+udlt27YJOzs78fLLL+vrMBbuXpWVleLkyZPi5MmTAoD4+OOPxcmTJ/VbDbTXu29abnbEiBEiLi5O7N27V7i5uXG52TvdZ599Jjw8PIRSqRR9+vTRL0tKdyYAV/35+uuv9XV0Op148803hZOTk1CpVGLIkCEiISHB4Do1NTVizpw5wsbGRpiYmIj77rtPZGdnG9QpKSkRkydPFhYWFsLCwkJMnjxZlJWVtcNTUkv9NbFgLHQuO3bsEIGBgUKlUgl/f3/x5ZdfGhxnPHQOFRUVYu7cuaJLly7C2NhYeHt7i9dff13U1dXp6zAW7l4HDhy46veEadOmCSHa991nZWWJ8ePHCxMTE2FjYyPmzJkjamtr2+zZJSGEaJu+ECIiIiIi6iw4x4KIiIiIiFqNiQUREREREbUaEwsiIiIiImo1JhZERERERNRqTCyIiIiIiKjVmFgQEREREVGrMbEgIiIiIqJWY2JBREREREStxsSCiIjuKJ6enli+fHlHN4OIiP6CiQUREf2t6dOnY+LEiQCAoUOHYt68ee1277Vr18LKyqpZ+YkTJ/D888+3WzuIiOjGGHV0A4iIqHPRaDRQKpUtPt/e3v4WtoaIiG4V9lgQEdF1TZ8+HZGRkfjkk08gSRIkSUJmZiYAICkpCePGjYO5uTkcHR0xZcoUFBcX688dOnQo5syZgwULFsDOzg6jRo0CAHz88ccICgqCmZkZ3N3dMWvWLFRVVQEAfv/9dzz11FMoLy/X32/x4sUAmg+Fys7OxgMPPABzc3NYWlri0UcfRUFBgf744sWL0atXL6xfvx6enp5Qq9V4/PHHUVlZ2bYfGhFRJ8PEgoiIruuTTz5BWFgYnnvuOeTl5SEvLw/u7u7Iy8tDeHg4evXqhZiYGOzevRsFBQV49NFHDc5ft24djIyMcOTIEXzxxRcAAJlMhhUrVuDMmTNYt24d9u/fj5dffhkAMHDgQCxfvhyWlpb6+y1cuLBZu4QQmDhxIkpLSxEZGYmIiAikpaXhscceM6iXlpaG7du3Y+fOndi5cyciIyOxbNmyNvq0iIg6Jw6FIiKi61Kr1VAqlTA1NYWTk5O+fOXKlejTpw/ee+89fdlXX30Fd3d3nDt3Dn5+fgAAX19ffPDBBwbXvHK+hpeXF5YsWYKZM2fi888/h1KphFqthiRJBvf7q7179+L06dPIyMiAu7s7AGD9+vXo0aMHTpw4gb59+wIAdDod1q5dCwsLCwDAlClTsG/fPrz77rut+2CIiEiPPRZERNRisbGxOHDgAMzNzfU//v7+ABp7CZqEhoY2O/fAgQMYNWoUXF1dYWFhgalTp6KkpASXL1++4fsnJyfD3d1dn1QAQPfu3WFlZYXk5GR9maenpz6pAABnZ2cUFhbe1LMSEdG1sceCiIhaTKfTYcKECXj//febHXN2dtb/2czMzOBYVlYWxo0bhxkzZmDJkiWwsbHB4cOH8cwzz0Cr1d7w/YUQkCTpuuUKhcLguCRJ0Ol0N3wfIiK6PiYWRER0Q5RKJRoaGgzK+vTpg61bt8LT0xNGRjf+v5SYmBjU19fjo48+gkzW2Hm+ZcuW697vr7p3747s7Gzk5OToey2SkpJQXl6OgICAG24PERG1HodCERHRDfH09MTx48eRmZmJ4uJi6HQ6zJ49G6WlpZg0aRKio6ORnp6OPXv24Omnn75mUuDj44P6+nr873//Q3p6OtavX49Vq1Y1u19VVRX27duH4uJiVFdXN7vOyJEjERwcjMmTJyMuLg7R0dGYOnUqwsPDrzr8ioiI2g4TCyIiuiELFy6EXC5H9+7dYW9vj+zsbLi4uODIkSNoaGjAmDFjEBgYiLlz50KtVut7Iq6mV69e+Pjjj/H+++8jMDAQGzduxNKlSw3qDBw4EDNmzMBjjz0Ge3v7ZpO/gcYhTdu3b4e1tTWGDBmCkSNHwtvbG5s3b77lz09ERNcmCSFERzeCiIiIiIjubOyxICIiIiKiVmNiQURERERErcbEgoiIiIiIWo2JBRERERERtRoTCyIiIiIiajUmFkRERERE1GpMLIiIiIiIqNWYWBARERERUasxsSAiIiIiolZjYkFERERERK3GxIKIiIiIiFqNiQUREREREbXa/wfS6gWO+ERjEQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Model Setup ===\n",
    "encoder_coverage = EncoderRNNWithCoverage(\n",
    "    input_size=len(input_vocab),\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "decoder_coverage = CoverageDecoderRNN(\n",
    "    output_size=len(output_vocab),\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "model_coverage = Seq2SeqCoverageModel(encoder_coverage, decoder_coverage, device).to(device)\n",
    "\n",
    "# === Optimizer & Loss ===\n",
    "optimizer_cov = torch.optim.Adam(model_coverage.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "criterion_cov = nn.CrossEntropyLoss(ignore_index=output_vocab[PAD_TOKEN])\n",
    "\n",
    "# === Train ===\n",
    "train_model(\n",
    "    model=model_coverage,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=dev_loader,\n",
    "    optimizer=optimizer_cov,\n",
    "    criterion=criterion_cov,\n",
    "    output_vocab=output_vocab,\n",
    "    device=device,\n",
    "    num_iters=num_iters,\n",
    "    print_every=print_every,\n",
    "    plot_every=plot_every,\n",
    "    teacher_forcing_ratio=0.6,\n",
    "    log_filename=\"CoverageModel_log.csv\",\n",
    "    plot_title=\"Coverage Mechanism Training Loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010dfe51",
   "metadata": {},
   "source": [
    "#### Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7790e605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spicy2 predictions saved to Spicy2_output.csv\n"
     ]
    }
   ],
   "source": [
    "# Make sure model is in evaluation mode\n",
    "model_coverage.eval()\n",
    "Spicy2_preds = []\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    ingredients_coverage = test_df.iloc[i]['Ingredients']\n",
    "\n",
    "    # 🔁 Join ingredients list to a string, then preprocess\n",
    "    if isinstance(ingredients_coverage, list):\n",
    "        ingredients = \" \".join(ingredients_coverage)\n",
    "\n",
    "    tokens_coverage = preprocess_text(ingredients_coverage)\n",
    "    input_ids_coverage = [input_vocab.get(tok, input_vocab[UNK_TOKEN]) for tok in tokens_coverage]\n",
    "    input_ids_coverage = input_ids_coverage[:MAX_INGREDIENT_LEN] + [input_vocab[PAD_TOKEN]] * max(0, MAX_INGREDIENT_LEN - len(input_ids_coverage))\n",
    "\n",
    "    src_tensor_coverage = torch.tensor(input_ids_coverage, dtype=torch.long, device=device)\n",
    "\n",
    "    # 🧠 Generate recipe\n",
    "    generated_recipe_coverage = generate_recipe_Coverage(model_coverage, src_tensor_coverage, output_vocab, device)\n",
    "    Spicy2_preds.append(generated_recipe_coverage)\n",
    "\n",
    "# 🗂️ Add predictions to DataFrame\n",
    "test_df['Recipe - Spicy 2'] = Spicy2_preds\n",
    "\n",
    "# ✅ Choose columns\n",
    "columns_to_save_2 = ['Ingredients', 'Recipe - Spicy 2']\n",
    "if 'Recipe' in test_df.columns:\n",
    "    columns_to_save_2.insert(1, 'Recipe')\n",
    "\n",
    "# 💾 Save to timestamped CSV\n",
    "filename_2 = \"Spicy2_output.csv\"\n",
    "test_df[columns_to_save_2].to_csv(filename_2, index=False)\n",
    "print(f\"✅ Spicy2 predictions saved to {filename_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bfed9f",
   "metadata": {},
   "source": [
    "#### Evalating the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9c6fb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1081/1081 [01:02<00:00, 17.18it/s]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Appended results to Assignment_2_evaluation_results.csv\n",
      "                Model      BLEU    METEOR BERTScore\n",
      "9  Coverage mechanism  0.017502  0.098239   0.80841\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Evaluate your attention model\n",
    "metrics_coverage = evaluate_model(\n",
    "    model_coverage,\n",
    "    test_loader,\n",
    "    input_vocab,\n",
    "    output_vocab,\n",
    "    device,\n",
    "    model_name=\"Coverage mechanism\"\n",
    ")\n",
    "\n",
    "# Step 2: Load existing results if the file exists\n",
    "results_file = \"Assignment_2_evaluation_results.csv\"\n",
    "if os.path.exists(results_file):\n",
    "    results_df = pd.read_csv(results_file)\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([metrics_coverage])], ignore_index=True)\n",
    "else:\n",
    "    results_df = pd.DataFrame([metrics_coverage])\n",
    "\n",
    "# Step 3: Save back to the same file\n",
    "results_df.to_csv(results_file, index=False)\n",
    "\n",
    "print(f\"✅ Appended results to {results_file}\")\n",
    "print(results_df.tail(1))  # show just the latest entry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba004e",
   "metadata": {},
   "source": [
    "### Toy Input texts (gold and predicted recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e78cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_recipe_from_input(model, input_text, input_vocab, output_vocab, device,\n",
    "                              preprocess_fn=preprocess_text,\n",
    "                              max_input_len=MAX_INGREDIENT_LEN,\n",
    "                              max_output_len=MAX_RECIPE_LEN,\n",
    "                              use_attention=False):\n",
    "    \"\"\"\n",
    "    Generate a recipe from an input ingredient list using the provided model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Seq2Seq model.\n",
    "        input_text: Raw ingredient string.\n",
    "        input_vocab: Dictionary mapping input tokens to indices.\n",
    "        output_vocab: Dictionary mapping output indices to tokens.\n",
    "        device: Device to run the model on (CPU or GPU).\n",
    "        preprocess_fn: Preprocessing function used during training.\n",
    "        max_input_len: Maximum length of input sequence.\n",
    "        max_output_len: Maximum length of output recipe.\n",
    "        use_attention: Whether the model uses attention.\n",
    "\n",
    "    Returns:\n",
    "        Generated recipe string.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    tokens = preprocess_fn(input_text)\n",
    "    input_ids = [input_vocab.get(tok, input_vocab[UNK_TOKEN]) for tok in tokens]\n",
    "    input_ids = input_ids[:max_input_len] + [input_vocab[PAD_TOKEN]] * max(0, max_input_len - len(input_ids))\n",
    "\n",
    "    src_tensor = torch.tensor(input_ids, dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_recipe = generate_recipe(model, src_tensor, output_vocab, device,\n",
    "                                           max_len=max_output_len,\n",
    "                                           use_attention=use_attention)\n",
    "    return generated_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64998206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Generated Recipe Set RNN:\n",
      " mix ingredient together add cup sugar water add sugar salt pepper add add vanilla add vanilla pour mixture mixture pan chill hour\n",
      "🧾 Generated Recipe model coverage:\n",
      " mix ingredient together add ginger ale\n"
     ]
    }
   ],
   "source": [
    "# Example input\n",
    "user_input = \"sugar, lemon juice,  water,  orange juice, strawberries, icecream\"\n",
    "\n",
    "output_recipe_attention = predict_recipe_from_input(\n",
    "    model= model_coverage, \n",
    "    input_text=user_input,\n",
    "    input_vocab=input_vocab,\n",
    "    output_vocab=output_vocab,\n",
    "    device=device,\n",
    "    use_attention= False # or True if the model uses attention\n",
    ")\n",
    "print(\"🧾 Generated Recipe model coverage:\\n\", output_recipe_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa1bb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Generated Recipe Set RNN:\n",
      " mix ingredient together add cup sugar add milk mixture add vanilla stir well add vanilla pour mixture mixture pan chill hour\n",
      "🧾 Generated Recipe model coverage:\n",
      " mix cream cheese sugar cream cheese sugar add cream cheese add cream cheese fold whipped cream cheese mixture chill\n"
     ]
    }
   ],
   "source": [
    "# Example input\n",
    "user_input = \"8 oz philadelphia cream cheese, 14 oz can sweetened condensed milk, 1 ts vanilla, 1/3 c  lemon juice, 48 oz canned cherries, 8 inch graham cracker,  pie crusts\"\n",
    "\n",
    "\n",
    "output_recipe_attention = predict_recipe_from_input(\n",
    "    model= model_coverage, \n",
    "    input_text=user_input,\n",
    "    input_vocab=input_vocab,\n",
    "    output_vocab=output_vocab,\n",
    "    device=device,\n",
    "    use_attention= False  # or True if the model uses attention\n",
    ")\n",
    "print(\"🧾 Generated Recipe model coverage:\\n\", output_recipe_attention)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
